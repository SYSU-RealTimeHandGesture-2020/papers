{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.layers.core import *\n",
    "# from tensorflow.keras.layers.convolutional import *\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 22 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_coarse = 14 # the number of coarse class\n",
    "        self.clc_fine = 28 # the number of fine-grained class\n",
    "        self.feat_d = 231\n",
    "        self.filters = 16\n",
    "        self.data_dir = '..\\\\data\\\\SHREC\\\\'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H,W],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l,joint_n,joint_d):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,joint_n*joint_d))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),joint_n*joint_d))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l,joint_n,joint_d)\n",
    "\n",
    "    print(\"slow\", diff_slow)\n",
    "    print(\"fast\", diff_fast)\n",
    "    print(\"JCD\", M)\n",
    "\n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "\n",
    "    # 测试删去x_d_fast\n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast]) # x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    print('concat', x.shape)\n",
    "    x = block(x,filters*2)\n",
    "    print('conv1', x.shape)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    print('pool1', x.shape)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    print('conv2', x.shape)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    print('pool2', x.shape)    \n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    print('conv3', x.shape)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
    "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
    "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
    "    \n",
    "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    print('pool', x.shape)    \n",
    "\n",
    "    x = d1D(x,128)\n",
    "    print('dense1', x.shape)    \n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    print('dense2', x.shape)    \n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(clc_num, activation='softmax')(x)\n",
    "    print('dense3', x.shape)    \n",
    "\n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow Tensor(\"reshape_8/Identity:0\", shape=(None, 32, 66), dtype=float32)\n",
      "fast Tensor(\"reshape_9/Identity:0\", shape=(None, 16, 66), dtype=float32)\n",
      "JCD Tensor(\"input_9:0\", shape=(None, 32, 231), dtype=float32)\n",
      "concat (None, 16, 48)\n",
      "conv1 (None, 16, 32)\n",
      "pool1 (None, 8, 32)\n",
      "conv2 (None, 8, 64)\n",
      "pool2 (None, 4, 64)\n",
      "conv3 (None, 4, 128)\n",
      "pool (None, 128)\n",
      "dense1 (None, 128)\n",
      "dense2 (None, 128)\n",
      "dense3 (None, 14)\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  [(None, 32, 231)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  [(None, 32, 22, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Model)                (None, 4, 128)       113696      M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           model_18[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          16384       global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 128)          512         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_162 (LeakyReLU)     (None, 128)          0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 128)          0           leaky_re_lu_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          16384       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 128)          512         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_163 (LeakyReLU)     (None, 128)          0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128)          0           leaky_re_lu_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 14)           1806        dropout_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 149,294\n",
      "Trainable params: 147,630\n",
      "Non-trainable params: 1,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"train.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without frame_sampling train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1960/1960 [00:24<00:00, 80.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Train['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 32, 231) (1960, 32, 22, 3) (1960, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_0.shape, X_1.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 840/840 [00:09<00:00, 88.46it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Test['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 32, 231) (840, 32, 22, 3) (840, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_0.shape, X_test_1.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/600\n",
      "1960/1960 [==============================] - 10s 5ms/sample - loss: 0.2446 - accuracy: 0.9316 - val_loss: 5.0073 - val_accuracy: 0.0893\n",
      "Epoch 2/600\n",
      "1960/1960 [==============================] - 2s 777us/sample - loss: 0.2582 - accuracy: 0.9194 - val_loss: 5.0805 - val_accuracy: 0.0821\n",
      "Epoch 3/600\n",
      "1960/1960 [==============================] - 2s 766us/sample - loss: 0.2613 - accuracy: 0.9255 - val_loss: 4.8437 - val_accuracy: 0.0964\n",
      "Epoch 4/600\n",
      "1960/1960 [==============================] - 2s 789us/sample - loss: 0.2737 - accuracy: 0.9260 - val_loss: 4.6482 - val_accuracy: 0.1036\n",
      "Epoch 5/600\n",
      "1960/1960 [==============================] - 1s 728us/sample - loss: 0.2448 - accuracy: 0.9281 - val_loss: 4.5795 - val_accuracy: 0.1119\n",
      "Epoch 6/600\n",
      "1960/1960 [==============================] - 1s 734us/sample - loss: 0.2431 - accuracy: 0.9255 - val_loss: 4.6427 - val_accuracy: 0.1119\n",
      "Epoch 7/600\n",
      "1960/1960 [==============================] - 1s 751us/sample - loss: 0.2484 - accuracy: 0.9291 - val_loss: 4.6529 - val_accuracy: 0.1083\n",
      "Epoch 8/600\n",
      "1960/1960 [==============================] - 1s 704us/sample - loss: 0.2437 - accuracy: 0.9276 - val_loss: 4.7129 - val_accuracy: 0.1071\n",
      "Epoch 9/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.2224 - accuracy: 0.9388 - val_loss: 4.8426 - val_accuracy: 0.1048\n",
      "Epoch 10/600\n",
      "1960/1960 [==============================] - 1s 726us/sample - loss: 0.2299 - accuracy: 0.9311 - val_loss: 4.9848 - val_accuracy: 0.1048\n",
      "Epoch 11/600\n",
      "1960/1960 [==============================] - 1s 723us/sample - loss: 0.2174 - accuracy: 0.9357 - val_loss: 5.0711 - val_accuracy: 0.1060\n",
      "Epoch 12/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.2380 - accuracy: 0.9301 - val_loss: 5.0186 - val_accuracy: 0.1107\n",
      "Epoch 13/600\n",
      "1960/1960 [==============================] - 1s 764us/sample - loss: 0.2346 - accuracy: 0.9362 - val_loss: 4.8727 - val_accuracy: 0.1131\n",
      "Epoch 14/600\n",
      "1960/1960 [==============================] - 1s 759us/sample - loss: 0.2139 - accuracy: 0.9393 - val_loss: 4.7491 - val_accuracy: 0.1238\n",
      "Epoch 15/600\n",
      "1960/1960 [==============================] - 1s 753us/sample - loss: 0.2431 - accuracy: 0.9311 - val_loss: 4.6983 - val_accuracy: 0.1310\n",
      "Epoch 16/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.2047 - accuracy: 0.9393 - val_loss: 4.6796 - val_accuracy: 0.1310\n",
      "Epoch 17/600\n",
      "1960/1960 [==============================] - 1s 717us/sample - loss: 0.2151 - accuracy: 0.9367 - val_loss: 4.7559 - val_accuracy: 0.1310\n",
      "Epoch 18/600\n",
      "1960/1960 [==============================] - 1s 721us/sample - loss: 0.2078 - accuracy: 0.9408 - val_loss: 4.8300 - val_accuracy: 0.1274\n",
      "Epoch 19/600\n",
      "1960/1960 [==============================] - 1s 723us/sample - loss: 0.1894 - accuracy: 0.9439 - val_loss: 4.9066 - val_accuracy: 0.1214\n",
      "Epoch 20/600\n",
      "1960/1960 [==============================] - 1s 712us/sample - loss: 0.1890 - accuracy: 0.9449 - val_loss: 4.9548 - val_accuracy: 0.1167\n",
      "Epoch 21/600\n",
      "1960/1960 [==============================] - 1s 695us/sample - loss: 0.1963 - accuracy: 0.9403 - val_loss: 4.9107 - val_accuracy: 0.1143\n",
      "Epoch 22/600\n",
      "1960/1960 [==============================] - 1s 702us/sample - loss: 0.1911 - accuracy: 0.9454 - val_loss: 4.8660 - val_accuracy: 0.1143\n",
      "Epoch 23/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.1945 - accuracy: 0.9429 - val_loss: 4.8422 - val_accuracy: 0.1155\n",
      "Epoch 24/600\n",
      "1960/1960 [==============================] - 2s 775us/sample - loss: 0.1800 - accuracy: 0.9480 - val_loss: 4.8867 - val_accuracy: 0.1155\n",
      "Epoch 25/600\n",
      "1960/1960 [==============================] - 2s 765us/sample - loss: 0.1965 - accuracy: 0.9444 - val_loss: 4.9285 - val_accuracy: 0.1155\n",
      "Epoch 26/600\n",
      "1960/1960 [==============================] - 1s 742us/sample - loss: 0.1793 - accuracy: 0.9510 - val_loss: 5.0030 - val_accuracy: 0.1143\n",
      "Epoch 27/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.1773 - accuracy: 0.9500 - val_loss: 5.0819 - val_accuracy: 0.1143\n",
      "Epoch 28/600\n",
      "1960/1960 [==============================] - 1s 694us/sample - loss: 0.1675 - accuracy: 0.9480 - val_loss: 5.1505 - val_accuracy: 0.1143\n",
      "Epoch 29/600\n",
      "1960/1960 [==============================] - 1s 718us/sample - loss: 0.1703 - accuracy: 0.9536 - val_loss: 5.1574 - val_accuracy: 0.1167\n",
      "Epoch 30/600\n",
      "1960/1960 [==============================] - 1s 706us/sample - loss: 0.1684 - accuracy: 0.9536 - val_loss: 5.1637 - val_accuracy: 0.1202\n",
      "Epoch 31/600\n",
      "1960/1960 [==============================] - 1s 718us/sample - loss: 0.1830 - accuracy: 0.9403 - val_loss: 5.1358 - val_accuracy: 0.1202\n",
      "Epoch 32/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.1465 - accuracy: 0.9592 - val_loss: 5.0633 - val_accuracy: 0.1214\n",
      "Epoch 33/600\n",
      "1960/1960 [==============================] - 1s 693us/sample - loss: 0.1668 - accuracy: 0.9490 - val_loss: 4.9536 - val_accuracy: 0.1250\n",
      "Epoch 34/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1616 - accuracy: 0.9541 - val_loss: 4.8786 - val_accuracy: 0.1298\n",
      "Epoch 35/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.1493 - accuracy: 0.9643 - val_loss: 4.9196 - val_accuracy: 0.1298\n",
      "Epoch 36/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1437 - accuracy: 0.9546 - val_loss: 4.9917 - val_accuracy: 0.1286\n",
      "Epoch 37/600\n",
      "1960/1960 [==============================] - 1s 762us/sample - loss: 0.1388 - accuracy: 0.9571 - val_loss: 5.0613 - val_accuracy: 0.1286\n",
      "Epoch 38/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.1544 - accuracy: 0.9566 - val_loss: 5.1414 - val_accuracy: 0.1286\n",
      "Epoch 39/600\n",
      "1960/1960 [==============================] - 1s 741us/sample - loss: 0.1569 - accuracy: 0.9536 - val_loss: 5.1934 - val_accuracy: 0.1310\n",
      "Epoch 40/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.1362 - accuracy: 0.9582 - val_loss: 5.2006 - val_accuracy: 0.1321\n",
      "Epoch 41/600\n",
      "1960/1960 [==============================] - 1s 700us/sample - loss: 0.1335 - accuracy: 0.9592 - val_loss: 5.2092 - val_accuracy: 0.1345\n",
      "Epoch 42/600\n",
      "1960/1960 [==============================] - 1s 718us/sample - loss: 0.1486 - accuracy: 0.9592 - val_loss: 5.1262 - val_accuracy: 0.1345\n",
      "Epoch 43/600\n",
      "1960/1960 [==============================] - 1s 720us/sample - loss: 0.1221 - accuracy: 0.9668 - val_loss: 5.0136 - val_accuracy: 0.1393\n",
      "Epoch 44/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.1369 - accuracy: 0.9577 - val_loss: 4.9336 - val_accuracy: 0.1405\n",
      "Epoch 45/600\n",
      "1960/1960 [==============================] - 1s 730us/sample - loss: 0.1439 - accuracy: 0.9612 - val_loss: 4.8156 - val_accuracy: 0.1452\n",
      "Epoch 46/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.1378 - accuracy: 0.9597 - val_loss: 4.7868 - val_accuracy: 0.1476\n",
      "Epoch 47/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.1399 - accuracy: 0.9628 - val_loss: 4.8163 - val_accuracy: 0.1476\n",
      "Epoch 48/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1318 - accuracy: 0.9587 - val_loss: 4.8564 - val_accuracy: 0.1476\n",
      "Epoch 49/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1380 - accuracy: 0.9628 - val_loss: 4.8766 - val_accuracy: 0.1476\n",
      "Epoch 50/600\n",
      "1960/1960 [==============================] - 1s 712us/sample - loss: 0.1318 - accuracy: 0.9638 - val_loss: 4.9036 - val_accuracy: 0.1476\n",
      "Epoch 51/600\n",
      "1960/1960 [==============================] - 1s 724us/sample - loss: 0.1104 - accuracy: 0.9679 - val_loss: 4.9202 - val_accuracy: 0.1464\n",
      "Epoch 52/600\n",
      "1960/1960 [==============================] - 1s 695us/sample - loss: 0.1357 - accuracy: 0.9628 - val_loss: 4.9001 - val_accuracy: 0.1476\n",
      "Epoch 53/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.1338 - accuracy: 0.9643 - val_loss: 4.8934 - val_accuracy: 0.1488\n",
      "Epoch 54/600\n",
      "1960/1960 [==============================] - 1s 697us/sample - loss: 0.1181 - accuracy: 0.9699 - val_loss: 4.8768 - val_accuracy: 0.1488\n",
      "Epoch 55/600\n",
      "1960/1960 [==============================] - 1s 704us/sample - loss: 0.1126 - accuracy: 0.9643 - val_loss: 4.8708 - val_accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1263 - accuracy: 0.9628 - val_loss: 4.8709 - val_accuracy: 0.1500\n",
      "Epoch 57/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.1226 - accuracy: 0.9617 - val_loss: 4.8561 - val_accuracy: 0.1512\n",
      "Epoch 58/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.1212 - accuracy: 0.9612 - val_loss: 4.8385 - val_accuracy: 0.1512\n",
      "Epoch 59/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.1183 - accuracy: 0.9668 - val_loss: 4.8398 - val_accuracy: 0.1524\n",
      "Epoch 60/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.1140 - accuracy: 0.9663 - val_loss: 4.8375 - val_accuracy: 0.1536\n",
      "Epoch 61/600\n",
      "1960/1960 [==============================] - 1s 715us/sample - loss: 0.1287 - accuracy: 0.9648 - val_loss: 4.8340 - val_accuracy: 0.1548\n",
      "Epoch 62/600\n",
      "1960/1960 [==============================] - 1s 723us/sample - loss: 0.1031 - accuracy: 0.9750 - val_loss: 4.8200 - val_accuracy: 0.1571\n",
      "Epoch 63/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.0976 - accuracy: 0.9760 - val_loss: 4.7959 - val_accuracy: 0.1595\n",
      "Epoch 64/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.1161 - accuracy: 0.9653 - val_loss: 4.7848 - val_accuracy: 0.1607\n",
      "Epoch 65/600\n",
      "1960/1960 [==============================] - 1s 728us/sample - loss: 0.1047 - accuracy: 0.9714 - val_loss: 4.7716 - val_accuracy: 0.1619\n",
      "Epoch 66/600\n",
      "1960/1960 [==============================] - 2s 810us/sample - loss: 0.1062 - accuracy: 0.9699 - val_loss: 4.7581 - val_accuracy: 0.1619\n",
      "Epoch 67/600\n",
      "1960/1960 [==============================] - 2s 791us/sample - loss: 0.1107 - accuracy: 0.9684 - val_loss: 4.7424 - val_accuracy: 0.1655\n",
      "Epoch 68/600\n",
      "1960/1960 [==============================] - 2s 816us/sample - loss: 0.1059 - accuracy: 0.9735 - val_loss: 4.7255 - val_accuracy: 0.1667\n",
      "Epoch 69/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.1204 - accuracy: 0.9648 - val_loss: 4.7059 - val_accuracy: 0.1679\n",
      "Epoch 70/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.1099 - accuracy: 0.9668 - val_loss: 4.6833 - val_accuracy: 0.1702\n",
      "Epoch 71/600\n",
      "1960/1960 [==============================] - 1s 760us/sample - loss: 0.1177 - accuracy: 0.9658 - val_loss: 4.6641 - val_accuracy: 0.1702\n",
      "Epoch 72/600\n",
      "1960/1960 [==============================] - 1s 712us/sample - loss: 0.1133 - accuracy: 0.9643 - val_loss: 4.6443 - val_accuracy: 0.1702\n",
      "Epoch 73/600\n",
      "1960/1960 [==============================] - 1s 717us/sample - loss: 0.1092 - accuracy: 0.9684 - val_loss: 4.6234 - val_accuracy: 0.1714\n",
      "Epoch 74/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.1144 - accuracy: 0.9653 - val_loss: 4.5928 - val_accuracy: 0.1750\n",
      "Epoch 75/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.1136 - accuracy: 0.9633 - val_loss: 4.5569 - val_accuracy: 0.1810\n",
      "Epoch 76/600\n",
      "1960/1960 [==============================] - 1s 731us/sample - loss: 0.1158 - accuracy: 0.9704 - val_loss: 4.5186 - val_accuracy: 0.1845\n",
      "Epoch 77/600\n",
      "1960/1960 [==============================] - 1s 694us/sample - loss: 0.1136 - accuracy: 0.9612 - val_loss: 4.4817 - val_accuracy: 0.1857\n",
      "Epoch 78/600\n",
      "1960/1960 [==============================] - 1s 748us/sample - loss: 0.0916 - accuracy: 0.9755 - val_loss: 4.4523 - val_accuracy: 0.1869\n",
      "Epoch 79/600\n",
      "1960/1960 [==============================] - 2s 766us/sample - loss: 0.0920 - accuracy: 0.9719 - val_loss: 4.4218 - val_accuracy: 0.1869\n",
      "Epoch 80/600\n",
      "1960/1960 [==============================] - 1s 744us/sample - loss: 0.1078 - accuracy: 0.9719 - val_loss: 4.3919 - val_accuracy: 0.1881\n",
      "Epoch 81/600\n",
      "1960/1960 [==============================] - 1s 753us/sample - loss: 0.1019 - accuracy: 0.9750 - val_loss: 4.3617 - val_accuracy: 0.1905\n",
      "Epoch 82/600\n",
      "1960/1960 [==============================] - 1s 752us/sample - loss: 0.1013 - accuracy: 0.9724 - val_loss: 4.3343 - val_accuracy: 0.1917\n",
      "Epoch 83/600\n",
      "1960/1960 [==============================] - 1s 719us/sample - loss: 0.1083 - accuracy: 0.9735 - val_loss: 4.3047 - val_accuracy: 0.1940\n",
      "Epoch 84/600\n",
      "1960/1960 [==============================] - 1s 706us/sample - loss: 0.1157 - accuracy: 0.9663 - val_loss: 4.2764 - val_accuracy: 0.1988\n",
      "Epoch 85/600\n",
      "1960/1960 [==============================] - 1s 716us/sample - loss: 0.0960 - accuracy: 0.9709 - val_loss: 4.2497 - val_accuracy: 0.2012\n",
      "Epoch 86/600\n",
      "1960/1960 [==============================] - 1s 747us/sample - loss: 0.1002 - accuracy: 0.9760 - val_loss: 4.2231 - val_accuracy: 0.2012\n",
      "Epoch 87/600\n",
      "1960/1960 [==============================] - 1s 708us/sample - loss: 0.1011 - accuracy: 0.9699 - val_loss: 4.1986 - val_accuracy: 0.2012\n",
      "Epoch 88/600\n",
      "1960/1960 [==============================] - 1s 683us/sample - loss: 0.1106 - accuracy: 0.9704 - val_loss: 4.1729 - val_accuracy: 0.2024\n",
      "Epoch 89/600\n",
      "1960/1960 [==============================] - 1s 736us/sample - loss: 0.0920 - accuracy: 0.9740 - val_loss: 4.1475 - val_accuracy: 0.2036\n",
      "Epoch 90/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.1065 - accuracy: 0.9679 - val_loss: 4.1243 - val_accuracy: 0.2036\n",
      "Epoch 91/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1028 - accuracy: 0.9668 - val_loss: 4.0996 - val_accuracy: 0.2048\n",
      "Epoch 92/600\n",
      "1960/1960 [==============================] - 1s 752us/sample - loss: 0.1062 - accuracy: 0.9689 - val_loss: 4.0723 - val_accuracy: 0.2048\n",
      "Epoch 93/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.1051 - accuracy: 0.9714 - val_loss: 4.0463 - val_accuracy: 0.2060\n",
      "Epoch 94/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.1175 - accuracy: 0.9612 - val_loss: 4.0203 - val_accuracy: 0.2083\n",
      "Epoch 95/600\n",
      "1960/1960 [==============================] - 1s 687us/sample - loss: 0.1170 - accuracy: 0.9673 - val_loss: 3.9946 - val_accuracy: 0.2107\n",
      "Epoch 96/600\n",
      "1960/1960 [==============================] - 1s 696us/sample - loss: 0.1106 - accuracy: 0.9679 - val_loss: 3.9712 - val_accuracy: 0.2167\n",
      "Epoch 97/600\n",
      "1960/1960 [==============================] - 1s 709us/sample - loss: 0.1041 - accuracy: 0.9714 - val_loss: 3.9469 - val_accuracy: 0.2190\n",
      "Epoch 98/600\n",
      "1960/1960 [==============================] - 1s 687us/sample - loss: 0.1032 - accuracy: 0.9724 - val_loss: 3.9233 - val_accuracy: 0.2250\n",
      "Epoch 99/600\n",
      "1960/1960 [==============================] - 1s 714us/sample - loss: 0.0900 - accuracy: 0.9735 - val_loss: 3.8992 - val_accuracy: 0.2262\n",
      "Epoch 100/600\n",
      "1960/1960 [==============================] - 1s 729us/sample - loss: 0.0973 - accuracy: 0.9760 - val_loss: 3.8761 - val_accuracy: 0.2286\n",
      "Epoch 101/600\n",
      "1960/1960 [==============================] - 1s 745us/sample - loss: 0.1015 - accuracy: 0.9709 - val_loss: 3.8528 - val_accuracy: 0.2321\n",
      "Epoch 102/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0953 - accuracy: 0.9724 - val_loss: 3.8293 - val_accuracy: 0.2405\n",
      "Epoch 103/600\n",
      "1960/1960 [==============================] - 1s 732us/sample - loss: 0.1033 - accuracy: 0.9730 - val_loss: 3.8052 - val_accuracy: 0.2440\n",
      "Epoch 104/600\n",
      "1960/1960 [==============================] - 1s 751us/sample - loss: 0.1074 - accuracy: 0.9719 - val_loss: 3.7806 - val_accuracy: 0.2464\n",
      "Epoch 105/600\n",
      "1960/1960 [==============================] - 1s 752us/sample - loss: 0.1053 - accuracy: 0.9709 - val_loss: 3.7559 - val_accuracy: 0.2476\n",
      "Epoch 106/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.0982 - accuracy: 0.9724 - val_loss: 3.7311 - val_accuracy: 0.2500\n",
      "Epoch 107/600\n",
      "1960/1960 [==============================] - 1s 696us/sample - loss: 0.1131 - accuracy: 0.9694 - val_loss: 3.7053 - val_accuracy: 0.2560\n",
      "Epoch 108/600\n",
      "1960/1960 [==============================] - 1s 709us/sample - loss: 0.1060 - accuracy: 0.9653 - val_loss: 3.6806 - val_accuracy: 0.2583\n",
      "Epoch 109/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.0983 - accuracy: 0.9714 - val_loss: 3.6556 - val_accuracy: 0.2643\n",
      "Epoch 110/600\n",
      "1960/1960 [==============================] - 1s 714us/sample - loss: 0.1065 - accuracy: 0.9714 - val_loss: 3.6308 - val_accuracy: 0.2667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/600\n",
      "1960/1960 [==============================] - 1s 732us/sample - loss: 0.1235 - accuracy: 0.9628 - val_loss: 3.6065 - val_accuracy: 0.2679\n",
      "Epoch 112/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.0981 - accuracy: 0.9714 - val_loss: 3.5808 - val_accuracy: 0.2714\n",
      "Epoch 113/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1172 - accuracy: 0.9709 - val_loss: 3.5561 - val_accuracy: 0.2726\n",
      "Epoch 114/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.1234 - accuracy: 0.9643 - val_loss: 3.5313 - val_accuracy: 0.2750\n",
      "Epoch 115/600\n",
      "1960/1960 [==============================] - 2s 767us/sample - loss: 0.1074 - accuracy: 0.9694 - val_loss: 3.5063 - val_accuracy: 0.2786\n",
      "Epoch 116/600\n",
      "1960/1960 [==============================] - 1s 714us/sample - loss: 0.1006 - accuracy: 0.9694 - val_loss: 3.4815 - val_accuracy: 0.2845\n",
      "Epoch 117/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.0952 - accuracy: 0.9719 - val_loss: 3.4566 - val_accuracy: 0.2845\n",
      "Epoch 118/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.1004 - accuracy: 0.9709 - val_loss: 3.4324 - val_accuracy: 0.2869\n",
      "Epoch 119/600\n",
      "1960/1960 [==============================] - 1s 701us/sample - loss: 0.1088 - accuracy: 0.9689 - val_loss: 3.4077 - val_accuracy: 0.2905\n",
      "Epoch 120/600\n",
      "1960/1960 [==============================] - 1s 698us/sample - loss: 0.0916 - accuracy: 0.9735 - val_loss: 3.3831 - val_accuracy: 0.2952\n",
      "Epoch 121/600\n",
      "1960/1960 [==============================] - 1s 693us/sample - loss: 0.0995 - accuracy: 0.9735 - val_loss: 3.3580 - val_accuracy: 0.3000\n",
      "Epoch 122/600\n",
      "1960/1960 [==============================] - 1s 718us/sample - loss: 0.1037 - accuracy: 0.9689 - val_loss: 3.3336 - val_accuracy: 0.3024\n",
      "Epoch 123/600\n",
      "1960/1960 [==============================] - 1s 764us/sample - loss: 0.1180 - accuracy: 0.9638 - val_loss: 3.3088 - val_accuracy: 0.3048\n",
      "Epoch 124/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.1150 - accuracy: 0.9689 - val_loss: 3.2844 - val_accuracy: 0.3060\n",
      "Epoch 125/600\n",
      "1960/1960 [==============================] - 1s 743us/sample - loss: 0.0946 - accuracy: 0.9735 - val_loss: 3.2597 - val_accuracy: 0.3083\n",
      "Epoch 126/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0961 - accuracy: 0.9755 - val_loss: 3.2354 - val_accuracy: 0.3107\n",
      "Epoch 127/600\n",
      "1960/1960 [==============================] - 1s 705us/sample - loss: 0.1164 - accuracy: 0.9704 - val_loss: 3.2112 - val_accuracy: 0.3143\n",
      "Epoch 128/600\n",
      "1960/1960 [==============================] - 1s 690us/sample - loss: 0.1102 - accuracy: 0.9684 - val_loss: 3.1876 - val_accuracy: 0.3167\n",
      "Epoch 129/600\n",
      "1960/1960 [==============================] - 1s 700us/sample - loss: 0.1015 - accuracy: 0.9719 - val_loss: 3.1641 - val_accuracy: 0.3202\n",
      "Epoch 130/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.1059 - accuracy: 0.9679 - val_loss: 3.1401 - val_accuracy: 0.3238\n",
      "Epoch 131/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.0909 - accuracy: 0.9755 - val_loss: 3.1167 - val_accuracy: 0.3321\n",
      "Epoch 132/600\n",
      "1960/1960 [==============================] - 1s 695us/sample - loss: 0.1006 - accuracy: 0.9745 - val_loss: 3.0924 - val_accuracy: 0.3369\n",
      "Epoch 133/600\n",
      "1960/1960 [==============================] - 1s 719us/sample - loss: 0.1055 - accuracy: 0.9679 - val_loss: 3.0693 - val_accuracy: 0.3405\n",
      "Epoch 134/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.1173 - accuracy: 0.9689 - val_loss: 3.0456 - val_accuracy: 0.3417\n",
      "Epoch 135/600\n",
      "1960/1960 [==============================] - 2s 766us/sample - loss: 0.1027 - accuracy: 0.9714 - val_loss: 3.0226 - val_accuracy: 0.3500\n",
      "Epoch 136/600\n",
      "1960/1960 [==============================] - 1s 748us/sample - loss: 0.1023 - accuracy: 0.9750 - val_loss: 2.9997 - val_accuracy: 0.3524\n",
      "Epoch 137/600\n",
      "1960/1960 [==============================] - 1s 733us/sample - loss: 0.0942 - accuracy: 0.9760 - val_loss: 2.9762 - val_accuracy: 0.3560\n",
      "Epoch 138/600\n",
      "1960/1960 [==============================] - 1s 744us/sample - loss: 0.0958 - accuracy: 0.9745 - val_loss: 2.9527 - val_accuracy: 0.3571\n",
      "Epoch 139/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1067 - accuracy: 0.9668 - val_loss: 2.9291 - val_accuracy: 0.3619\n",
      "Epoch 140/600\n",
      "1960/1960 [==============================] - 1s 694us/sample - loss: 0.0949 - accuracy: 0.9745 - val_loss: 2.9060 - val_accuracy: 0.3643\n",
      "Epoch 141/600\n",
      "1960/1960 [==============================] - 1s 696us/sample - loss: 0.1049 - accuracy: 0.9699 - val_loss: 2.8835 - val_accuracy: 0.3690\n",
      "Epoch 142/600\n",
      "1960/1960 [==============================] - 1s 702us/sample - loss: 0.1080 - accuracy: 0.9714 - val_loss: 2.8601 - val_accuracy: 0.3714\n",
      "Epoch 143/600\n",
      "1960/1960 [==============================] - 1s 720us/sample - loss: 0.0954 - accuracy: 0.9724 - val_loss: 2.8369 - val_accuracy: 0.3762\n",
      "Epoch 144/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.1108 - accuracy: 0.9704 - val_loss: 2.8136 - val_accuracy: 0.3821\n",
      "Epoch 145/600\n",
      "1960/1960 [==============================] - 2s 775us/sample - loss: 0.1090 - accuracy: 0.9714 - val_loss: 2.7912 - val_accuracy: 0.3833\n",
      "Epoch 146/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.1196 - accuracy: 0.9699 - val_loss: 2.7684 - val_accuracy: 0.3857\n",
      "Epoch 147/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.0970 - accuracy: 0.9735 - val_loss: 2.7455 - val_accuracy: 0.3917\n",
      "Epoch 148/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1083 - accuracy: 0.9704 - val_loss: 2.7230 - val_accuracy: 0.3964\n",
      "Epoch 149/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.1136 - accuracy: 0.9704 - val_loss: 2.7003 - val_accuracy: 0.4012\n",
      "Epoch 150/600\n",
      "1960/1960 [==============================] - 1s 721us/sample - loss: 0.1166 - accuracy: 0.9648 - val_loss: 2.6775 - val_accuracy: 0.4048\n",
      "Epoch 151/600\n",
      "1960/1960 [==============================] - 1s 716us/sample - loss: 0.1055 - accuracy: 0.9714 - val_loss: 2.6552 - val_accuracy: 0.4095\n",
      "Epoch 152/600\n",
      "1960/1960 [==============================] - 1s 706us/sample - loss: 0.1158 - accuracy: 0.9648 - val_loss: 2.6330 - val_accuracy: 0.4131\n",
      "Epoch 153/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.0959 - accuracy: 0.9709 - val_loss: 2.6111 - val_accuracy: 0.4167\n",
      "Epoch 154/600\n",
      "1960/1960 [==============================] - 1s 695us/sample - loss: 0.0915 - accuracy: 0.9735 - val_loss: 2.5897 - val_accuracy: 0.4214\n",
      "Epoch 155/600\n",
      "1960/1960 [==============================] - 1s 726us/sample - loss: 0.0959 - accuracy: 0.9760 - val_loss: 2.5682 - val_accuracy: 0.4226\n",
      "Epoch 156/600\n",
      "1960/1960 [==============================] - 1s 740us/sample - loss: 0.1034 - accuracy: 0.9724 - val_loss: 2.5468 - val_accuracy: 0.4298\n",
      "Epoch 157/600\n",
      "1960/1960 [==============================] - 1s 752us/sample - loss: 0.1056 - accuracy: 0.9740 - val_loss: 2.5259 - val_accuracy: 0.4333\n",
      "Epoch 158/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1161 - accuracy: 0.9679 - val_loss: 2.5047 - val_accuracy: 0.4369\n",
      "Epoch 159/600\n",
      "1960/1960 [==============================] - 2s 912us/sample - loss: 0.1061 - accuracy: 0.9704 - val_loss: 2.4833 - val_accuracy: 0.4393\n",
      "Epoch 160/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1005 - accuracy: 0.9694 - val_loss: 2.4616 - val_accuracy: 0.4452\n",
      "Epoch 161/600\n",
      "1960/1960 [==============================] - 2s 923us/sample - loss: 0.1061 - accuracy: 0.9663 - val_loss: 2.4405 - val_accuracy: 0.4476\n",
      "Epoch 162/600\n",
      "1960/1960 [==============================] - 2s 817us/sample - loss: 0.0884 - accuracy: 0.9765 - val_loss: 2.4198 - val_accuracy: 0.4500\n",
      "Epoch 163/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1046 - accuracy: 0.9709 - val_loss: 2.3994 - val_accuracy: 0.4536\n",
      "Epoch 164/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.1044 - accuracy: 0.9653 - val_loss: 2.3791 - val_accuracy: 0.4631\n",
      "Epoch 165/600\n",
      "1960/1960 [==============================] - 1s 753us/sample - loss: 0.1016 - accuracy: 0.9689 - val_loss: 2.3587 - val_accuracy: 0.4714\n",
      "Epoch 166/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.1013 - accuracy: 0.9714 - val_loss: 2.3378 - val_accuracy: 0.4738\n",
      "Epoch 167/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.0980 - accuracy: 0.9755 - val_loss: 2.3167 - val_accuracy: 0.4762\n",
      "Epoch 168/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.1138 - accuracy: 0.9633 - val_loss: 2.2960 - val_accuracy: 0.4786\n",
      "Epoch 169/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.0988 - accuracy: 0.9730 - val_loss: 2.2752 - val_accuracy: 0.4786\n",
      "Epoch 170/600\n",
      "1960/1960 [==============================] - 1s 729us/sample - loss: 0.1010 - accuracy: 0.9714 - val_loss: 2.2550 - val_accuracy: 0.4798\n",
      "Epoch 171/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.1021 - accuracy: 0.9714 - val_loss: 2.2346 - val_accuracy: 0.4821\n",
      "Epoch 172/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.0974 - accuracy: 0.9699 - val_loss: 2.2144 - val_accuracy: 0.4845\n",
      "Epoch 173/600\n",
      "1960/1960 [==============================] - 1s 722us/sample - loss: 0.1067 - accuracy: 0.9735 - val_loss: 2.1940 - val_accuracy: 0.4917\n",
      "Epoch 174/600\n",
      "1960/1960 [==============================] - 1s 708us/sample - loss: 0.0992 - accuracy: 0.9750 - val_loss: 2.1748 - val_accuracy: 0.4940\n",
      "Epoch 175/600\n",
      "1960/1960 [==============================] - 1s 690us/sample - loss: 0.1078 - accuracy: 0.9735 - val_loss: 2.1550 - val_accuracy: 0.4952\n",
      "Epoch 176/600\n",
      "1960/1960 [==============================] - 1s 729us/sample - loss: 0.0974 - accuracy: 0.9735 - val_loss: 2.1355 - val_accuracy: 0.4976\n",
      "Epoch 177/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.1004 - accuracy: 0.9689 - val_loss: 2.1165 - val_accuracy: 0.5000\n",
      "Epoch 178/600\n",
      "1960/1960 [==============================] - 1s 748us/sample - loss: 0.0941 - accuracy: 0.9760 - val_loss: 2.0975 - val_accuracy: 0.5036\n",
      "Epoch 179/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.1056 - accuracy: 0.9730 - val_loss: 2.0781 - val_accuracy: 0.5083\n",
      "Epoch 180/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.1088 - accuracy: 0.9679 - val_loss: 2.0599 - val_accuracy: 0.5131\n",
      "Epoch 181/600\n",
      "1960/1960 [==============================] - 1s 705us/sample - loss: 0.0930 - accuracy: 0.9740 - val_loss: 2.0404 - val_accuracy: 0.5179\n",
      "Epoch 182/600\n",
      "1960/1960 [==============================] - 1s 711us/sample - loss: 0.1178 - accuracy: 0.9694 - val_loss: 2.0218 - val_accuracy: 0.5250\n",
      "Epoch 183/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.1113 - accuracy: 0.9694 - val_loss: 2.0028 - val_accuracy: 0.5298\n",
      "Epoch 184/600\n",
      "1960/1960 [==============================] - 1s 721us/sample - loss: 0.0993 - accuracy: 0.9719 - val_loss: 1.9842 - val_accuracy: 0.5321\n",
      "Epoch 185/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.1093 - accuracy: 0.9704 - val_loss: 1.9658 - val_accuracy: 0.5357\n",
      "Epoch 186/600\n",
      "1960/1960 [==============================] - 1s 696us/sample - loss: 0.1052 - accuracy: 0.9704 - val_loss: 1.9474 - val_accuracy: 0.5381\n",
      "Epoch 187/600\n",
      "1960/1960 [==============================] - 1s 722us/sample - loss: 0.1079 - accuracy: 0.9699 - val_loss: 1.9293 - val_accuracy: 0.5405\n",
      "Epoch 188/600\n",
      "1960/1960 [==============================] - 1s 762us/sample - loss: 0.1091 - accuracy: 0.9730 - val_loss: 1.9114 - val_accuracy: 0.5417\n",
      "Epoch 189/600\n",
      "1960/1960 [==============================] - 1s 760us/sample - loss: 0.1154 - accuracy: 0.9704 - val_loss: 1.8935 - val_accuracy: 0.5429\n",
      "Epoch 190/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.0983 - accuracy: 0.9740 - val_loss: 1.8761 - val_accuracy: 0.5452\n",
      "Epoch 191/600\n",
      "1960/1960 [==============================] - 1s 741us/sample - loss: 0.0983 - accuracy: 0.9714 - val_loss: 1.8582 - val_accuracy: 0.5536\n",
      "Epoch 192/600\n",
      "1960/1960 [==============================] - 1s 745us/sample - loss: 0.0932 - accuracy: 0.9745 - val_loss: 1.8412 - val_accuracy: 0.5548\n",
      "Epoch 193/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.1189 - accuracy: 0.9673 - val_loss: 1.8236 - val_accuracy: 0.5583\n",
      "Epoch 194/600\n",
      "1960/1960 [==============================] - 1s 688us/sample - loss: 0.0996 - accuracy: 0.9719 - val_loss: 1.8067 - val_accuracy: 0.5619\n",
      "Epoch 195/600\n",
      "1960/1960 [==============================] - 1s 702us/sample - loss: 0.1063 - accuracy: 0.9658 - val_loss: 1.7899 - val_accuracy: 0.5667\n",
      "Epoch 196/600\n",
      "1960/1960 [==============================] - 1s 698us/sample - loss: 0.0956 - accuracy: 0.9745 - val_loss: 1.7723 - val_accuracy: 0.5750\n",
      "Epoch 197/600\n",
      "1960/1960 [==============================] - 1s 709us/sample - loss: 0.1103 - accuracy: 0.9679 - val_loss: 1.7554 - val_accuracy: 0.5798\n",
      "Epoch 198/600\n",
      "1960/1960 [==============================] - 1s 735us/sample - loss: 0.0903 - accuracy: 0.9760 - val_loss: 1.7384 - val_accuracy: 0.5821\n",
      "Epoch 199/600\n",
      "1960/1960 [==============================] - 2s 808us/sample - loss: 0.1001 - accuracy: 0.9679 - val_loss: 1.7219 - val_accuracy: 0.5833\n",
      "Epoch 200/600\n",
      "1960/1960 [==============================] - 2s 765us/sample - loss: 0.1145 - accuracy: 0.9699 - val_loss: 1.7053 - val_accuracy: 0.5905\n",
      "Epoch 201/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1164 - accuracy: 0.9679 - val_loss: 1.6887 - val_accuracy: 0.5952\n",
      "Epoch 202/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.1009 - accuracy: 0.9699 - val_loss: 1.6724 - val_accuracy: 0.5964\n",
      "Epoch 203/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1086 - accuracy: 0.9689 - val_loss: 1.6560 - val_accuracy: 0.6012\n",
      "Epoch 204/600\n",
      "1960/1960 [==============================] - 1s 722us/sample - loss: 0.1066 - accuracy: 0.9689 - val_loss: 1.6400 - val_accuracy: 0.6060\n",
      "Epoch 205/600\n",
      "1960/1960 [==============================] - 1s 708us/sample - loss: 0.1161 - accuracy: 0.9673 - val_loss: 1.6242 - val_accuracy: 0.6071\n",
      "Epoch 206/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.0952 - accuracy: 0.9755 - val_loss: 1.6088 - val_accuracy: 0.6119\n",
      "Epoch 207/600\n",
      "1960/1960 [==============================] - 1s 736us/sample - loss: 0.1064 - accuracy: 0.9658 - val_loss: 1.5934 - val_accuracy: 0.6143\n",
      "Epoch 208/600\n",
      "1960/1960 [==============================] - 1s 712us/sample - loss: 0.1049 - accuracy: 0.9694 - val_loss: 1.5783 - val_accuracy: 0.6214\n",
      "Epoch 209/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.0967 - accuracy: 0.9714 - val_loss: 1.5636 - val_accuracy: 0.6226\n",
      "Epoch 210/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.1097 - accuracy: 0.9709 - val_loss: 1.5489 - val_accuracy: 0.6262\n",
      "Epoch 211/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.1043 - accuracy: 0.9740 - val_loss: 1.5338 - val_accuracy: 0.6321\n",
      "Epoch 212/600\n",
      "1960/1960 [==============================] - 1s 743us/sample - loss: 0.0972 - accuracy: 0.9730 - val_loss: 1.5192 - val_accuracy: 0.6369\n",
      "Epoch 213/600\n",
      "1960/1960 [==============================] - 2s 768us/sample - loss: 0.1049 - accuracy: 0.9699 - val_loss: 1.5052 - val_accuracy: 0.6429\n",
      "Epoch 214/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1134 - accuracy: 0.9648 - val_loss: 1.4912 - val_accuracy: 0.6452\n",
      "Epoch 215/600\n",
      "1960/1960 [==============================] - 1s 764us/sample - loss: 0.1018 - accuracy: 0.9735 - val_loss: 1.4774 - val_accuracy: 0.6476\n",
      "Epoch 216/600\n",
      "1960/1960 [==============================] - 1s 715us/sample - loss: 0.1095 - accuracy: 0.9709 - val_loss: 1.4636 - val_accuracy: 0.6512\n",
      "Epoch 217/600\n",
      "1960/1960 [==============================] - 1s 721us/sample - loss: 0.0973 - accuracy: 0.9755 - val_loss: 1.4497 - val_accuracy: 0.6524\n",
      "Epoch 218/600\n",
      "1960/1960 [==============================] - 1s 723us/sample - loss: 0.1040 - accuracy: 0.9709 - val_loss: 1.4360 - val_accuracy: 0.6548\n",
      "Epoch 219/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 1s 726us/sample - loss: 0.1013 - accuracy: 0.9745 - val_loss: 1.4223 - val_accuracy: 0.6583\n",
      "Epoch 220/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1195 - accuracy: 0.9607 - val_loss: 1.4088 - val_accuracy: 0.6631\n",
      "Epoch 221/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.0959 - accuracy: 0.9730 - val_loss: 1.3953 - val_accuracy: 0.6702\n",
      "Epoch 222/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1035 - accuracy: 0.9709 - val_loss: 1.3825 - val_accuracy: 0.6750\n",
      "Epoch 223/600\n",
      "1960/1960 [==============================] - 1s 754us/sample - loss: 0.0884 - accuracy: 0.9776 - val_loss: 1.3697 - val_accuracy: 0.6750\n",
      "Epoch 224/600\n",
      "1960/1960 [==============================] - 1s 743us/sample - loss: 0.1083 - accuracy: 0.9684 - val_loss: 1.3572 - val_accuracy: 0.6774\n",
      "Epoch 225/600\n",
      "1960/1960 [==============================] - 1s 720us/sample - loss: 0.0991 - accuracy: 0.9679 - val_loss: 1.3444 - val_accuracy: 0.6774\n",
      "Epoch 226/600\n",
      "1960/1960 [==============================] - 1s 735us/sample - loss: 0.0952 - accuracy: 0.9750 - val_loss: 1.3320 - val_accuracy: 0.6821\n",
      "Epoch 227/600\n",
      "1960/1960 [==============================] - 1s 706us/sample - loss: 0.1074 - accuracy: 0.9689 - val_loss: 1.3199 - val_accuracy: 0.6857\n",
      "Epoch 228/600\n",
      "1960/1960 [==============================] - 1s 702us/sample - loss: 0.1022 - accuracy: 0.9770 - val_loss: 1.3081 - val_accuracy: 0.6893\n",
      "Epoch 229/600\n",
      "1960/1960 [==============================] - 1s 710us/sample - loss: 0.0899 - accuracy: 0.9776 - val_loss: 1.2961 - val_accuracy: 0.6893\n",
      "Epoch 230/600\n",
      "1960/1960 [==============================] - 1s 736us/sample - loss: 0.1019 - accuracy: 0.9699 - val_loss: 1.2837 - val_accuracy: 0.6917\n",
      "Epoch 231/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.0924 - accuracy: 0.9740 - val_loss: 1.2719 - val_accuracy: 0.7000\n",
      "Epoch 232/600\n",
      "1960/1960 [==============================] - 1s 736us/sample - loss: 0.1106 - accuracy: 0.9714 - val_loss: 1.2604 - val_accuracy: 0.7012\n",
      "Epoch 233/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1001 - accuracy: 0.9704 - val_loss: 1.2492 - val_accuracy: 0.7012\n",
      "Epoch 234/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.0932 - accuracy: 0.9765 - val_loss: 1.2381 - val_accuracy: 0.7036\n",
      "Epoch 235/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.1011 - accuracy: 0.9750 - val_loss: 1.2268 - val_accuracy: 0.7048\n",
      "Epoch 236/600\n",
      "1960/1960 [==============================] - 1s 717us/sample - loss: 0.1246 - accuracy: 0.9638 - val_loss: 1.2156 - val_accuracy: 0.7131\n",
      "Epoch 237/600\n",
      "1960/1960 [==============================] - 1s 719us/sample - loss: 0.0928 - accuracy: 0.9745 - val_loss: 1.2047 - val_accuracy: 0.7155\n",
      "Epoch 238/600\n",
      "1960/1960 [==============================] - 1s 724us/sample - loss: 0.1042 - accuracy: 0.9750 - val_loss: 1.1939 - val_accuracy: 0.7190\n",
      "Epoch 239/600\n",
      "1960/1960 [==============================] - 1s 700us/sample - loss: 0.1128 - accuracy: 0.9653 - val_loss: 1.1828 - val_accuracy: 0.7214\n",
      "Epoch 240/600\n",
      "1960/1960 [==============================] - 1s 734us/sample - loss: 0.0984 - accuracy: 0.9699 - val_loss: 1.1721 - val_accuracy: 0.7214\n",
      "Epoch 241/600\n",
      "1960/1960 [==============================] - 1s 716us/sample - loss: 0.0955 - accuracy: 0.9714 - val_loss: 1.1615 - val_accuracy: 0.7238\n",
      "Epoch 242/600\n",
      "1960/1960 [==============================] - 1s 759us/sample - loss: 0.0969 - accuracy: 0.9730 - val_loss: 1.1511 - val_accuracy: 0.7238\n",
      "Epoch 243/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1199 - accuracy: 0.9668 - val_loss: 1.1404 - val_accuracy: 0.7262\n",
      "Epoch 244/600\n",
      "1960/1960 [==============================] - 2s 922us/sample - loss: 0.1095 - accuracy: 0.9724 - val_loss: 1.1300 - val_accuracy: 0.7274\n",
      "Epoch 245/600\n",
      "1960/1960 [==============================] - 2s 908us/sample - loss: 0.1009 - accuracy: 0.9699 - val_loss: 1.1197 - val_accuracy: 0.7298\n",
      "Epoch 246/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.1078 - accuracy: 0.9673 - val_loss: 1.1096 - val_accuracy: 0.7310\n",
      "Epoch 247/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.1179 - accuracy: 0.9694 - val_loss: 1.0999 - val_accuracy: 0.7333\n",
      "Epoch 248/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.1065 - accuracy: 0.9730 - val_loss: 1.0903 - val_accuracy: 0.7357\n",
      "Epoch 249/600\n",
      "1960/1960 [==============================] - 2s 905us/sample - loss: 0.1142 - accuracy: 0.9689 - val_loss: 1.0808 - val_accuracy: 0.7369\n",
      "Epoch 250/600\n",
      "1960/1960 [==============================] - 2s 915us/sample - loss: 0.0927 - accuracy: 0.9745 - val_loss: 1.0714 - val_accuracy: 0.7369\n",
      "Epoch 251/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.1200 - accuracy: 0.9633 - val_loss: 1.0618 - val_accuracy: 0.7381\n",
      "Epoch 252/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.0920 - accuracy: 0.9750 - val_loss: 1.0525 - val_accuracy: 0.7405\n",
      "Epoch 253/600\n",
      "1960/1960 [==============================] - 2s 949us/sample - loss: 0.1139 - accuracy: 0.9724 - val_loss: 1.0435 - val_accuracy: 0.7440\n",
      "Epoch 254/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1089 - accuracy: 0.9679 - val_loss: 1.0349 - val_accuracy: 0.7452\n",
      "Epoch 255/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.1041 - accuracy: 0.9694 - val_loss: 1.0262 - val_accuracy: 0.7476\n",
      "Epoch 256/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.0842 - accuracy: 0.9781 - val_loss: 1.0175 - val_accuracy: 0.7500\n",
      "Epoch 257/600\n",
      "1960/1960 [==============================] - 1s 744us/sample - loss: 0.1069 - accuracy: 0.9709 - val_loss: 1.0088 - val_accuracy: 0.7500\n",
      "Epoch 258/600\n",
      "1960/1960 [==============================] - 2s 876us/sample - loss: 0.1096 - accuracy: 0.9689 - val_loss: 1.0003 - val_accuracy: 0.7524\n",
      "Epoch 259/600\n",
      "1960/1960 [==============================] - 2s 832us/sample - loss: 0.1120 - accuracy: 0.9679 - val_loss: 0.9919 - val_accuracy: 0.7548\n",
      "Epoch 260/600\n",
      "1960/1960 [==============================] - 2s 919us/sample - loss: 0.1105 - accuracy: 0.9643 - val_loss: 0.9833 - val_accuracy: 0.7571\n",
      "Epoch 261/600\n",
      "1960/1960 [==============================] - 2s 924us/sample - loss: 0.1101 - accuracy: 0.9668 - val_loss: 0.9751 - val_accuracy: 0.7583\n",
      "Epoch 262/600\n",
      "1960/1960 [==============================] - 2s 886us/sample - loss: 0.1129 - accuracy: 0.9663 - val_loss: 0.9663 - val_accuracy: 0.7643\n",
      "Epoch 263/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.1148 - accuracy: 0.9684 - val_loss: 0.9577 - val_accuracy: 0.7702\n",
      "Epoch 264/600\n",
      "1960/1960 [==============================] - 1s 754us/sample - loss: 0.0977 - accuracy: 0.9735 - val_loss: 0.9492 - val_accuracy: 0.7714\n",
      "Epoch 265/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1023 - accuracy: 0.9689 - val_loss: 0.9408 - val_accuracy: 0.7726\n",
      "Epoch 266/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.1044 - accuracy: 0.9719 - val_loss: 0.9325 - val_accuracy: 0.7738\n",
      "Epoch 267/600\n",
      "1960/1960 [==============================] - 1s 713us/sample - loss: 0.0987 - accuracy: 0.9694 - val_loss: 0.9243 - val_accuracy: 0.7750\n",
      "Epoch 268/600\n",
      "1960/1960 [==============================] - 1s 745us/sample - loss: 0.1101 - accuracy: 0.9699 - val_loss: 0.9161 - val_accuracy: 0.7786\n",
      "Epoch 269/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.9081 - val_accuracy: 0.7810\n",
      "Epoch 270/600\n",
      "1960/1960 [==============================] - 1s 727us/sample - loss: 0.1079 - accuracy: 0.9679 - val_loss: 0.8999 - val_accuracy: 0.7845\n",
      "Epoch 271/600\n",
      "1960/1960 [==============================] - 1s 707us/sample - loss: 0.1021 - accuracy: 0.9673 - val_loss: 0.8923 - val_accuracy: 0.7857\n",
      "Epoch 272/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1200 - accuracy: 0.9612 - val_loss: 0.8845 - val_accuracy: 0.7869\n",
      "Epoch 273/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.0986 - accuracy: 0.9724 - val_loss: 0.8767 - val_accuracy: 0.7869\n",
      "Epoch 274/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.1045 - accuracy: 0.9719 - val_loss: 0.8691 - val_accuracy: 0.7881\n",
      "Epoch 275/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1061 - accuracy: 0.9694 - val_loss: 0.8617 - val_accuracy: 0.7893\n",
      "Epoch 276/600\n",
      "1960/1960 [==============================] - 1s 730us/sample - loss: 0.1095 - accuracy: 0.9673 - val_loss: 0.8542 - val_accuracy: 0.7893\n",
      "Epoch 277/600\n",
      "1960/1960 [==============================] - 1s 717us/sample - loss: 0.1166 - accuracy: 0.9643 - val_loss: 0.8468 - val_accuracy: 0.7893\n",
      "Epoch 278/600\n",
      "1960/1960 [==============================] - 1s 688us/sample - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.8395 - val_accuracy: 0.7893\n",
      "Epoch 279/600\n",
      "1960/1960 [==============================] - 1s 689us/sample - loss: 0.1111 - accuracy: 0.9663 - val_loss: 0.8322 - val_accuracy: 0.7917\n",
      "Epoch 280/600\n",
      "1960/1960 [==============================] - 1s 698us/sample - loss: 0.1037 - accuracy: 0.9694 - val_loss: 0.8249 - val_accuracy: 0.7929\n",
      "Epoch 281/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.0844 - accuracy: 0.9781 - val_loss: 0.8177 - val_accuracy: 0.7940\n",
      "Epoch 282/600\n",
      "1960/1960 [==============================] - 1s 709us/sample - loss: 0.1053 - accuracy: 0.9694 - val_loss: 0.8106 - val_accuracy: 0.7940\n",
      "Epoch 283/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.1019 - accuracy: 0.9735 - val_loss: 0.8037 - val_accuracy: 0.8000\n",
      "Epoch 284/600\n",
      "1960/1960 [==============================] - 1s 733us/sample - loss: 0.0993 - accuracy: 0.9724 - val_loss: 0.7968 - val_accuracy: 0.8000\n",
      "Epoch 285/600\n",
      "1960/1960 [==============================] - 1s 748us/sample - loss: 0.1025 - accuracy: 0.9745 - val_loss: 0.7898 - val_accuracy: 0.8012\n",
      "Epoch 286/600\n",
      "1960/1960 [==============================] - 1s 732us/sample - loss: 0.0979 - accuracy: 0.9735 - val_loss: 0.7830 - val_accuracy: 0.8000\n",
      "Epoch 287/600\n",
      "1960/1960 [==============================] - 1s 741us/sample - loss: 0.1067 - accuracy: 0.9684 - val_loss: 0.7763 - val_accuracy: 0.8024\n",
      "Epoch 288/600\n",
      "1960/1960 [==============================] - 1s 724us/sample - loss: 0.0998 - accuracy: 0.9765 - val_loss: 0.7695 - val_accuracy: 0.8036\n",
      "Epoch 289/600\n",
      "1960/1960 [==============================] - 1s 729us/sample - loss: 0.1011 - accuracy: 0.9745 - val_loss: 0.7629 - val_accuracy: 0.8036\n",
      "Epoch 290/600\n",
      "1960/1960 [==============================] - 1s 691us/sample - loss: 0.1045 - accuracy: 0.9689 - val_loss: 0.7563 - val_accuracy: 0.8048\n",
      "Epoch 291/600\n",
      "1960/1960 [==============================] - 1s 699us/sample - loss: 0.0963 - accuracy: 0.9724 - val_loss: 0.7497 - val_accuracy: 0.8048\n",
      "Epoch 292/600\n",
      "1960/1960 [==============================] - 1s 708us/sample - loss: 0.1072 - accuracy: 0.9684 - val_loss: 0.7433 - val_accuracy: 0.8048\n",
      "Epoch 293/600\n",
      "1960/1960 [==============================] - 1s 705us/sample - loss: 0.1022 - accuracy: 0.9719 - val_loss: 0.7370 - val_accuracy: 0.8048\n",
      "Epoch 294/600\n",
      "1960/1960 [==============================] - 1s 723us/sample - loss: 0.0879 - accuracy: 0.9724 - val_loss: 0.7309 - val_accuracy: 0.8060\n",
      "Epoch 295/600\n",
      "1960/1960 [==============================] - 1s 750us/sample - loss: 0.1016 - accuracy: 0.9745 - val_loss: 0.7246 - val_accuracy: 0.8071\n",
      "Epoch 296/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.0886 - accuracy: 0.9730 - val_loss: 0.7184 - val_accuracy: 0.8071\n",
      "Epoch 297/600\n",
      "1960/1960 [==============================] - 1s 751us/sample - loss: 0.1095 - accuracy: 0.9673 - val_loss: 0.7120 - val_accuracy: 0.8071\n",
      "Epoch 298/600\n",
      "1960/1960 [==============================] - 2s 864us/sample - loss: 0.1060 - accuracy: 0.9689 - val_loss: 0.7056 - val_accuracy: 0.8071\n",
      "Epoch 299/600\n",
      "1960/1960 [==============================] - 2s 863us/sample - loss: 0.1000 - accuracy: 0.9730 - val_loss: 0.6993 - val_accuracy: 0.8071\n",
      "Epoch 300/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0930 - accuracy: 0.9730 - val_loss: 0.6931 - val_accuracy: 0.8119\n",
      "Epoch 301/600\n",
      "1960/1960 [==============================] - 1s 692us/sample - loss: 0.1050 - accuracy: 0.9714 - val_loss: 0.6868 - val_accuracy: 0.8131\n",
      "Epoch 302/600\n",
      "1960/1960 [==============================] - 1s 691us/sample - loss: 0.0981 - accuracy: 0.9724 - val_loss: 0.6806 - val_accuracy: 0.8143\n",
      "Epoch 303/600\n",
      "1960/1960 [==============================] - 1s 730us/sample - loss: 0.1066 - accuracy: 0.9689 - val_loss: 0.6743 - val_accuracy: 0.8167\n",
      "Epoch 304/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.0884 - accuracy: 0.9755 - val_loss: 0.6681 - val_accuracy: 0.8190\n",
      "Epoch 305/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0960 - accuracy: 0.9730 - val_loss: 0.6620 - val_accuracy: 0.8226\n",
      "Epoch 306/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0963 - accuracy: 0.9699 - val_loss: 0.6560 - val_accuracy: 0.8238\n",
      "Epoch 307/600\n",
      "1960/1960 [==============================] - 2s 957us/sample - loss: 0.1116 - accuracy: 0.9668 - val_loss: 0.6502 - val_accuracy: 0.8238\n",
      "Epoch 308/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0963 - accuracy: 0.9781 - val_loss: 0.6445 - val_accuracy: 0.8238\n",
      "Epoch 309/600\n",
      "1960/1960 [==============================] - 2s 817us/sample - loss: 0.1020 - accuracy: 0.9719 - val_loss: 0.6388 - val_accuracy: 0.8274\n",
      "Epoch 310/600\n",
      "1960/1960 [==============================] - 2s 961us/sample - loss: 0.1146 - accuracy: 0.9648 - val_loss: 0.6331 - val_accuracy: 0.8310\n",
      "Epoch 311/600\n",
      "1960/1960 [==============================] - 2s 793us/sample - loss: 0.0938 - accuracy: 0.9755 - val_loss: 0.6274 - val_accuracy: 0.8321\n",
      "Epoch 312/600\n",
      "1960/1960 [==============================] - 2s 849us/sample - loss: 0.0964 - accuracy: 0.9740 - val_loss: 0.6218 - val_accuracy: 0.8333\n",
      "Epoch 313/600\n",
      "1960/1960 [==============================] - 2s 988us/sample - loss: 0.0950 - accuracy: 0.9694 - val_loss: 0.6164 - val_accuracy: 0.8357\n",
      "Epoch 314/600\n",
      "1960/1960 [==============================] - 2s 821us/sample - loss: 0.1142 - accuracy: 0.9689 - val_loss: 0.6109 - val_accuracy: 0.8381\n",
      "Epoch 315/600\n",
      "1960/1960 [==============================] - 2s 849us/sample - loss: 0.1187 - accuracy: 0.9679 - val_loss: 0.6057 - val_accuracy: 0.8381\n",
      "Epoch 316/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.1000 - accuracy: 0.9709 - val_loss: 0.6005 - val_accuracy: 0.8381\n",
      "Epoch 317/600\n",
      "1960/1960 [==============================] - 2s 891us/sample - loss: 0.0869 - accuracy: 0.9745 - val_loss: 0.5953 - val_accuracy: 0.8405\n",
      "Epoch 318/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0997 - accuracy: 0.9735 - val_loss: 0.5901 - val_accuracy: 0.8417\n",
      "Epoch 319/600\n",
      "1960/1960 [==============================] - 1s 736us/sample - loss: 0.0930 - accuracy: 0.9765 - val_loss: 0.5851 - val_accuracy: 0.8440\n",
      "Epoch 320/600\n",
      "1960/1960 [==============================] - 1s 724us/sample - loss: 0.0916 - accuracy: 0.9781 - val_loss: 0.5803 - val_accuracy: 0.8452\n",
      "Epoch 321/600\n",
      "1960/1960 [==============================] - 1s 733us/sample - loss: 0.1106 - accuracy: 0.9684 - val_loss: 0.5754 - val_accuracy: 0.8488\n",
      "Epoch 322/600\n",
      "1960/1960 [==============================] - 1s 703us/sample - loss: 0.0927 - accuracy: 0.9745 - val_loss: 0.5706 - val_accuracy: 0.8500\n",
      "Epoch 323/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.5659 - val_accuracy: 0.8524\n",
      "Epoch 324/600\n",
      "1960/1960 [==============================] - 2s 896us/sample - loss: 0.1039 - accuracy: 0.9730 - val_loss: 0.5612 - val_accuracy: 0.8524\n",
      "Epoch 325/600\n",
      "1960/1960 [==============================] - 2s 913us/sample - loss: 0.0950 - accuracy: 0.9770 - val_loss: 0.5564 - val_accuracy: 0.8524\n",
      "Epoch 326/600\n",
      "1960/1960 [==============================] - 2s 947us/sample - loss: 0.1133 - accuracy: 0.9638 - val_loss: 0.5516 - val_accuracy: 0.8524\n",
      "Epoch 327/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1129 - accuracy: 0.9648 - val_loss: 0.5469 - val_accuracy: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.5422 - val_accuracy: 0.8536\n",
      "Epoch 329/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.0974 - accuracy: 0.9724 - val_loss: 0.5377 - val_accuracy: 0.8560\n",
      "Epoch 330/600\n",
      "1960/1960 [==============================] - 2s 797us/sample - loss: 0.1003 - accuracy: 0.9724 - val_loss: 0.5332 - val_accuracy: 0.8560\n",
      "Epoch 331/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.1000 - accuracy: 0.9740 - val_loss: 0.5289 - val_accuracy: 0.8560\n",
      "Epoch 332/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0962 - accuracy: 0.9755 - val_loss: 0.5246 - val_accuracy: 0.8571\n",
      "Epoch 333/600\n",
      "1960/1960 [==============================] - 2s 990us/sample - loss: 0.1081 - accuracy: 0.9679 - val_loss: 0.5201 - val_accuracy: 0.8571\n",
      "Epoch 334/600\n",
      "1960/1960 [==============================] - 2s 973us/sample - loss: 0.0850 - accuracy: 0.9770 - val_loss: 0.5160 - val_accuracy: 0.8595\n",
      "Epoch 335/600\n",
      "1960/1960 [==============================] - 2s 989us/sample - loss: 0.0978 - accuracy: 0.9719 - val_loss: 0.5116 - val_accuracy: 0.8631\n",
      "Epoch 336/600\n",
      "1960/1960 [==============================] - 2s 913us/sample - loss: 0.0896 - accuracy: 0.9765 - val_loss: 0.5074 - val_accuracy: 0.8631\n",
      "Epoch 337/600\n",
      "1960/1960 [==============================] - 2s 892us/sample - loss: 0.0971 - accuracy: 0.9724 - val_loss: 0.5032 - val_accuracy: 0.8631\n",
      "Epoch 338/600\n",
      "1960/1960 [==============================] - 2s 863us/sample - loss: 0.1034 - accuracy: 0.9709 - val_loss: 0.4989 - val_accuracy: 0.8643\n",
      "Epoch 339/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.1027 - accuracy: 0.9745 - val_loss: 0.4949 - val_accuracy: 0.8643\n",
      "Epoch 340/600\n",
      "1960/1960 [==============================] - 2s 879us/sample - loss: 0.1076 - accuracy: 0.9658 - val_loss: 0.4909 - val_accuracy: 0.8643\n",
      "Epoch 341/600\n",
      "1960/1960 [==============================] - 2s 860us/sample - loss: 0.1088 - accuracy: 0.9663 - val_loss: 0.4871 - val_accuracy: 0.8667\n",
      "Epoch 342/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.4832 - val_accuracy: 0.8679\n",
      "Epoch 343/600\n",
      "1960/1960 [==============================] - 2s 899us/sample - loss: 0.1160 - accuracy: 0.9673 - val_loss: 0.4794 - val_accuracy: 0.8690\n",
      "Epoch 344/600\n",
      "1960/1960 [==============================] - 2s 892us/sample - loss: 0.1071 - accuracy: 0.9689 - val_loss: 0.4755 - val_accuracy: 0.8702\n",
      "Epoch 345/600\n",
      "1960/1960 [==============================] - 2s 869us/sample - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.4716 - val_accuracy: 0.8702\n",
      "Epoch 346/600\n",
      "1960/1960 [==============================] - 2s 939us/sample - loss: 0.1091 - accuracy: 0.9673 - val_loss: 0.4679 - val_accuracy: 0.8702\n",
      "Epoch 347/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.1123 - accuracy: 0.9719 - val_loss: 0.4643 - val_accuracy: 0.8738\n",
      "Epoch 348/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.1060 - accuracy: 0.9724 - val_loss: 0.4603 - val_accuracy: 0.8738\n",
      "Epoch 349/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.0880 - accuracy: 0.9760 - val_loss: 0.4569 - val_accuracy: 0.8726\n",
      "Epoch 350/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.1056 - accuracy: 0.9663 - val_loss: 0.4534 - val_accuracy: 0.8738\n",
      "Epoch 351/600\n",
      "1960/1960 [==============================] - 2s 878us/sample - loss: 0.1106 - accuracy: 0.9658 - val_loss: 0.4501 - val_accuracy: 0.8738\n",
      "Epoch 352/600\n",
      "1960/1960 [==============================] - 2s 939us/sample - loss: 0.1072 - accuracy: 0.9709 - val_loss: 0.4467 - val_accuracy: 0.8738\n",
      "Epoch 353/600\n",
      "1960/1960 [==============================] - 2s 986us/sample - loss: 0.1102 - accuracy: 0.9694 - val_loss: 0.4434 - val_accuracy: 0.8750\n",
      "Epoch 354/600\n",
      "1960/1960 [==============================] - 2s 962us/sample - loss: 0.0982 - accuracy: 0.9730 - val_loss: 0.4400 - val_accuracy: 0.8750\n",
      "Epoch 355/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0972 - accuracy: 0.9755 - val_loss: 0.4367 - val_accuracy: 0.8750\n",
      "Epoch 356/600\n",
      "1960/1960 [==============================] - 2s 920us/sample - loss: 0.1075 - accuracy: 0.9714 - val_loss: 0.4335 - val_accuracy: 0.8750\n",
      "Epoch 357/600\n",
      "1960/1960 [==============================] - 2s 918us/sample - loss: 0.1015 - accuracy: 0.9694 - val_loss: 0.4302 - val_accuracy: 0.8774\n",
      "Epoch 358/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.4270 - val_accuracy: 0.8786\n",
      "Epoch 359/600\n",
      "1960/1960 [==============================] - 2s 922us/sample - loss: 0.1137 - accuracy: 0.9684 - val_loss: 0.4238 - val_accuracy: 0.8798\n",
      "Epoch 360/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1044 - accuracy: 0.9673 - val_loss: 0.4207 - val_accuracy: 0.8810\n",
      "Epoch 361/600\n",
      "1960/1960 [==============================] - 2s 939us/sample - loss: 0.1201 - accuracy: 0.9673 - val_loss: 0.4176 - val_accuracy: 0.8821\n",
      "Epoch 362/600\n",
      "1960/1960 [==============================] - 2s 932us/sample - loss: 0.1102 - accuracy: 0.9694 - val_loss: 0.4145 - val_accuracy: 0.8821\n",
      "Epoch 363/600\n",
      "1960/1960 [==============================] - 2s 961us/sample - loss: 0.0959 - accuracy: 0.9740 - val_loss: 0.4115 - val_accuracy: 0.8821\n",
      "Epoch 364/600\n",
      "1960/1960 [==============================] - 2s 953us/sample - loss: 0.1000 - accuracy: 0.9724 - val_loss: 0.4086 - val_accuracy: 0.8845\n",
      "Epoch 365/600\n",
      "1960/1960 [==============================] - 2s 929us/sample - loss: 0.1029 - accuracy: 0.9755 - val_loss: 0.4058 - val_accuracy: 0.8869\n",
      "Epoch 366/600\n",
      "1960/1960 [==============================] - 2s 909us/sample - loss: 0.0999 - accuracy: 0.9724 - val_loss: 0.4029 - val_accuracy: 0.8881\n",
      "Epoch 367/600\n",
      "1960/1960 [==============================] - 2s 968us/sample - loss: 0.0896 - accuracy: 0.9765 - val_loss: 0.4001 - val_accuracy: 0.8881\n",
      "Epoch 368/600\n",
      "1960/1960 [==============================] - 2s 969us/sample - loss: 0.1080 - accuracy: 0.9689 - val_loss: 0.3973 - val_accuracy: 0.8905\n",
      "Epoch 369/600\n",
      "1960/1960 [==============================] - 2s 967us/sample - loss: 0.0933 - accuracy: 0.9709 - val_loss: 0.3946 - val_accuracy: 0.8905\n",
      "Epoch 370/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1021 - accuracy: 0.9709 - val_loss: 0.3920 - val_accuracy: 0.8917\n",
      "Epoch 371/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1020 - accuracy: 0.9684 - val_loss: 0.3893 - val_accuracy: 0.8917\n",
      "Epoch 372/600\n",
      "1960/1960 [==============================] - 2s 952us/sample - loss: 0.1015 - accuracy: 0.9673 - val_loss: 0.3867 - val_accuracy: 0.8929\n",
      "Epoch 373/600\n",
      "1960/1960 [==============================] - 2s 963us/sample - loss: 0.1003 - accuracy: 0.9704 - val_loss: 0.3842 - val_accuracy: 0.8929\n",
      "Epoch 374/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1071 - accuracy: 0.9679 - val_loss: 0.3817 - val_accuracy: 0.8952\n",
      "Epoch 375/600\n",
      "1960/1960 [==============================] - 2s 947us/sample - loss: 0.1002 - accuracy: 0.9750 - val_loss: 0.3792 - val_accuracy: 0.8952\n",
      "Epoch 376/600\n",
      "1960/1960 [==============================] - 2s 952us/sample - loss: 0.1009 - accuracy: 0.9719 - val_loss: 0.3769 - val_accuracy: 0.8952\n",
      "Epoch 377/600\n",
      "1960/1960 [==============================] - 2s 949us/sample - loss: 0.0917 - accuracy: 0.9770 - val_loss: 0.3744 - val_accuracy: 0.8952\n",
      "Epoch 378/600\n",
      "1960/1960 [==============================] - 2s 871us/sample - loss: 0.1027 - accuracy: 0.9755 - val_loss: 0.3722 - val_accuracy: 0.8964\n",
      "Epoch 379/600\n",
      "1960/1960 [==============================] - 2s 881us/sample - loss: 0.0973 - accuracy: 0.9770 - val_loss: 0.3700 - val_accuracy: 0.8976\n",
      "Epoch 380/600\n",
      "1960/1960 [==============================] - 2s 922us/sample - loss: 0.1020 - accuracy: 0.9673 - val_loss: 0.3678 - val_accuracy: 0.8976\n",
      "Epoch 381/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0952 - accuracy: 0.9735 - val_loss: 0.3655 - val_accuracy: 0.8976\n",
      "Epoch 382/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1048 - accuracy: 0.9730 - val_loss: 0.3633 - val_accuracy: 0.8976\n",
      "Epoch 383/600\n",
      "1960/1960 [==============================] - 2s 975us/sample - loss: 0.1010 - accuracy: 0.9745 - val_loss: 0.3612 - val_accuracy: 0.8988\n",
      "Epoch 384/600\n",
      "1960/1960 [==============================] - 2s 945us/sample - loss: 0.0917 - accuracy: 0.9740 - val_loss: 0.3592 - val_accuracy: 0.9000\n",
      "Epoch 385/600\n",
      "1960/1960 [==============================] - 2s 918us/sample - loss: 0.0977 - accuracy: 0.9699 - val_loss: 0.3571 - val_accuracy: 0.9012\n",
      "Epoch 386/600\n",
      "1960/1960 [==============================] - 2s 948us/sample - loss: 0.1035 - accuracy: 0.9694 - val_loss: 0.3551 - val_accuracy: 0.9012\n",
      "Epoch 387/600\n",
      "1960/1960 [==============================] - 2s 929us/sample - loss: 0.1004 - accuracy: 0.9745 - val_loss: 0.3531 - val_accuracy: 0.9000\n",
      "Epoch 388/600\n",
      "1960/1960 [==============================] - 2s 821us/sample - loss: 0.1151 - accuracy: 0.9628 - val_loss: 0.3511 - val_accuracy: 0.9024\n",
      "Epoch 389/600\n",
      "1960/1960 [==============================] - 2s 981us/sample - loss: 0.1038 - accuracy: 0.9740 - val_loss: 0.3491 - val_accuracy: 0.9024\n",
      "Epoch 390/600\n",
      "1960/1960 [==============================] - 2s 950us/sample - loss: 0.1134 - accuracy: 0.9699 - val_loss: 0.3472 - val_accuracy: 0.9024\n",
      "Epoch 391/600\n",
      "1960/1960 [==============================] - 2s 861us/sample - loss: 0.0973 - accuracy: 0.9745 - val_loss: 0.3454 - val_accuracy: 0.9036\n",
      "Epoch 392/600\n",
      "1960/1960 [==============================] - 2s 988us/sample - loss: 0.1050 - accuracy: 0.9689 - val_loss: 0.3436 - val_accuracy: 0.9036\n",
      "Epoch 393/600\n",
      "1960/1960 [==============================] - 2s 866us/sample - loss: 0.1013 - accuracy: 0.9709 - val_loss: 0.3418 - val_accuracy: 0.9036\n",
      "Epoch 394/600\n",
      "1960/1960 [==============================] - 2s 908us/sample - loss: 0.1041 - accuracy: 0.9694 - val_loss: 0.3399 - val_accuracy: 0.9048\n",
      "Epoch 395/600\n",
      "1960/1960 [==============================] - 2s 964us/sample - loss: 0.1112 - accuracy: 0.9633 - val_loss: 0.3382 - val_accuracy: 0.9060\n",
      "Epoch 396/600\n",
      "1960/1960 [==============================] - 2s 959us/sample - loss: 0.0887 - accuracy: 0.9770 - val_loss: 0.3364 - val_accuracy: 0.9060\n",
      "Epoch 397/600\n",
      "1960/1960 [==============================] - 2s 860us/sample - loss: 0.0938 - accuracy: 0.9704 - val_loss: 0.3346 - val_accuracy: 0.9048\n",
      "Epoch 398/600\n",
      "1960/1960 [==============================] - 2s 872us/sample - loss: 0.1115 - accuracy: 0.9684 - val_loss: 0.3330 - val_accuracy: 0.9048\n",
      "Epoch 399/600\n",
      "1960/1960 [==============================] - 2s 908us/sample - loss: 0.1090 - accuracy: 0.9679 - val_loss: 0.3314 - val_accuracy: 0.9048\n",
      "Epoch 400/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.1031 - accuracy: 0.9694 - val_loss: 0.3297 - val_accuracy: 0.9048\n",
      "Epoch 401/600\n",
      "1960/1960 [==============================] - 2s 899us/sample - loss: 0.1083 - accuracy: 0.9684 - val_loss: 0.3281 - val_accuracy: 0.9060\n",
      "Epoch 402/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.1126 - accuracy: 0.9648 - val_loss: 0.3264 - val_accuracy: 0.9060\n",
      "Epoch 403/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1031 - accuracy: 0.9714 - val_loss: 0.3248 - val_accuracy: 0.9071\n",
      "Epoch 404/600\n",
      "1960/1960 [==============================] - 2s 935us/sample - loss: 0.0953 - accuracy: 0.9714 - val_loss: 0.3232 - val_accuracy: 0.9071\n",
      "Epoch 405/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1183 - accuracy: 0.9663 - val_loss: 0.3217 - val_accuracy: 0.9071\n",
      "Epoch 406/600\n",
      "1960/1960 [==============================] - 2s 960us/sample - loss: 0.1052 - accuracy: 0.9679 - val_loss: 0.3202 - val_accuracy: 0.9071\n",
      "Epoch 407/600\n",
      "1960/1960 [==============================] - 2s 984us/sample - loss: 0.1025 - accuracy: 0.9694 - val_loss: 0.3187 - val_accuracy: 0.9071\n",
      "Epoch 408/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0881 - accuracy: 0.9755 - val_loss: 0.3172 - val_accuracy: 0.9071\n",
      "Epoch 409/600\n",
      "1960/1960 [==============================] - 2s 973us/sample - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.3157 - val_accuracy: 0.9095\n",
      "Epoch 410/600\n",
      "1960/1960 [==============================] - 2s 990us/sample - loss: 0.0968 - accuracy: 0.9770 - val_loss: 0.3143 - val_accuracy: 0.9095\n",
      "Epoch 411/600\n",
      "1960/1960 [==============================] - 2s 991us/sample - loss: 0.1005 - accuracy: 0.9745 - val_loss: 0.3130 - val_accuracy: 0.9107\n",
      "Epoch 412/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1106 - accuracy: 0.9709 - val_loss: 0.3117 - val_accuracy: 0.9107\n",
      "Epoch 413/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.3104 - val_accuracy: 0.9119\n",
      "Epoch 414/600\n",
      "1960/1960 [==============================] - 2s 969us/sample - loss: 0.0988 - accuracy: 0.9730 - val_loss: 0.3092 - val_accuracy: 0.9119\n",
      "Epoch 415/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1131 - accuracy: 0.9709 - val_loss: 0.3080 - val_accuracy: 0.9119\n",
      "Epoch 416/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1098 - accuracy: 0.9699 - val_loss: 0.3069 - val_accuracy: 0.9119\n",
      "Epoch 417/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1033 - accuracy: 0.9699 - val_loss: 0.3057 - val_accuracy: 0.9119\n",
      "Epoch 418/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0943 - accuracy: 0.9745 - val_loss: 0.3045 - val_accuracy: 0.9119\n",
      "Epoch 419/600\n",
      "1960/1960 [==============================] - 2s 976us/sample - loss: 0.1072 - accuracy: 0.9719 - val_loss: 0.3033 - val_accuracy: 0.9119\n",
      "Epoch 420/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1122 - accuracy: 0.9673 - val_loss: 0.3022 - val_accuracy: 0.9131\n",
      "Epoch 421/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1002 - accuracy: 0.9730 - val_loss: 0.3011 - val_accuracy: 0.9131\n",
      "Epoch 422/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0914 - accuracy: 0.9755 - val_loss: 0.3000 - val_accuracy: 0.9143\n",
      "Epoch 423/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0998 - accuracy: 0.9724 - val_loss: 0.2991 - val_accuracy: 0.9143\n",
      "Epoch 424/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1038 - accuracy: 0.9714 - val_loss: 0.2981 - val_accuracy: 0.9131\n",
      "Epoch 425/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1089 - accuracy: 0.9719 - val_loss: 0.2971 - val_accuracy: 0.9131\n",
      "Epoch 426/600\n",
      "1960/1960 [==============================] - 2s 928us/sample - loss: 0.0974 - accuracy: 0.9745 - val_loss: 0.2962 - val_accuracy: 0.9131\n",
      "Epoch 427/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0931 - accuracy: 0.9745 - val_loss: 0.2952 - val_accuracy: 0.9131\n",
      "Epoch 428/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0984 - accuracy: 0.9740 - val_loss: 0.2943 - val_accuracy: 0.9155\n",
      "Epoch 429/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1064 - accuracy: 0.9709 - val_loss: 0.2934 - val_accuracy: 0.9155\n",
      "Epoch 430/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0994 - accuracy: 0.9684 - val_loss: 0.2925 - val_accuracy: 0.9167\n",
      "Epoch 431/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1118 - accuracy: 0.9673 - val_loss: 0.2916 - val_accuracy: 0.9179\n",
      "Epoch 432/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1003 - accuracy: 0.9704 - val_loss: 0.2907 - val_accuracy: 0.9190\n",
      "Epoch 433/600\n",
      "1960/1960 [==============================] - 2s 975us/sample - loss: 0.1008 - accuracy: 0.9730 - val_loss: 0.2898 - val_accuracy: 0.9190\n",
      "Epoch 434/600\n",
      "1960/1960 [==============================] - 2s 966us/sample - loss: 0.0896 - accuracy: 0.9776 - val_loss: 0.2889 - val_accuracy: 0.9190\n",
      "Epoch 435/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0915 - accuracy: 0.9745 - val_loss: 0.2882 - val_accuracy: 0.9190\n",
      "Epoch 436/600\n",
      "1960/1960 [==============================] - 2s 996us/sample - loss: 0.1094 - accuracy: 0.9673 - val_loss: 0.2874 - val_accuracy: 0.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0934 - accuracy: 0.9765 - val_loss: 0.2866 - val_accuracy: 0.9202\n",
      "Epoch 438/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0948 - accuracy: 0.9750 - val_loss: 0.2858 - val_accuracy: 0.9202\n",
      "Epoch 439/600\n",
      "1960/1960 [==============================] - 2s 981us/sample - loss: 0.1060 - accuracy: 0.9689 - val_loss: 0.2850 - val_accuracy: 0.9214\n",
      "Epoch 440/600\n",
      "1960/1960 [==============================] - 2s 990us/sample - loss: 0.1068 - accuracy: 0.9679 - val_loss: 0.2843 - val_accuracy: 0.9238\n",
      "Epoch 441/600\n",
      "1960/1960 [==============================] - 2s 909us/sample - loss: 0.1004 - accuracy: 0.9724 - val_loss: 0.2836 - val_accuracy: 0.9226\n",
      "Epoch 442/600\n",
      "1960/1960 [==============================] - 2s 885us/sample - loss: 0.0884 - accuracy: 0.9730 - val_loss: 0.2828 - val_accuracy: 0.9238\n",
      "Epoch 443/600\n",
      "1960/1960 [==============================] - 2s 951us/sample - loss: 0.0988 - accuracy: 0.9714 - val_loss: 0.2821 - val_accuracy: 0.9238\n",
      "Epoch 444/600\n",
      "1960/1960 [==============================] - 2s 962us/sample - loss: 0.0824 - accuracy: 0.9811 - val_loss: 0.2814 - val_accuracy: 0.9238\n",
      "Epoch 445/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.1104 - accuracy: 0.9668 - val_loss: 0.2806 - val_accuracy: 0.9262\n",
      "Epoch 446/600\n",
      "1960/1960 [==============================] - 2s 838us/sample - loss: 0.1038 - accuracy: 0.9699 - val_loss: 0.2799 - val_accuracy: 0.9262\n",
      "Epoch 447/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.1132 - accuracy: 0.9648 - val_loss: 0.2792 - val_accuracy: 0.9262\n",
      "Epoch 448/600\n",
      "1960/1960 [==============================] - 2s 798us/sample - loss: 0.0968 - accuracy: 0.9709 - val_loss: 0.2785 - val_accuracy: 0.9262\n",
      "Epoch 449/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.0868 - accuracy: 0.9750 - val_loss: 0.2778 - val_accuracy: 0.9262\n",
      "Epoch 450/600\n",
      "1960/1960 [==============================] - 1s 764us/sample - loss: 0.0950 - accuracy: 0.9735 - val_loss: 0.2772 - val_accuracy: 0.9262\n",
      "Epoch 451/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.1035 - accuracy: 0.9735 - val_loss: 0.2765 - val_accuracy: 0.9262\n",
      "Epoch 452/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.2759 - val_accuracy: 0.9262\n",
      "Epoch 453/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.1144 - accuracy: 0.9653 - val_loss: 0.2753 - val_accuracy: 0.9250\n",
      "Epoch 454/600\n",
      "1960/1960 [==============================] - 2s 848us/sample - loss: 0.0991 - accuracy: 0.9684 - val_loss: 0.2747 - val_accuracy: 0.9262\n",
      "Epoch 455/600\n",
      "1960/1960 [==============================] - 2s 855us/sample - loss: 0.1000 - accuracy: 0.9714 - val_loss: 0.2742 - val_accuracy: 0.9262\n",
      "Epoch 456/600\n",
      "1960/1960 [==============================] - 2s 870us/sample - loss: 0.0984 - accuracy: 0.9684 - val_loss: 0.2737 - val_accuracy: 0.9262\n",
      "Epoch 457/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.1062 - accuracy: 0.9668 - val_loss: 0.2731 - val_accuracy: 0.9262\n",
      "Epoch 458/600\n",
      "1960/1960 [==============================] - 2s 816us/sample - loss: 0.1076 - accuracy: 0.9735 - val_loss: 0.2726 - val_accuracy: 0.9262\n",
      "Epoch 459/600\n",
      "1960/1960 [==============================] - 1s 748us/sample - loss: 0.0945 - accuracy: 0.9745 - val_loss: 0.2721 - val_accuracy: 0.9262\n",
      "Epoch 460/600\n",
      "1960/1960 [==============================] - 2s 811us/sample - loss: 0.1006 - accuracy: 0.9730 - val_loss: 0.2716 - val_accuracy: 0.9262\n",
      "Epoch 461/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0992 - accuracy: 0.9699 - val_loss: 0.2711 - val_accuracy: 0.9274\n",
      "Epoch 462/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.0964 - accuracy: 0.9755 - val_loss: 0.2707 - val_accuracy: 0.9274\n",
      "Epoch 463/600\n",
      "1960/1960 [==============================] - 2s 859us/sample - loss: 0.1097 - accuracy: 0.9699 - val_loss: 0.2702 - val_accuracy: 0.9274\n",
      "Epoch 464/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.1056 - accuracy: 0.9740 - val_loss: 0.2698 - val_accuracy: 0.9274\n",
      "Epoch 465/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0978 - accuracy: 0.9745 - val_loss: 0.2694 - val_accuracy: 0.9274\n",
      "Epoch 466/600\n",
      "1960/1960 [==============================] - 2s 810us/sample - loss: 0.1018 - accuracy: 0.9684 - val_loss: 0.2690 - val_accuracy: 0.9274\n",
      "Epoch 467/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.0914 - accuracy: 0.9740 - val_loss: 0.2686 - val_accuracy: 0.9286\n",
      "Epoch 468/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.0860 - accuracy: 0.9776 - val_loss: 0.2682 - val_accuracy: 0.9286\n",
      "Epoch 469/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.0946 - accuracy: 0.9735 - val_loss: 0.2678 - val_accuracy: 0.9286\n",
      "Epoch 470/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.2674 - val_accuracy: 0.9286\n",
      "Epoch 471/600\n",
      "1960/1960 [==============================] - 2s 798us/sample - loss: 0.0971 - accuracy: 0.9724 - val_loss: 0.2671 - val_accuracy: 0.9286\n",
      "Epoch 472/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.1086 - accuracy: 0.9679 - val_loss: 0.2667 - val_accuracy: 0.9274\n",
      "Epoch 473/600\n",
      "1960/1960 [==============================] - 2s 811us/sample - loss: 0.1084 - accuracy: 0.9638 - val_loss: 0.2663 - val_accuracy: 0.9286\n",
      "Epoch 474/600\n",
      "1960/1960 [==============================] - 2s 891us/sample - loss: 0.1011 - accuracy: 0.9694 - val_loss: 0.2659 - val_accuracy: 0.9298\n",
      "Epoch 475/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0914 - accuracy: 0.9735 - val_loss: 0.2655 - val_accuracy: 0.9298\n",
      "Epoch 476/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0970 - accuracy: 0.9735 - val_loss: 0.2652 - val_accuracy: 0.9298\n",
      "Epoch 477/600\n",
      "1960/1960 [==============================] - 2s 921us/sample - loss: 0.1042 - accuracy: 0.9694 - val_loss: 0.2649 - val_accuracy: 0.9298\n",
      "Epoch 478/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.1053 - accuracy: 0.9704 - val_loss: 0.2645 - val_accuracy: 0.9298\n",
      "Epoch 479/600\n",
      "1960/1960 [==============================] - 2s 768us/sample - loss: 0.1002 - accuracy: 0.9730 - val_loss: 0.2642 - val_accuracy: 0.9286\n",
      "Epoch 480/600\n",
      "1960/1960 [==============================] - 2s 883us/sample - loss: 0.0950 - accuracy: 0.9750 - val_loss: 0.2640 - val_accuracy: 0.9286\n",
      "Epoch 481/600\n",
      "1960/1960 [==============================] - 2s 855us/sample - loss: 0.0979 - accuracy: 0.9684 - val_loss: 0.2637 - val_accuracy: 0.9274\n",
      "Epoch 482/600\n",
      "1960/1960 [==============================] - 2s 867us/sample - loss: 0.1066 - accuracy: 0.9694 - val_loss: 0.2634 - val_accuracy: 0.9286\n",
      "Epoch 483/600\n",
      "1960/1960 [==============================] - 2s 970us/sample - loss: 0.0972 - accuracy: 0.9765 - val_loss: 0.2632 - val_accuracy: 0.9286\n",
      "Epoch 484/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1036 - accuracy: 0.9633 - val_loss: 0.2629 - val_accuracy: 0.9286\n",
      "Epoch 485/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0955 - accuracy: 0.9704 - val_loss: 0.2626 - val_accuracy: 0.9298\n",
      "Epoch 486/600\n",
      "1960/1960 [==============================] - 2s 892us/sample - loss: 0.1021 - accuracy: 0.9760 - val_loss: 0.2623 - val_accuracy: 0.9298\n",
      "Epoch 487/600\n",
      "1960/1960 [==============================] - 2s 910us/sample - loss: 0.0930 - accuracy: 0.9750 - val_loss: 0.2620 - val_accuracy: 0.9298\n",
      "Epoch 488/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1053 - accuracy: 0.9684 - val_loss: 0.2618 - val_accuracy: 0.9298\n",
      "Epoch 489/600\n",
      "1960/1960 [==============================] - 2s 895us/sample - loss: 0.1093 - accuracy: 0.9699 - val_loss: 0.2615 - val_accuracy: 0.9298\n",
      "Epoch 490/600\n",
      "1960/1960 [==============================] - 2s 803us/sample - loss: 0.1038 - accuracy: 0.9694 - val_loss: 0.2613 - val_accuracy: 0.9298\n",
      "Epoch 491/600\n",
      "1960/1960 [==============================] - 2s 874us/sample - loss: 0.1082 - accuracy: 0.9653 - val_loss: 0.2610 - val_accuracy: 0.9298\n",
      "Epoch 492/600\n",
      "1960/1960 [==============================] - 2s 840us/sample - loss: 0.0997 - accuracy: 0.9704 - val_loss: 0.2608 - val_accuracy: 0.9298\n",
      "Epoch 493/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.0858 - accuracy: 0.9801 - val_loss: 0.2606 - val_accuracy: 0.9298\n",
      "Epoch 494/600\n",
      "1960/1960 [==============================] - 2s 931us/sample - loss: 0.0914 - accuracy: 0.9740 - val_loss: 0.2604 - val_accuracy: 0.9298\n",
      "Epoch 495/600\n",
      "1960/1960 [==============================] - 2s 980us/sample - loss: 0.1043 - accuracy: 0.9699 - val_loss: 0.2602 - val_accuracy: 0.9298\n",
      "Epoch 496/600\n",
      "1960/1960 [==============================] - 2s 890us/sample - loss: 0.0998 - accuracy: 0.9704 - val_loss: 0.2599 - val_accuracy: 0.9298\n",
      "Epoch 497/600\n",
      "1960/1960 [==============================] - 2s 806us/sample - loss: 0.1038 - accuracy: 0.9689 - val_loss: 0.2597 - val_accuracy: 0.9298\n",
      "Epoch 498/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.1024 - accuracy: 0.9704 - val_loss: 0.2595 - val_accuracy: 0.9298\n",
      "Epoch 499/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.1034 - accuracy: 0.9709 - val_loss: 0.2592 - val_accuracy: 0.9298\n",
      "Epoch 500/600\n",
      "1960/1960 [==============================] - 2s 852us/sample - loss: 0.1043 - accuracy: 0.9684 - val_loss: 0.2590 - val_accuracy: 0.9298\n",
      "Epoch 501/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0972 - accuracy: 0.9709 - val_loss: 0.2589 - val_accuracy: 0.9298\n",
      "Epoch 502/600\n",
      "1960/1960 [==============================] - 2s 922us/sample - loss: 0.1052 - accuracy: 0.9694 - val_loss: 0.2587 - val_accuracy: 0.9286\n",
      "Epoch 503/600\n",
      "1960/1960 [==============================] - 2s 848us/sample - loss: 0.1018 - accuracy: 0.9750 - val_loss: 0.2584 - val_accuracy: 0.9298\n",
      "Epoch 504/600\n",
      "1960/1960 [==============================] - 2s 864us/sample - loss: 0.1023 - accuracy: 0.9709 - val_loss: 0.2583 - val_accuracy: 0.9310\n",
      "Epoch 505/600\n",
      "1960/1960 [==============================] - 2s 864us/sample - loss: 0.0933 - accuracy: 0.9781 - val_loss: 0.2581 - val_accuracy: 0.9310\n",
      "Epoch 506/600\n",
      "1960/1960 [==============================] - 2s 876us/sample - loss: 0.0903 - accuracy: 0.9760 - val_loss: 0.2579 - val_accuracy: 0.9310\n",
      "Epoch 507/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0857 - accuracy: 0.9770 - val_loss: 0.2578 - val_accuracy: 0.9310\n",
      "Epoch 508/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.1068 - accuracy: 0.9714 - val_loss: 0.2577 - val_accuracy: 0.9321\n",
      "Epoch 509/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0994 - accuracy: 0.9704 - val_loss: 0.2576 - val_accuracy: 0.9333\n",
      "Epoch 510/600\n",
      "1960/1960 [==============================] - 2s 891us/sample - loss: 0.1090 - accuracy: 0.9699 - val_loss: 0.2575 - val_accuracy: 0.9333\n",
      "Epoch 511/600\n",
      "1960/1960 [==============================] - 2s 894us/sample - loss: 0.1025 - accuracy: 0.9709 - val_loss: 0.2574 - val_accuracy: 0.9333\n",
      "Epoch 512/600\n",
      "1960/1960 [==============================] - 2s 873us/sample - loss: 0.0899 - accuracy: 0.9765 - val_loss: 0.2573 - val_accuracy: 0.9333\n",
      "Epoch 513/600\n",
      "1960/1960 [==============================] - 2s 976us/sample - loss: 0.1125 - accuracy: 0.9679 - val_loss: 0.2572 - val_accuracy: 0.9333\n",
      "Epoch 514/600\n",
      "1960/1960 [==============================] - 2s 957us/sample - loss: 0.1017 - accuracy: 0.9694 - val_loss: 0.2571 - val_accuracy: 0.9333\n",
      "Epoch 515/600\n",
      "1960/1960 [==============================] - 2s 872us/sample - loss: 0.1030 - accuracy: 0.9714 - val_loss: 0.2570 - val_accuracy: 0.9333\n",
      "Epoch 516/600\n",
      "1960/1960 [==============================] - 2s 853us/sample - loss: 0.1073 - accuracy: 0.9694 - val_loss: 0.2569 - val_accuracy: 0.9333\n",
      "Epoch 517/600\n",
      "1960/1960 [==============================] - 2s 887us/sample - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.2568 - val_accuracy: 0.9333\n",
      "Epoch 518/600\n",
      "1960/1960 [==============================] - 2s 942us/sample - loss: 0.1104 - accuracy: 0.9673 - val_loss: 0.2567 - val_accuracy: 0.9333\n",
      "Epoch 519/600\n",
      "1960/1960 [==============================] - 2s 962us/sample - loss: 0.0992 - accuracy: 0.9714 - val_loss: 0.2566 - val_accuracy: 0.9333\n",
      "Epoch 520/600\n",
      "1960/1960 [==============================] - 2s 931us/sample - loss: 0.1052 - accuracy: 0.9704 - val_loss: 0.2565 - val_accuracy: 0.9345\n",
      "Epoch 521/600\n",
      "1960/1960 [==============================] - 2s 941us/sample - loss: 0.1001 - accuracy: 0.9740 - val_loss: 0.2565 - val_accuracy: 0.9345\n",
      "Epoch 522/600\n",
      "1960/1960 [==============================] - 2s 867us/sample - loss: 0.0979 - accuracy: 0.9740 - val_loss: 0.2564 - val_accuracy: 0.9345\n",
      "Epoch 523/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0998 - accuracy: 0.9719 - val_loss: 0.2563 - val_accuracy: 0.9333\n",
      "Epoch 524/600\n",
      "1960/1960 [==============================] - 2s 907us/sample - loss: 0.1013 - accuracy: 0.9730 - val_loss: 0.2563 - val_accuracy: 0.9333\n",
      "Epoch 525/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.1046 - accuracy: 0.9689 - val_loss: 0.2562 - val_accuracy: 0.9333\n",
      "Epoch 526/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0990 - accuracy: 0.9730 - val_loss: 0.2561 - val_accuracy: 0.9333\n",
      "Epoch 527/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.1055 - accuracy: 0.9663 - val_loss: 0.2561 - val_accuracy: 0.9333\n",
      "Epoch 528/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0938 - accuracy: 0.9770 - val_loss: 0.2560 - val_accuracy: 0.9333\n",
      "Epoch 529/600\n",
      "1960/1960 [==============================] - 2s 951us/sample - loss: 0.0937 - accuracy: 0.9724 - val_loss: 0.2559 - val_accuracy: 0.9333\n",
      "Epoch 530/600\n",
      "1960/1960 [==============================] - 2s 946us/sample - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.2559 - val_accuracy: 0.9333\n",
      "Epoch 531/600\n",
      "1960/1960 [==============================] - 2s 970us/sample - loss: 0.1084 - accuracy: 0.9719 - val_loss: 0.2558 - val_accuracy: 0.9333\n",
      "Epoch 532/600\n",
      "1960/1960 [==============================] - 2s 919us/sample - loss: 0.1135 - accuracy: 0.9709 - val_loss: 0.2557 - val_accuracy: 0.9333\n",
      "Epoch 533/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1021 - accuracy: 0.9730 - val_loss: 0.2557 - val_accuracy: 0.9333\n",
      "Epoch 534/600\n",
      "1960/1960 [==============================] - 2s 969us/sample - loss: 0.1067 - accuracy: 0.9724 - val_loss: 0.2556 - val_accuracy: 0.9333\n",
      "Epoch 535/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0978 - accuracy: 0.9740 - val_loss: 0.2556 - val_accuracy: 0.9333\n",
      "Epoch 536/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1083 - accuracy: 0.9684 - val_loss: 0.2555 - val_accuracy: 0.9333\n",
      "Epoch 537/600\n",
      "1960/1960 [==============================] - 2s 999us/sample - loss: 0.1153 - accuracy: 0.9689 - val_loss: 0.2554 - val_accuracy: 0.9333\n",
      "Epoch 538/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0930 - accuracy: 0.9750 - val_loss: 0.2554 - val_accuracy: 0.9333\n",
      "Epoch 539/600\n",
      "1960/1960 [==============================] - 2s 973us/sample - loss: 0.0973 - accuracy: 0.9735 - val_loss: 0.2554 - val_accuracy: 0.9333\n",
      "Epoch 540/600\n",
      "1960/1960 [==============================] - 2s 921us/sample - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.2553 - val_accuracy: 0.9333\n",
      "Epoch 541/600\n",
      "1960/1960 [==============================] - 2s 955us/sample - loss: 0.1184 - accuracy: 0.9617 - val_loss: 0.2552 - val_accuracy: 0.9321\n",
      "Epoch 542/600\n",
      "1960/1960 [==============================] - 2s 863us/sample - loss: 0.1051 - accuracy: 0.9699 - val_loss: 0.2552 - val_accuracy: 0.9321\n",
      "Epoch 543/600\n",
      "1960/1960 [==============================] - 2s 903us/sample - loss: 0.1025 - accuracy: 0.9740 - val_loss: 0.2551 - val_accuracy: 0.9321\n",
      "Epoch 544/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1024 - accuracy: 0.9730 - val_loss: 0.2550 - val_accuracy: 0.9321\n",
      "Epoch 545/600\n",
      "1960/1960 [==============================] - 2s 978us/sample - loss: 0.0898 - accuracy: 0.9765 - val_loss: 0.2550 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/600\n",
      "1960/1960 [==============================] - 2s 944us/sample - loss: 0.1182 - accuracy: 0.9628 - val_loss: 0.2549 - val_accuracy: 0.9333\n",
      "Epoch 547/600\n",
      "1960/1960 [==============================] - 2s 934us/sample - loss: 0.0921 - accuracy: 0.9765 - val_loss: 0.2549 - val_accuracy: 0.9333\n",
      "Epoch 548/600\n",
      "1960/1960 [==============================] - 2s 940us/sample - loss: 0.0960 - accuracy: 0.9760 - val_loss: 0.2548 - val_accuracy: 0.9333\n",
      "Epoch 549/600\n",
      "1960/1960 [==============================] - 2s 966us/sample - loss: 0.1036 - accuracy: 0.9709 - val_loss: 0.2547 - val_accuracy: 0.9345\n",
      "Epoch 550/600\n",
      "1960/1960 [==============================] - 2s 998us/sample - loss: 0.0914 - accuracy: 0.9760 - val_loss: 0.2547 - val_accuracy: 0.9345\n",
      "Epoch 551/600\n",
      "1960/1960 [==============================] - 2s 945us/sample - loss: 0.1018 - accuracy: 0.9719 - val_loss: 0.2546 - val_accuracy: 0.9345\n",
      "Epoch 552/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0946 - accuracy: 0.9730 - val_loss: 0.2546 - val_accuracy: 0.9345\n",
      "Epoch 553/600\n",
      "1960/1960 [==============================] - 2s 937us/sample - loss: 0.1093 - accuracy: 0.9689 - val_loss: 0.2545 - val_accuracy: 0.9345\n",
      "Epoch 554/600\n",
      "1960/1960 [==============================] - 2s 961us/sample - loss: 0.0951 - accuracy: 0.9735 - val_loss: 0.2545 - val_accuracy: 0.9345\n",
      "Epoch 555/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1197 - accuracy: 0.9658 - val_loss: 0.2545 - val_accuracy: 0.9345\n",
      "Epoch 556/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1012 - accuracy: 0.9724 - val_loss: 0.2545 - val_accuracy: 0.9333\n",
      "Epoch 557/600\n",
      "1960/1960 [==============================] - 2s 986us/sample - loss: 0.1000 - accuracy: 0.9730 - val_loss: 0.2545 - val_accuracy: 0.9333\n",
      "Epoch 558/600\n",
      "1960/1960 [==============================] - 2s 858us/sample - loss: 0.0969 - accuracy: 0.9745 - val_loss: 0.2545 - val_accuracy: 0.9333\n",
      "Epoch 559/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1033 - accuracy: 0.9694 - val_loss: 0.2544 - val_accuracy: 0.9333\n",
      "Epoch 560/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1080 - accuracy: 0.9704 - val_loss: 0.2544 - val_accuracy: 0.9333\n",
      "Epoch 561/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0993 - accuracy: 0.9704 - val_loss: 0.2544 - val_accuracy: 0.9333\n",
      "Epoch 562/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1056 - accuracy: 0.9643 - val_loss: 0.2543 - val_accuracy: 0.9333\n",
      "Epoch 563/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0921 - accuracy: 0.9786 - val_loss: 0.2543 - val_accuracy: 0.9333\n",
      "Epoch 564/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0885 - accuracy: 0.9755 - val_loss: 0.2542 - val_accuracy: 0.9333\n",
      "Epoch 565/600\n",
      "1960/1960 [==============================] - 2s 983us/sample - loss: 0.1002 - accuracy: 0.9694 - val_loss: 0.2542 - val_accuracy: 0.9333\n",
      "Epoch 566/600\n",
      "1960/1960 [==============================] - 2s 982us/sample - loss: 0.0910 - accuracy: 0.9745 - val_loss: 0.2541 - val_accuracy: 0.9345\n",
      "Epoch 567/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1034 - accuracy: 0.9694 - val_loss: 0.2541 - val_accuracy: 0.9345\n",
      "Epoch 568/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0925 - accuracy: 0.9724 - val_loss: 0.2540 - val_accuracy: 0.9345\n",
      "Epoch 569/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1014 - accuracy: 0.9735 - val_loss: 0.2540 - val_accuracy: 0.9345\n",
      "Epoch 570/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0933 - accuracy: 0.9735 - val_loss: 0.2539 - val_accuracy: 0.9345\n",
      "Epoch 571/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0956 - accuracy: 0.9704 - val_loss: 0.2539 - val_accuracy: 0.9345\n",
      "Epoch 572/600\n",
      "1960/1960 [==============================] - 2s 961us/sample - loss: 0.1083 - accuracy: 0.9694 - val_loss: 0.2538 - val_accuracy: 0.9345\n",
      "Epoch 573/600\n",
      "1960/1960 [==============================] - 2s 933us/sample - loss: 0.0972 - accuracy: 0.9745 - val_loss: 0.2537 - val_accuracy: 0.9345\n",
      "Epoch 574/600\n",
      "1960/1960 [==============================] - 2s 985us/sample - loss: 0.1018 - accuracy: 0.9750 - val_loss: 0.2537 - val_accuracy: 0.9345\n",
      "Epoch 575/600\n",
      "1960/1960 [==============================] - 2s 911us/sample - loss: 0.1010 - accuracy: 0.9724 - val_loss: 0.2537 - val_accuracy: 0.9345\n",
      "Epoch 576/600\n",
      "1960/1960 [==============================] - 2s 948us/sample - loss: 0.0931 - accuracy: 0.9735 - val_loss: 0.2536 - val_accuracy: 0.9345\n",
      "Epoch 577/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0940 - accuracy: 0.9735 - val_loss: 0.2536 - val_accuracy: 0.9345\n",
      "Epoch 578/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1111 - accuracy: 0.9699 - val_loss: 0.2536 - val_accuracy: 0.9345\n",
      "Epoch 579/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0990 - accuracy: 0.9714 - val_loss: 0.2536 - val_accuracy: 0.9345\n",
      "Epoch 580/600\n",
      "1960/1960 [==============================] - 2s 982us/sample - loss: 0.1079 - accuracy: 0.9673 - val_loss: 0.2535 - val_accuracy: 0.9345\n",
      "Epoch 581/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0884 - accuracy: 0.9745 - val_loss: 0.2535 - val_accuracy: 0.9345\n",
      "Epoch 582/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0847 - accuracy: 0.9760 - val_loss: 0.2535 - val_accuracy: 0.9345\n",
      "Epoch 583/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.2535 - val_accuracy: 0.9345\n",
      "Epoch 584/600\n",
      "1960/1960 [==============================] - 2s 975us/sample - loss: 0.0912 - accuracy: 0.9724 - val_loss: 0.2534 - val_accuracy: 0.9333\n",
      "Epoch 585/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0979 - accuracy: 0.9770 - val_loss: 0.2534 - val_accuracy: 0.9333\n",
      "Epoch 586/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0944 - accuracy: 0.9730 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
      "Epoch 587/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0884 - accuracy: 0.9781 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
      "Epoch 588/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1100 - accuracy: 0.9689 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
      "Epoch 589/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1025 - accuracy: 0.9689 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
      "Epoch 590/600\n",
      "1960/1960 [==============================] - 2s 899us/sample - loss: 0.1016 - accuracy: 0.9699 - val_loss: 0.2532 - val_accuracy: 0.9333\n",
      "Epoch 591/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1001 - accuracy: 0.9724 - val_loss: 0.2532 - val_accuracy: 0.9333\n",
      "Epoch 592/600\n",
      "1960/1960 [==============================] - 2s 960us/sample - loss: 0.1047 - accuracy: 0.9704 - val_loss: 0.2532 - val_accuracy: 0.9333\n",
      "Epoch 593/600\n",
      "1960/1960 [==============================] - 2s 937us/sample - loss: 0.0934 - accuracy: 0.9724 - val_loss: 0.2532 - val_accuracy: 0.9333\n",
      "Epoch 594/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.1140 - accuracy: 0.9679 - val_loss: 0.2533 - val_accuracy: 0.9333\n",
      "Epoch 595/600\n",
      "1960/1960 [==============================] - 2s 938us/sample - loss: 0.1014 - accuracy: 0.9704 - val_loss: 0.2533 - val_accuracy: 0.9345\n",
      "Epoch 596/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0973 - accuracy: 0.9709 - val_loss: 0.2533 - val_accuracy: 0.9345\n",
      "Epoch 597/600\n",
      "1960/1960 [==============================] - 2s 871us/sample - loss: 0.0897 - accuracy: 0.9776 - val_loss: 0.2533 - val_accuracy: 0.9345\n",
      "Epoch 598/600\n",
      "1960/1960 [==============================] - 2s 830us/sample - loss: 0.0974 - accuracy: 0.9735 - val_loss: 0.2533 - val_accuracy: 0.9345\n",
      "Epoch 599/600\n",
      "1960/1960 [==============================] - 2s 812us/sample - loss: 0.0919 - accuracy: 0.9745 - val_loss: 0.2533 - val_accuracy: 0.9345\n",
      "Epoch 600/600\n",
      "1960/1960 [==============================] - 2s 887us/sample - loss: 0.0975 - accuracy: 0.9709 - val_loss: 0.2534 - val_accuracy: 0.9345\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_Net.save_weights('weights/coarse_lite.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With frame_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    print('epoch{}'.format(e))\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in tqdm(range(len(Train['pose']))): \n",
    "\n",
    "        label = np.zeros(C.clc_coarse)\n",
    "        label[Train['coarse_label'][i]-1] = 1 \n",
    "        \n",
    "        p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "        p = sampling_frame(p,C)\n",
    "        \n",
    "        M = get_CG(p,C)\n",
    "        \n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "   \n",
    "\n",
    "    DD_Net.fit([X_0,X_1],Y,\n",
    "            batch_size=len(Y),\n",
    "            epochs=1,\n",
    "            verbose=True,\n",
    "            shuffle=True,\n",
    "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate time (excute it twice, the first time initialize takes extra times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737669944763184"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "y = DD_Net.predict([X_0,X_1])\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAI/CAYAAACf7mYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n24bnetkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = DD_Net.predict([X_test_0,X_test_1])\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(Y_pred,axis=1))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
