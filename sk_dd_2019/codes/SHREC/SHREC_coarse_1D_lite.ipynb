{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.layers.core import *\n",
    "# from tensorflow.keras.layers.convolutional import *\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 12 # the number of joints\n",
    "        self.joint_n = 22 # the number of joints\n",
    "        self.joint_d = 3 # the dimension of joints\n",
    "        self.clc_coarse = 14 # the number of coarse class\n",
    "        self.clc_fine = 28 # the number of fine-grained class\n",
    "        self.feat_d = 231\n",
    "        self.filters = 16\n",
    "        self.data_dir = '..\\\\data\\\\SHREC\\\\'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H,W],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,22*3))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),22*3))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l)\n",
    "\n",
    "    print(\"slow\", diff_slow)\n",
    "    print(\"fast\", diff_fast)\n",
    "    print(\"M\", M)\n",
    "    print(\"P\", P)\n",
    "\n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "        \n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    x = block(x,filters*2)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
    "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
    "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
    "    \n",
    "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    \n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(clc_num, activation='softmax')(x)\n",
    "    \n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow Tensor(\"reshape_32/Identity:0\", shape=(None, 32, 66), dtype=float32)\n",
      "fast Tensor(\"reshape_33/Identity:0\", shape=(None, 16, 66), dtype=float32)\n",
      "M Tensor(\"input_37:0\", shape=(None, 32, 231), dtype=float32)\n",
      "P Tensor(\"input_38:0\", shape=(None, 32, 22, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  [(None, 32, 231)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  [(None, 32, 22, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 4, 128)       119392      M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           model_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16384       global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)      (None, 128)          0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           leaky_re_lu_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16384       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)      (None, 128)          0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           leaky_re_lu_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 14)           1806        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 154,990\n",
      "Trainable params: 153,198\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pickle.load(open(C.data_dir+\"train.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without frame_sampling train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1960/1960 [00:26<00:00, 74.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Train['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 32, 231) (1960, 32, 22, 3) (1960, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_0.shape, X_1.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 840/840 [00:11<00:00, 75.48it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range(p)\n",
    "    \n",
    "    label = np.zeros(C.clc_coarse)\n",
    "    label[Test['coarse_label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 32, 231) (840, 32, 22, 3) (840, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_0.shape, X_test_1.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1960 samples, validate on 840 samples\n",
      "Epoch 1/600\n",
      "1960/1960 [==============================] - 14s 7ms/sample - loss: 0.1597 - accuracy: 0.9536 - val_loss: 0.9058 - val_accuracy: 0.7524\n",
      "Epoch 2/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.1648 - accuracy: 0.9561 - val_loss: 0.8754 - val_accuracy: 0.7619\n",
      "Epoch 3/600\n",
      "1960/1960 [==============================] - 2s 798us/sample - loss: 0.1617 - accuracy: 0.9592 - val_loss: 0.8560 - val_accuracy: 0.7476\n",
      "Epoch 4/600\n",
      "1960/1960 [==============================] - 2s 810us/sample - loss: 0.1687 - accuracy: 0.9571 - val_loss: 0.8811 - val_accuracy: 0.7393\n",
      "Epoch 5/600\n",
      "1960/1960 [==============================] - 2s 791us/sample - loss: 0.1559 - accuracy: 0.9571 - val_loss: 0.9135 - val_accuracy: 0.7393\n",
      "Epoch 6/600\n",
      "1960/1960 [==============================] - 2s 821us/sample - loss: 0.1746 - accuracy: 0.9505 - val_loss: 0.9880 - val_accuracy: 0.7274\n",
      "Epoch 7/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.1535 - accuracy: 0.9561 - val_loss: 1.0210 - val_accuracy: 0.7310\n",
      "Epoch 8/600\n",
      "1960/1960 [==============================] - 1s 757us/sample - loss: 0.1393 - accuracy: 0.9592 - val_loss: 1.0623 - val_accuracy: 0.7238\n",
      "Epoch 9/600\n",
      "1960/1960 [==============================] - 1s 754us/sample - loss: 0.1597 - accuracy: 0.9536 - val_loss: 1.0567 - val_accuracy: 0.7250\n",
      "Epoch 10/600\n",
      "1960/1960 [==============================] - 1s 753us/sample - loss: 0.1325 - accuracy: 0.9668 - val_loss: 1.0327 - val_accuracy: 0.7262\n",
      "Epoch 11/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.1445 - accuracy: 0.9587 - val_loss: 1.0036 - val_accuracy: 0.7321\n",
      "Epoch 12/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.1331 - accuracy: 0.9633 - val_loss: 1.0021 - val_accuracy: 0.7310\n",
      "Epoch 13/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.1460 - accuracy: 0.9561 - val_loss: 1.0314 - val_accuracy: 0.7250\n",
      "Epoch 14/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.1195 - accuracy: 0.9673 - val_loss: 1.0322 - val_accuracy: 0.7214\n",
      "Epoch 15/600\n",
      "1960/1960 [==============================] - 2s 791us/sample - loss: 0.1280 - accuracy: 0.9622 - val_loss: 1.0080 - val_accuracy: 0.7286\n",
      "Epoch 16/600\n",
      "1960/1960 [==============================] - 2s 812us/sample - loss: 0.1319 - accuracy: 0.9592 - val_loss: 0.9829 - val_accuracy: 0.7381\n",
      "Epoch 17/600\n",
      "1960/1960 [==============================] - 2s 859us/sample - loss: 0.1279 - accuracy: 0.9612 - val_loss: 0.9693 - val_accuracy: 0.7417\n",
      "Epoch 18/600\n",
      "1960/1960 [==============================] - 1s 751us/sample - loss: 0.1204 - accuracy: 0.9668 - val_loss: 0.9798 - val_accuracy: 0.7464\n",
      "Epoch 19/600\n",
      "1960/1960 [==============================] - 1s 745us/sample - loss: 0.1334 - accuracy: 0.9617 - val_loss: 0.9383 - val_accuracy: 0.7583\n",
      "Epoch 20/600\n",
      "1960/1960 [==============================] - 1s 730us/sample - loss: 0.1084 - accuracy: 0.9694 - val_loss: 0.9250 - val_accuracy: 0.7607\n",
      "Epoch 21/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.1167 - accuracy: 0.9684 - val_loss: 0.9159 - val_accuracy: 0.7595\n",
      "Epoch 22/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.1174 - accuracy: 0.9668 - val_loss: 0.9032 - val_accuracy: 0.7607\n",
      "Epoch 23/600\n",
      "1960/1960 [==============================] - 1s 753us/sample - loss: 0.0978 - accuracy: 0.9740 - val_loss: 0.8936 - val_accuracy: 0.7631\n",
      "Epoch 24/600\n",
      "1960/1960 [==============================] - 2s 870us/sample - loss: 0.1141 - accuracy: 0.9663 - val_loss: 0.8914 - val_accuracy: 0.7655\n",
      "Epoch 25/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.1122 - accuracy: 0.9684 - val_loss: 0.8951 - val_accuracy: 0.7690\n",
      "Epoch 26/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.1045 - accuracy: 0.9730 - val_loss: 0.9078 - val_accuracy: 0.7679\n",
      "Epoch 27/600\n",
      "1960/1960 [==============================] - 2s 829us/sample - loss: 0.1164 - accuracy: 0.9694 - val_loss: 0.9245 - val_accuracy: 0.7583\n",
      "Epoch 28/600\n",
      "1960/1960 [==============================] - 1s 741us/sample - loss: 0.1092 - accuracy: 0.9673 - val_loss: 0.9480 - val_accuracy: 0.7583\n",
      "Epoch 29/600\n",
      "1960/1960 [==============================] - 1s 751us/sample - loss: 0.1159 - accuracy: 0.9622 - val_loss: 0.9532 - val_accuracy: 0.7583\n",
      "Epoch 30/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.1225 - accuracy: 0.9638 - val_loss: 0.9557 - val_accuracy: 0.7583\n",
      "Epoch 31/600\n",
      "1960/1960 [==============================] - 1s 742us/sample - loss: 0.1201 - accuracy: 0.9628 - val_loss: 0.9545 - val_accuracy: 0.7643\n",
      "Epoch 32/600\n",
      "1960/1960 [==============================] - 1s 746us/sample - loss: 0.1047 - accuracy: 0.9679 - val_loss: 0.9529 - val_accuracy: 0.7667\n",
      "Epoch 33/600\n",
      "1960/1960 [==============================] - 1s 732us/sample - loss: 0.1048 - accuracy: 0.9709 - val_loss: 0.9462 - val_accuracy: 0.7667\n",
      "Epoch 34/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0982 - accuracy: 0.9724 - val_loss: 0.9373 - val_accuracy: 0.7690\n",
      "Epoch 35/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.1034 - accuracy: 0.9684 - val_loss: 0.9269 - val_accuracy: 0.7714\n",
      "Epoch 36/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.0978 - accuracy: 0.9776 - val_loss: 0.9155 - val_accuracy: 0.7762\n",
      "Epoch 37/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.1080 - accuracy: 0.9673 - val_loss: 0.9003 - val_accuracy: 0.7774\n",
      "Epoch 38/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.1028 - accuracy: 0.9699 - val_loss: 0.8880 - val_accuracy: 0.7774\n",
      "Epoch 39/600\n",
      "1960/1960 [==============================] - 1s 731us/sample - loss: 0.1039 - accuracy: 0.9740 - val_loss: 0.8775 - val_accuracy: 0.7798\n",
      "Epoch 40/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0861 - accuracy: 0.9770 - val_loss: 0.8652 - val_accuracy: 0.7821\n",
      "Epoch 41/600\n",
      "1960/1960 [==============================] - 1s 759us/sample - loss: 0.0905 - accuracy: 0.9745 - val_loss: 0.8519 - val_accuracy: 0.7821\n",
      "Epoch 42/600\n",
      "1960/1960 [==============================] - 1s 735us/sample - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.8372 - val_accuracy: 0.7845\n",
      "Epoch 43/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.1026 - accuracy: 0.9689 - val_loss: 0.8227 - val_accuracy: 0.7869\n",
      "Epoch 44/600\n",
      "1960/1960 [==============================] - 1s 760us/sample - loss: 0.1078 - accuracy: 0.9709 - val_loss: 0.8082 - val_accuracy: 0.7905\n",
      "Epoch 45/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.7924 - val_accuracy: 0.7976\n",
      "Epoch 46/600\n",
      "1960/1960 [==============================] - 2s 803us/sample - loss: 0.0958 - accuracy: 0.9724 - val_loss: 0.7769 - val_accuracy: 0.8012\n",
      "Epoch 47/600\n",
      "1960/1960 [==============================] - 2s 820us/sample - loss: 0.0899 - accuracy: 0.9765 - val_loss: 0.7651 - val_accuracy: 0.8012\n",
      "Epoch 48/600\n",
      "1960/1960 [==============================] - 2s 830us/sample - loss: 0.0962 - accuracy: 0.9735 - val_loss: 0.7535 - val_accuracy: 0.8036\n",
      "Epoch 49/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0938 - accuracy: 0.9735 - val_loss: 0.7408 - val_accuracy: 0.8048\n",
      "Epoch 50/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.1007 - accuracy: 0.9638 - val_loss: 0.7277 - val_accuracy: 0.8071\n",
      "Epoch 51/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.0965 - accuracy: 0.9730 - val_loss: 0.7156 - val_accuracy: 0.8107\n",
      "Epoch 52/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.1011 - accuracy: 0.9719 - val_loss: 0.7038 - val_accuracy: 0.8119\n",
      "Epoch 53/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.6925 - val_accuracy: 0.8143\n",
      "Epoch 54/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.0896 - accuracy: 0.9745 - val_loss: 0.6824 - val_accuracy: 0.8167\n",
      "Epoch 55/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.0857 - accuracy: 0.9765 - val_loss: 0.6729 - val_accuracy: 0.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/600\n",
      "1960/1960 [==============================] - 2s 808us/sample - loss: 0.0924 - accuracy: 0.9724 - val_loss: 0.6633 - val_accuracy: 0.8202\n",
      "Epoch 57/600\n",
      "1960/1960 [==============================] - 2s 833us/sample - loss: 0.0954 - accuracy: 0.9745 - val_loss: 0.6547 - val_accuracy: 0.8238\n",
      "Epoch 58/600\n",
      "1960/1960 [==============================] - 2s 981us/sample - loss: 0.0911 - accuracy: 0.9735 - val_loss: 0.6467 - val_accuracy: 0.8250\n",
      "Epoch 59/600\n",
      "1960/1960 [==============================] - 2s 915us/sample - loss: 0.0897 - accuracy: 0.9735 - val_loss: 0.6395 - val_accuracy: 0.8262\n",
      "Epoch 60/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0932 - accuracy: 0.9755 - val_loss: 0.6330 - val_accuracy: 0.8274\n",
      "Epoch 61/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0918 - accuracy: 0.9714 - val_loss: 0.6258 - val_accuracy: 0.8298\n",
      "Epoch 62/600\n",
      "1960/1960 [==============================] - 2s 793us/sample - loss: 0.1015 - accuracy: 0.9689 - val_loss: 0.6187 - val_accuracy: 0.8333\n",
      "Epoch 63/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0895 - accuracy: 0.9760 - val_loss: 0.6116 - val_accuracy: 0.8393\n",
      "Epoch 64/600\n",
      "1960/1960 [==============================] - 1s 745us/sample - loss: 0.0972 - accuracy: 0.9714 - val_loss: 0.6054 - val_accuracy: 0.8405\n",
      "Epoch 65/600\n",
      "1960/1960 [==============================] - 2s 819us/sample - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.5992 - val_accuracy: 0.8417\n",
      "Epoch 66/600\n",
      "1960/1960 [==============================] - 2s 826us/sample - loss: 0.0906 - accuracy: 0.9755 - val_loss: 0.5934 - val_accuracy: 0.8429\n",
      "Epoch 67/600\n",
      "1960/1960 [==============================] - 2s 815us/sample - loss: 0.0989 - accuracy: 0.9745 - val_loss: 0.5876 - val_accuracy: 0.8440\n",
      "Epoch 68/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0912 - accuracy: 0.9786 - val_loss: 0.5822 - val_accuracy: 0.8452\n",
      "Epoch 69/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.0951 - accuracy: 0.9704 - val_loss: 0.5766 - val_accuracy: 0.8476\n",
      "Epoch 70/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0984 - accuracy: 0.9750 - val_loss: 0.5706 - val_accuracy: 0.8476\n",
      "Epoch 71/600\n",
      "1960/1960 [==============================] - 1s 726us/sample - loss: 0.0998 - accuracy: 0.9709 - val_loss: 0.5644 - val_accuracy: 0.8500\n",
      "Epoch 72/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.0977 - accuracy: 0.9760 - val_loss: 0.5582 - val_accuracy: 0.8512\n",
      "Epoch 73/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0886 - accuracy: 0.9740 - val_loss: 0.5523 - val_accuracy: 0.8524\n",
      "Epoch 74/600\n",
      "1960/1960 [==============================] - 1s 742us/sample - loss: 0.0932 - accuracy: 0.9704 - val_loss: 0.5464 - val_accuracy: 0.8548\n",
      "Epoch 75/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.0917 - accuracy: 0.9755 - val_loss: 0.5407 - val_accuracy: 0.8560\n",
      "Epoch 76/600\n",
      "1960/1960 [==============================] - 2s 798us/sample - loss: 0.0955 - accuracy: 0.9735 - val_loss: 0.5348 - val_accuracy: 0.8571\n",
      "Epoch 77/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.0878 - accuracy: 0.9735 - val_loss: 0.5290 - val_accuracy: 0.8595\n",
      "Epoch 78/600\n",
      "1960/1960 [==============================] - 2s 994us/sample - loss: 0.0830 - accuracy: 0.9730 - val_loss: 0.5236 - val_accuracy: 0.8619\n",
      "Epoch 79/600\n",
      "1960/1960 [==============================] - 2s 867us/sample - loss: 0.0925 - accuracy: 0.9730 - val_loss: 0.5184 - val_accuracy: 0.8619\n",
      "Epoch 80/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0842 - accuracy: 0.9755 - val_loss: 0.5130 - val_accuracy: 0.8619\n",
      "Epoch 81/600\n",
      "1960/1960 [==============================] - 2s 823us/sample - loss: 0.1000 - accuracy: 0.9719 - val_loss: 0.5078 - val_accuracy: 0.8619\n",
      "Epoch 82/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.0845 - accuracy: 0.9776 - val_loss: 0.5025 - val_accuracy: 0.8655\n",
      "Epoch 83/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0942 - accuracy: 0.9735 - val_loss: 0.4974 - val_accuracy: 0.8655\n",
      "Epoch 84/600\n",
      "1960/1960 [==============================] - 2s 826us/sample - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.4923 - val_accuracy: 0.8667\n",
      "Epoch 85/600\n",
      "1960/1960 [==============================] - 2s 869us/sample - loss: 0.0922 - accuracy: 0.9760 - val_loss: 0.4873 - val_accuracy: 0.8667\n",
      "Epoch 86/600\n",
      "1960/1960 [==============================] - 2s 854us/sample - loss: 0.1020 - accuracy: 0.9719 - val_loss: 0.4826 - val_accuracy: 0.8690\n",
      "Epoch 87/600\n",
      "1960/1960 [==============================] - 2s 899us/sample - loss: 0.0988 - accuracy: 0.9724 - val_loss: 0.4780 - val_accuracy: 0.8690\n",
      "Epoch 88/600\n",
      "1960/1960 [==============================] - 2s 950us/sample - loss: 0.1034 - accuracy: 0.9719 - val_loss: 0.4733 - val_accuracy: 0.8702\n",
      "Epoch 89/600\n",
      "1960/1960 [==============================] - 2s 873us/sample - loss: 0.0962 - accuracy: 0.9755 - val_loss: 0.4687 - val_accuracy: 0.8702\n",
      "Epoch 90/600\n",
      "1960/1960 [==============================] - 2s 895us/sample - loss: 0.0941 - accuracy: 0.9750 - val_loss: 0.4642 - val_accuracy: 0.8702\n",
      "Epoch 91/600\n",
      "1960/1960 [==============================] - 2s 905us/sample - loss: 0.0966 - accuracy: 0.9730 - val_loss: 0.4596 - val_accuracy: 0.8702\n",
      "Epoch 92/600\n",
      "1960/1960 [==============================] - 2s 880us/sample - loss: 0.0865 - accuracy: 0.9786 - val_loss: 0.4551 - val_accuracy: 0.8714\n",
      "Epoch 93/600\n",
      "1960/1960 [==============================] - 2s 909us/sample - loss: 0.1000 - accuracy: 0.9740 - val_loss: 0.4508 - val_accuracy: 0.8738\n",
      "Epoch 94/600\n",
      "1960/1960 [==============================] - 2s 922us/sample - loss: 0.0848 - accuracy: 0.9786 - val_loss: 0.4466 - val_accuracy: 0.8738\n",
      "Epoch 95/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.1066 - accuracy: 0.9714 - val_loss: 0.4425 - val_accuracy: 0.8738\n",
      "Epoch 96/600\n",
      "1960/1960 [==============================] - 2s 826us/sample - loss: 0.0954 - accuracy: 0.9750 - val_loss: 0.4383 - val_accuracy: 0.8786\n",
      "Epoch 97/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0924 - accuracy: 0.9719 - val_loss: 0.4342 - val_accuracy: 0.8798\n",
      "Epoch 98/600\n",
      "1960/1960 [==============================] - 2s 791us/sample - loss: 0.1143 - accuracy: 0.9684 - val_loss: 0.4300 - val_accuracy: 0.8821\n",
      "Epoch 99/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0996 - accuracy: 0.9699 - val_loss: 0.4258 - val_accuracy: 0.8821\n",
      "Epoch 100/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0960 - accuracy: 0.9755 - val_loss: 0.4219 - val_accuracy: 0.8845\n",
      "Epoch 101/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.4181 - val_accuracy: 0.8857\n",
      "Epoch 102/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.1046 - accuracy: 0.9689 - val_loss: 0.4142 - val_accuracy: 0.8857\n",
      "Epoch 103/600\n",
      "1960/1960 [==============================] - 2s 777us/sample - loss: 0.0888 - accuracy: 0.9755 - val_loss: 0.4103 - val_accuracy: 0.8857\n",
      "Epoch 104/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0870 - accuracy: 0.9760 - val_loss: 0.4065 - val_accuracy: 0.8857\n",
      "Epoch 105/600\n",
      "1960/1960 [==============================] - 2s 872us/sample - loss: 0.1056 - accuracy: 0.9668 - val_loss: 0.4028 - val_accuracy: 0.8869\n",
      "Epoch 106/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0945 - accuracy: 0.9765 - val_loss: 0.3991 - val_accuracy: 0.8869\n",
      "Epoch 107/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0935 - accuracy: 0.9699 - val_loss: 0.3955 - val_accuracy: 0.8881\n",
      "Epoch 108/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0916 - accuracy: 0.9760 - val_loss: 0.3918 - val_accuracy: 0.8881\n",
      "Epoch 109/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0817 - accuracy: 0.9791 - val_loss: 0.3884 - val_accuracy: 0.8893\n",
      "Epoch 110/600\n",
      "1960/1960 [==============================] - 1s 764us/sample - loss: 0.1008 - accuracy: 0.9750 - val_loss: 0.3851 - val_accuracy: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/600\n",
      "1960/1960 [==============================] - 1s 743us/sample - loss: 0.0876 - accuracy: 0.9750 - val_loss: 0.3819 - val_accuracy: 0.8952\n",
      "Epoch 112/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.1005 - accuracy: 0.9694 - val_loss: 0.3787 - val_accuracy: 0.8976\n",
      "Epoch 113/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.1096 - accuracy: 0.9679 - val_loss: 0.3754 - val_accuracy: 0.8976\n",
      "Epoch 114/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0923 - accuracy: 0.9724 - val_loss: 0.3722 - val_accuracy: 0.9000\n",
      "Epoch 115/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.1028 - accuracy: 0.9704 - val_loss: 0.3691 - val_accuracy: 0.9012\n",
      "Epoch 116/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.0970 - accuracy: 0.9745 - val_loss: 0.3661 - val_accuracy: 0.9012\n",
      "Epoch 117/600\n",
      "1960/1960 [==============================] - 2s 823us/sample - loss: 0.0952 - accuracy: 0.9740 - val_loss: 0.3631 - val_accuracy: 0.9036\n",
      "Epoch 118/600\n",
      "1960/1960 [==============================] - 2s 854us/sample - loss: 0.0878 - accuracy: 0.9770 - val_loss: 0.3601 - val_accuracy: 0.9036\n",
      "Epoch 119/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0879 - accuracy: 0.9755 - val_loss: 0.3572 - val_accuracy: 0.9048\n",
      "Epoch 120/600\n",
      "1960/1960 [==============================] - 1s 752us/sample - loss: 0.1017 - accuracy: 0.9704 - val_loss: 0.3544 - val_accuracy: 0.9048\n",
      "Epoch 121/600\n",
      "1960/1960 [==============================] - 1s 734us/sample - loss: 0.0922 - accuracy: 0.9745 - val_loss: 0.3516 - val_accuracy: 0.9048\n",
      "Epoch 122/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.1008 - accuracy: 0.9719 - val_loss: 0.3488 - val_accuracy: 0.9060\n",
      "Epoch 123/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.0964 - accuracy: 0.9750 - val_loss: 0.3461 - val_accuracy: 0.9060\n",
      "Epoch 124/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0864 - accuracy: 0.9786 - val_loss: 0.3435 - val_accuracy: 0.9071\n",
      "Epoch 125/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0997 - accuracy: 0.9745 - val_loss: 0.3408 - val_accuracy: 0.9095\n",
      "Epoch 126/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.1022 - accuracy: 0.9709 - val_loss: 0.3383 - val_accuracy: 0.9107\n",
      "Epoch 127/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.0911 - accuracy: 0.9714 - val_loss: 0.3359 - val_accuracy: 0.9107\n",
      "Epoch 128/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0899 - accuracy: 0.9760 - val_loss: 0.3334 - val_accuracy: 0.9131\n",
      "Epoch 129/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.0910 - accuracy: 0.9735 - val_loss: 0.3309 - val_accuracy: 0.9131\n",
      "Epoch 130/600\n",
      "1960/1960 [==============================] - 1s 759us/sample - loss: 0.1030 - accuracy: 0.9745 - val_loss: 0.3285 - val_accuracy: 0.9131\n",
      "Epoch 131/600\n",
      "1960/1960 [==============================] - 1s 762us/sample - loss: 0.0949 - accuracy: 0.9714 - val_loss: 0.3261 - val_accuracy: 0.9131\n",
      "Epoch 132/600\n",
      "1960/1960 [==============================] - 1s 756us/sample - loss: 0.1061 - accuracy: 0.9684 - val_loss: 0.3237 - val_accuracy: 0.9131\n",
      "Epoch 133/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0950 - accuracy: 0.9704 - val_loss: 0.3213 - val_accuracy: 0.9131\n",
      "Epoch 134/600\n",
      "1960/1960 [==============================] - 1s 743us/sample - loss: 0.0917 - accuracy: 0.9755 - val_loss: 0.3191 - val_accuracy: 0.9131\n",
      "Epoch 135/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.0858 - accuracy: 0.9760 - val_loss: 0.3168 - val_accuracy: 0.9131\n",
      "Epoch 136/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0872 - accuracy: 0.9745 - val_loss: 0.3147 - val_accuracy: 0.9155\n",
      "Epoch 137/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.1060 - accuracy: 0.9714 - val_loss: 0.3126 - val_accuracy: 0.9155\n",
      "Epoch 138/600\n",
      "1960/1960 [==============================] - 2s 815us/sample - loss: 0.1028 - accuracy: 0.9673 - val_loss: 0.3105 - val_accuracy: 0.9155\n",
      "Epoch 139/600\n",
      "1960/1960 [==============================] - 1s 739us/sample - loss: 0.0901 - accuracy: 0.9760 - val_loss: 0.3083 - val_accuracy: 0.9155\n",
      "Epoch 140/600\n",
      "1960/1960 [==============================] - 1s 729us/sample - loss: 0.0885 - accuracy: 0.9745 - val_loss: 0.3062 - val_accuracy: 0.9155\n",
      "Epoch 141/600\n",
      "1960/1960 [==============================] - 2s 806us/sample - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.3042 - val_accuracy: 0.9155\n",
      "Epoch 142/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.3021 - val_accuracy: 0.9155\n",
      "Epoch 143/600\n",
      "1960/1960 [==============================] - 1s 757us/sample - loss: 0.0869 - accuracy: 0.9770 - val_loss: 0.3001 - val_accuracy: 0.9155\n",
      "Epoch 144/600\n",
      "1960/1960 [==============================] - 1s 725us/sample - loss: 0.0831 - accuracy: 0.9806 - val_loss: 0.2982 - val_accuracy: 0.9155\n",
      "Epoch 145/600\n",
      "1960/1960 [==============================] - 1s 738us/sample - loss: 0.0896 - accuracy: 0.9745 - val_loss: 0.2963 - val_accuracy: 0.9167\n",
      "Epoch 146/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.2944 - val_accuracy: 0.9167\n",
      "Epoch 147/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.0830 - accuracy: 0.9796 - val_loss: 0.2925 - val_accuracy: 0.9167\n",
      "Epoch 148/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0861 - accuracy: 0.9765 - val_loss: 0.2906 - val_accuracy: 0.9167\n",
      "Epoch 149/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.0840 - accuracy: 0.9770 - val_loss: 0.2888 - val_accuracy: 0.9179\n",
      "Epoch 150/600\n",
      "1960/1960 [==============================] - 1s 731us/sample - loss: 0.0846 - accuracy: 0.9791 - val_loss: 0.2870 - val_accuracy: 0.9179\n",
      "Epoch 151/600\n",
      "1960/1960 [==============================] - 1s 734us/sample - loss: 0.0986 - accuracy: 0.9709 - val_loss: 0.2853 - val_accuracy: 0.9179\n",
      "Epoch 152/600\n",
      "1960/1960 [==============================] - 1s 762us/sample - loss: 0.0993 - accuracy: 0.9689 - val_loss: 0.2836 - val_accuracy: 0.9179\n",
      "Epoch 153/600\n",
      "1960/1960 [==============================] - 1s 762us/sample - loss: 0.0918 - accuracy: 0.9709 - val_loss: 0.2820 - val_accuracy: 0.9179\n",
      "Epoch 154/600\n",
      "1960/1960 [==============================] - 1s 760us/sample - loss: 0.0856 - accuracy: 0.9735 - val_loss: 0.2803 - val_accuracy: 0.9179\n",
      "Epoch 155/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.0784 - accuracy: 0.9821 - val_loss: 0.2787 - val_accuracy: 0.9179\n",
      "Epoch 156/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0950 - accuracy: 0.9745 - val_loss: 0.2771 - val_accuracy: 0.9190\n",
      "Epoch 157/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.0964 - accuracy: 0.9745 - val_loss: 0.2755 - val_accuracy: 0.9190\n",
      "Epoch 158/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0950 - accuracy: 0.9740 - val_loss: 0.2739 - val_accuracy: 0.9190\n",
      "Epoch 159/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0887 - accuracy: 0.9755 - val_loss: 0.2724 - val_accuracy: 0.9190\n",
      "Epoch 160/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0856 - accuracy: 0.9765 - val_loss: 0.2708 - val_accuracy: 0.9202\n",
      "Epoch 161/600\n",
      "1960/1960 [==============================] - 1s 735us/sample - loss: 0.0823 - accuracy: 0.9781 - val_loss: 0.2693 - val_accuracy: 0.9202\n",
      "Epoch 162/600\n",
      "1960/1960 [==============================] - 1s 732us/sample - loss: 0.0936 - accuracy: 0.9730 - val_loss: 0.2678 - val_accuracy: 0.9214\n",
      "Epoch 163/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.0936 - accuracy: 0.9719 - val_loss: 0.2663 - val_accuracy: 0.9226\n",
      "Epoch 164/600\n",
      "1960/1960 [==============================] - 1s 737us/sample - loss: 0.0804 - accuracy: 0.9750 - val_loss: 0.2649 - val_accuracy: 0.9226\n",
      "Epoch 165/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 879us/sample - loss: 0.0824 - accuracy: 0.9765 - val_loss: 0.2635 - val_accuracy: 0.9238\n",
      "Epoch 166/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0951 - accuracy: 0.9735 - val_loss: 0.2621 - val_accuracy: 0.9238\n",
      "Epoch 167/600\n",
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.1054 - accuracy: 0.9689 - val_loss: 0.2607 - val_accuracy: 0.9238\n",
      "Epoch 168/600\n",
      "1960/1960 [==============================] - 2s 867us/sample - loss: 0.0887 - accuracy: 0.9740 - val_loss: 0.2594 - val_accuracy: 0.9250\n",
      "Epoch 169/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0903 - accuracy: 0.9755 - val_loss: 0.2581 - val_accuracy: 0.9250\n",
      "Epoch 170/600\n",
      "1960/1960 [==============================] - 2s 924us/sample - loss: 0.0996 - accuracy: 0.9745 - val_loss: 0.2569 - val_accuracy: 0.9250\n",
      "Epoch 171/600\n",
      "1960/1960 [==============================] - 2s 950us/sample - loss: 0.0948 - accuracy: 0.9699 - val_loss: 0.2557 - val_accuracy: 0.9262\n",
      "Epoch 172/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0785 - accuracy: 0.9791 - val_loss: 0.2545 - val_accuracy: 0.9274\n",
      "Epoch 173/600\n",
      "1960/1960 [==============================] - 2s 768us/sample - loss: 0.0887 - accuracy: 0.9786 - val_loss: 0.2533 - val_accuracy: 0.9286\n",
      "Epoch 174/600\n",
      "1960/1960 [==============================] - 2s 893us/sample - loss: 0.0944 - accuracy: 0.9740 - val_loss: 0.2521 - val_accuracy: 0.9286\n",
      "Epoch 175/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0985 - accuracy: 0.9699 - val_loss: 0.2510 - val_accuracy: 0.9286\n",
      "Epoch 176/600\n",
      "1960/1960 [==============================] - 2s 816us/sample - loss: 0.0974 - accuracy: 0.9730 - val_loss: 0.2498 - val_accuracy: 0.9274\n",
      "Epoch 177/600\n",
      "1960/1960 [==============================] - 2s 858us/sample - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.2486 - val_accuracy: 0.9274\n",
      "Epoch 178/600\n",
      "1960/1960 [==============================] - 2s 804us/sample - loss: 0.0802 - accuracy: 0.9796 - val_loss: 0.2475 - val_accuracy: 0.9274\n",
      "Epoch 179/600\n",
      "1960/1960 [==============================] - 2s 832us/sample - loss: 0.0957 - accuracy: 0.9735 - val_loss: 0.2464 - val_accuracy: 0.9310\n",
      "Epoch 180/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.0936 - accuracy: 0.9750 - val_loss: 0.2454 - val_accuracy: 0.9310\n",
      "Epoch 181/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.2443 - val_accuracy: 0.9310\n",
      "Epoch 182/600\n",
      "1960/1960 [==============================] - 2s 866us/sample - loss: 0.0959 - accuracy: 0.9724 - val_loss: 0.2433 - val_accuracy: 0.9321\n",
      "Epoch 183/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0917 - accuracy: 0.9719 - val_loss: 0.2422 - val_accuracy: 0.9333\n",
      "Epoch 184/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0754 - accuracy: 0.9816 - val_loss: 0.2412 - val_accuracy: 0.9345\n",
      "Epoch 185/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.2402 - val_accuracy: 0.9369\n",
      "Epoch 186/600\n",
      "1960/1960 [==============================] - 2s 838us/sample - loss: 0.0841 - accuracy: 0.9781 - val_loss: 0.2392 - val_accuracy: 0.9369\n",
      "Epoch 187/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0942 - accuracy: 0.9770 - val_loss: 0.2382 - val_accuracy: 0.9369\n",
      "Epoch 188/600\n",
      "1960/1960 [==============================] - 2s 834us/sample - loss: 0.1085 - accuracy: 0.9694 - val_loss: 0.2373 - val_accuracy: 0.9369\n",
      "Epoch 189/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0873 - accuracy: 0.9730 - val_loss: 0.2364 - val_accuracy: 0.9381\n",
      "Epoch 190/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.0932 - accuracy: 0.9719 - val_loss: 0.2354 - val_accuracy: 0.9381\n",
      "Epoch 191/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0814 - accuracy: 0.9791 - val_loss: 0.2345 - val_accuracy: 0.9393\n",
      "Epoch 192/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.1057 - accuracy: 0.9689 - val_loss: 0.2336 - val_accuracy: 0.9393\n",
      "Epoch 193/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0921 - accuracy: 0.9755 - val_loss: 0.2327 - val_accuracy: 0.9393\n",
      "Epoch 194/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0816 - accuracy: 0.9770 - val_loss: 0.2319 - val_accuracy: 0.9393\n",
      "Epoch 195/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.1081 - accuracy: 0.9740 - val_loss: 0.2310 - val_accuracy: 0.9393\n",
      "Epoch 196/600\n",
      "1960/1960 [==============================] - 2s 844us/sample - loss: 0.0845 - accuracy: 0.9801 - val_loss: 0.2302 - val_accuracy: 0.9405\n",
      "Epoch 197/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0843 - accuracy: 0.9811 - val_loss: 0.2295 - val_accuracy: 0.9405\n",
      "Epoch 198/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.0829 - accuracy: 0.9786 - val_loss: 0.2288 - val_accuracy: 0.9405\n",
      "Epoch 199/600\n",
      "1960/1960 [==============================] - 2s 835us/sample - loss: 0.0838 - accuracy: 0.9791 - val_loss: 0.2281 - val_accuracy: 0.9405\n",
      "Epoch 200/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0816 - accuracy: 0.9837 - val_loss: 0.2273 - val_accuracy: 0.9393\n",
      "Epoch 201/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.1036 - accuracy: 0.9724 - val_loss: 0.2267 - val_accuracy: 0.9405\n",
      "Epoch 202/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.0865 - accuracy: 0.9776 - val_loss: 0.2260 - val_accuracy: 0.9405\n",
      "Epoch 203/600\n",
      "1960/1960 [==============================] - 2s 766us/sample - loss: 0.0853 - accuracy: 0.9776 - val_loss: 0.2254 - val_accuracy: 0.9417\n",
      "Epoch 204/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0938 - accuracy: 0.9740 - val_loss: 0.2247 - val_accuracy: 0.9405\n",
      "Epoch 205/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.0847 - accuracy: 0.9781 - val_loss: 0.2241 - val_accuracy: 0.9417\n",
      "Epoch 206/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0850 - accuracy: 0.9750 - val_loss: 0.2235 - val_accuracy: 0.9429\n",
      "Epoch 207/600\n",
      "1960/1960 [==============================] - 2s 871us/sample - loss: 0.0867 - accuracy: 0.9786 - val_loss: 0.2228 - val_accuracy: 0.9440\n",
      "Epoch 208/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.2222 - val_accuracy: 0.9452\n",
      "Epoch 209/600\n",
      "1960/1960 [==============================] - 2s 1ms/sample - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.2217 - val_accuracy: 0.9452\n",
      "Epoch 210/600\n",
      "1960/1960 [==============================] - 2s 914us/sample - loss: 0.0940 - accuracy: 0.9745 - val_loss: 0.2211 - val_accuracy: 0.9452\n",
      "Epoch 211/600\n",
      "1960/1960 [==============================] - 2s 878us/sample - loss: 0.0884 - accuracy: 0.9755 - val_loss: 0.2206 - val_accuracy: 0.9452\n",
      "Epoch 212/600\n",
      "1960/1960 [==============================] - 2s 853us/sample - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.2201 - val_accuracy: 0.9452\n",
      "Epoch 213/600\n",
      "1960/1960 [==============================] - 2s 797us/sample - loss: 0.0830 - accuracy: 0.9821 - val_loss: 0.2195 - val_accuracy: 0.9452\n",
      "Epoch 214/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0823 - accuracy: 0.9781 - val_loss: 0.2190 - val_accuracy: 0.9452\n",
      "Epoch 215/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0834 - accuracy: 0.9791 - val_loss: 0.2185 - val_accuracy: 0.9452\n",
      "Epoch 216/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0850 - accuracy: 0.9765 - val_loss: 0.2180 - val_accuracy: 0.9452\n",
      "Epoch 217/600\n",
      "1960/1960 [==============================] - 2s 804us/sample - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.2175 - val_accuracy: 0.9452\n",
      "Epoch 218/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.1054 - accuracy: 0.9689 - val_loss: 0.2171 - val_accuracy: 0.9452\n",
      "Epoch 219/600\n",
      "1960/1960 [==============================] - 2s 827us/sample - loss: 0.0936 - accuracy: 0.9745 - val_loss: 0.2166 - val_accuracy: 0.9464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/600\n",
      "1960/1960 [==============================] - 2s 768us/sample - loss: 0.0911 - accuracy: 0.9714 - val_loss: 0.2161 - val_accuracy: 0.9464\n",
      "Epoch 221/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.1106 - accuracy: 0.9704 - val_loss: 0.2157 - val_accuracy: 0.9464\n",
      "Epoch 222/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.2152 - val_accuracy: 0.9464\n",
      "Epoch 223/600\n",
      "1960/1960 [==============================] - 2s 824us/sample - loss: 0.0980 - accuracy: 0.9745 - val_loss: 0.2147 - val_accuracy: 0.9464\n",
      "Epoch 224/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0897 - accuracy: 0.9765 - val_loss: 0.2143 - val_accuracy: 0.9476\n",
      "Epoch 225/600\n",
      "1960/1960 [==============================] - 2s 829us/sample - loss: 0.0879 - accuracy: 0.9740 - val_loss: 0.2138 - val_accuracy: 0.9476\n",
      "Epoch 226/600\n",
      "1960/1960 [==============================] - 2s 823us/sample - loss: 0.0885 - accuracy: 0.9760 - val_loss: 0.2134 - val_accuracy: 0.9476\n",
      "Epoch 227/600\n",
      "1960/1960 [==============================] - 2s 830us/sample - loss: 0.1006 - accuracy: 0.9699 - val_loss: 0.2130 - val_accuracy: 0.9476\n",
      "Epoch 228/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0949 - accuracy: 0.9745 - val_loss: 0.2125 - val_accuracy: 0.9476\n",
      "Epoch 229/600\n",
      "1960/1960 [==============================] - 2s 869us/sample - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.2121 - val_accuracy: 0.9476\n",
      "Epoch 230/600\n",
      "1960/1960 [==============================] - 1s 749us/sample - loss: 0.0924 - accuracy: 0.9765 - val_loss: 0.2117 - val_accuracy: 0.9464\n",
      "Epoch 231/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0868 - accuracy: 0.9740 - val_loss: 0.2113 - val_accuracy: 0.9464\n",
      "Epoch 232/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.0877 - accuracy: 0.9760 - val_loss: 0.2109 - val_accuracy: 0.9464\n",
      "Epoch 233/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.0935 - accuracy: 0.9719 - val_loss: 0.2105 - val_accuracy: 0.9464\n",
      "Epoch 234/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.2101 - val_accuracy: 0.9452\n",
      "Epoch 235/600\n",
      "1960/1960 [==============================] - 2s 808us/sample - loss: 0.0998 - accuracy: 0.9689 - val_loss: 0.2097 - val_accuracy: 0.9452\n",
      "Epoch 236/600\n",
      "1960/1960 [==============================] - 2s 872us/sample - loss: 0.0889 - accuracy: 0.9770 - val_loss: 0.2093 - val_accuracy: 0.9452\n",
      "Epoch 237/600\n",
      "1960/1960 [==============================] - 2s 845us/sample - loss: 0.0814 - accuracy: 0.9770 - val_loss: 0.2089 - val_accuracy: 0.9452\n",
      "Epoch 238/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0831 - accuracy: 0.9801 - val_loss: 0.2086 - val_accuracy: 0.9452\n",
      "Epoch 239/600\n",
      "1960/1960 [==============================] - 2s 856us/sample - loss: 0.0868 - accuracy: 0.9750 - val_loss: 0.2082 - val_accuracy: 0.9452\n",
      "Epoch 240/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.2078 - val_accuracy: 0.9452\n",
      "Epoch 241/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.1032 - accuracy: 0.9750 - val_loss: 0.2074 - val_accuracy: 0.9452\n",
      "Epoch 242/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0902 - accuracy: 0.9770 - val_loss: 0.2071 - val_accuracy: 0.9452\n",
      "Epoch 243/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0814 - accuracy: 0.9816 - val_loss: 0.2068 - val_accuracy: 0.9452\n",
      "Epoch 244/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0898 - accuracy: 0.9735 - val_loss: 0.2065 - val_accuracy: 0.9476\n",
      "Epoch 245/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.0825 - accuracy: 0.9745 - val_loss: 0.2062 - val_accuracy: 0.9476\n",
      "Epoch 246/600\n",
      "1960/1960 [==============================] - 2s 830us/sample - loss: 0.0831 - accuracy: 0.9801 - val_loss: 0.2059 - val_accuracy: 0.9476\n",
      "Epoch 247/600\n",
      "1960/1960 [==============================] - 2s 806us/sample - loss: 0.0923 - accuracy: 0.9750 - val_loss: 0.2057 - val_accuracy: 0.9476\n",
      "Epoch 248/600\n",
      "1960/1960 [==============================] - 2s 808us/sample - loss: 0.0864 - accuracy: 0.9776 - val_loss: 0.2054 - val_accuracy: 0.9488\n",
      "Epoch 249/600\n",
      "1960/1960 [==============================] - 2s 866us/sample - loss: 0.0818 - accuracy: 0.9806 - val_loss: 0.2051 - val_accuracy: 0.9488\n",
      "Epoch 250/600\n",
      "1960/1960 [==============================] - 2s 876us/sample - loss: 0.1007 - accuracy: 0.9745 - val_loss: 0.2049 - val_accuracy: 0.9488\n",
      "Epoch 251/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0790 - accuracy: 0.9816 - val_loss: 0.2046 - val_accuracy: 0.9488\n",
      "Epoch 252/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0929 - accuracy: 0.9740 - val_loss: 0.2044 - val_accuracy: 0.9488\n",
      "Epoch 253/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.0939 - accuracy: 0.9765 - val_loss: 0.2041 - val_accuracy: 0.9488\n",
      "Epoch 254/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0927 - accuracy: 0.9684 - val_loss: 0.2039 - val_accuracy: 0.9488\n",
      "Epoch 255/600\n",
      "1960/1960 [==============================] - 2s 810us/sample - loss: 0.0842 - accuracy: 0.9796 - val_loss: 0.2037 - val_accuracy: 0.9488\n",
      "Epoch 256/600\n",
      "1960/1960 [==============================] - 2s 853us/sample - loss: 0.0968 - accuracy: 0.9730 - val_loss: 0.2034 - val_accuracy: 0.9488\n",
      "Epoch 257/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.2032 - val_accuracy: 0.9488\n",
      "Epoch 258/600\n",
      "1960/1960 [==============================] - 2s 829us/sample - loss: 0.0982 - accuracy: 0.9709 - val_loss: 0.2030 - val_accuracy: 0.9488\n",
      "Epoch 259/600\n",
      "1960/1960 [==============================] - 2s 820us/sample - loss: 0.0852 - accuracy: 0.9770 - val_loss: 0.2028 - val_accuracy: 0.9488\n",
      "Epoch 260/600\n",
      "1960/1960 [==============================] - 2s 767us/sample - loss: 0.0844 - accuracy: 0.9796 - val_loss: 0.2026 - val_accuracy: 0.9476\n",
      "Epoch 261/600\n",
      "1960/1960 [==============================] - 1s 759us/sample - loss: 0.1144 - accuracy: 0.9673 - val_loss: 0.2024 - val_accuracy: 0.9476\n",
      "Epoch 262/600\n",
      "1960/1960 [==============================] - 2s 808us/sample - loss: 0.0852 - accuracy: 0.9796 - val_loss: 0.2022 - val_accuracy: 0.9476\n",
      "Epoch 263/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.1018 - accuracy: 0.9719 - val_loss: 0.2020 - val_accuracy: 0.9476\n",
      "Epoch 264/600\n",
      "1960/1960 [==============================] - 2s 817us/sample - loss: 0.1005 - accuracy: 0.9709 - val_loss: 0.2019 - val_accuracy: 0.9476\n",
      "Epoch 265/600\n",
      "1960/1960 [==============================] - 2s 820us/sample - loss: 0.0797 - accuracy: 0.9781 - val_loss: 0.2017 - val_accuracy: 0.9476\n",
      "Epoch 266/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0891 - accuracy: 0.9730 - val_loss: 0.2015 - val_accuracy: 0.9476\n",
      "Epoch 267/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.2014 - val_accuracy: 0.9464\n",
      "Epoch 268/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0832 - accuracy: 0.9791 - val_loss: 0.2012 - val_accuracy: 0.9464\n",
      "Epoch 269/600\n",
      "1960/1960 [==============================] - 2s 866us/sample - loss: 0.0963 - accuracy: 0.9745 - val_loss: 0.2010 - val_accuracy: 0.9464\n",
      "Epoch 270/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0759 - accuracy: 0.9796 - val_loss: 0.2008 - val_accuracy: 0.9452\n",
      "Epoch 271/600\n",
      "1960/1960 [==============================] - 2s 767us/sample - loss: 0.0912 - accuracy: 0.9724 - val_loss: 0.2007 - val_accuracy: 0.9452\n",
      "Epoch 272/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0936 - accuracy: 0.9740 - val_loss: 0.2005 - val_accuracy: 0.9452\n",
      "Epoch 273/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0950 - accuracy: 0.9786 - val_loss: 0.2003 - val_accuracy: 0.9452\n",
      "Epoch 274/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0882 - accuracy: 0.9740 - val_loss: 0.2001 - val_accuracy: 0.9452\n",
      "Epoch 275/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.0856 - accuracy: 0.9745 - val_loss: 0.2000 - val_accuracy: 0.9452\n",
      "Epoch 276/600\n",
      "1960/1960 [==============================] - 2s 881us/sample - loss: 0.0810 - accuracy: 0.9806 - val_loss: 0.1998 - val_accuracy: 0.9452\n",
      "Epoch 277/600\n",
      "1960/1960 [==============================] - 2s 834us/sample - loss: 0.1021 - accuracy: 0.9704 - val_loss: 0.1996 - val_accuracy: 0.9452\n",
      "Epoch 278/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0923 - accuracy: 0.9745 - val_loss: 0.1995 - val_accuracy: 0.9452\n",
      "Epoch 279/600\n",
      "1960/1960 [==============================] - 2s 856us/sample - loss: 0.0841 - accuracy: 0.9806 - val_loss: 0.1994 - val_accuracy: 0.9464\n",
      "Epoch 280/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0886 - accuracy: 0.9745 - val_loss: 0.1992 - val_accuracy: 0.9464\n",
      "Epoch 281/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.0915 - accuracy: 0.9760 - val_loss: 0.1991 - val_accuracy: 0.9464\n",
      "Epoch 282/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0961 - accuracy: 0.9740 - val_loss: 0.1990 - val_accuracy: 0.9464\n",
      "Epoch 283/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0815 - accuracy: 0.9765 - val_loss: 0.1989 - val_accuracy: 0.9464\n",
      "Epoch 284/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0820 - accuracy: 0.9816 - val_loss: 0.1988 - val_accuracy: 0.9464\n",
      "Epoch 285/600\n",
      "1960/1960 [==============================] - 2s 820us/sample - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.1987 - val_accuracy: 0.9464\n",
      "Epoch 286/600\n",
      "1960/1960 [==============================] - 2s 848us/sample - loss: 0.0946 - accuracy: 0.9689 - val_loss: 0.1985 - val_accuracy: 0.9464\n",
      "Epoch 287/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0860 - accuracy: 0.9760 - val_loss: 0.1984 - val_accuracy: 0.9464\n",
      "Epoch 288/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1983 - val_accuracy: 0.9464\n",
      "Epoch 289/600\n",
      "1960/1960 [==============================] - 2s 875us/sample - loss: 0.0905 - accuracy: 0.9765 - val_loss: 0.1982 - val_accuracy: 0.9476\n",
      "Epoch 290/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.1076 - accuracy: 0.9684 - val_loss: 0.1981 - val_accuracy: 0.9476\n",
      "Epoch 291/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0984 - accuracy: 0.9730 - val_loss: 0.1980 - val_accuracy: 0.9476\n",
      "Epoch 292/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0935 - accuracy: 0.9755 - val_loss: 0.1980 - val_accuracy: 0.9476\n",
      "Epoch 293/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0884 - accuracy: 0.9786 - val_loss: 0.1978 - val_accuracy: 0.9476\n",
      "Epoch 294/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0905 - accuracy: 0.9755 - val_loss: 0.1977 - val_accuracy: 0.9476\n",
      "Epoch 295/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0931 - accuracy: 0.9755 - val_loss: 0.1976 - val_accuracy: 0.9476\n",
      "Epoch 296/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0985 - accuracy: 0.9719 - val_loss: 0.1975 - val_accuracy: 0.9476\n",
      "Epoch 297/600\n",
      "1960/1960 [==============================] - 2s 847us/sample - loss: 0.0873 - accuracy: 0.9791 - val_loss: 0.1974 - val_accuracy: 0.9476\n",
      "Epoch 298/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0873 - accuracy: 0.9745 - val_loss: 0.1974 - val_accuracy: 0.9476\n",
      "Epoch 299/600\n",
      "1960/1960 [==============================] - 2s 819us/sample - loss: 0.0907 - accuracy: 0.9765 - val_loss: 0.1973 - val_accuracy: 0.9476\n",
      "Epoch 300/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.0841 - accuracy: 0.9781 - val_loss: 0.1972 - val_accuracy: 0.9476\n",
      "Epoch 301/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0838 - accuracy: 0.9781 - val_loss: 0.1971 - val_accuracy: 0.9476\n",
      "Epoch 302/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.0884 - accuracy: 0.9770 - val_loss: 0.1970 - val_accuracy: 0.9476\n",
      "Epoch 303/600\n",
      "1960/1960 [==============================] - 2s 847us/sample - loss: 0.0835 - accuracy: 0.9740 - val_loss: 0.1970 - val_accuracy: 0.9476\n",
      "Epoch 304/600\n",
      "1960/1960 [==============================] - 1s 758us/sample - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.1969 - val_accuracy: 0.9476\n",
      "Epoch 305/600\n",
      "1960/1960 [==============================] - 2s 861us/sample - loss: 0.0888 - accuracy: 0.9760 - val_loss: 0.1968 - val_accuracy: 0.9476\n",
      "Epoch 306/600\n",
      "1960/1960 [==============================] - 2s 895us/sample - loss: 0.0908 - accuracy: 0.9765 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
      "Epoch 307/600\n",
      "1960/1960 [==============================] - 2s 873us/sample - loss: 0.0903 - accuracy: 0.9740 - val_loss: 0.1967 - val_accuracy: 0.9464\n",
      "Epoch 308/600\n",
      "1960/1960 [==============================] - 2s 861us/sample - loss: 0.0902 - accuracy: 0.9745 - val_loss: 0.1967 - val_accuracy: 0.9464\n",
      "Epoch 309/600\n",
      "1960/1960 [==============================] - 2s 920us/sample - loss: 0.1091 - accuracy: 0.9684 - val_loss: 0.1966 - val_accuracy: 0.9464\n",
      "Epoch 310/600\n",
      "1960/1960 [==============================] - 2s 870us/sample - loss: 0.0960 - accuracy: 0.9745 - val_loss: 0.1966 - val_accuracy: 0.9464\n",
      "Epoch 311/600\n",
      "1960/1960 [==============================] - 2s 768us/sample - loss: 0.1032 - accuracy: 0.9694 - val_loss: 0.1965 - val_accuracy: 0.9464\n",
      "Epoch 312/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.1965 - val_accuracy: 0.9464\n",
      "Epoch 313/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0922 - accuracy: 0.9755 - val_loss: 0.1965 - val_accuracy: 0.9464\n",
      "Epoch 314/600\n",
      "1960/1960 [==============================] - 2s 843us/sample - loss: 0.0967 - accuracy: 0.9719 - val_loss: 0.1964 - val_accuracy: 0.9464\n",
      "Epoch 315/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0893 - accuracy: 0.9765 - val_loss: 0.1964 - val_accuracy: 0.9464\n",
      "Epoch 316/600\n",
      "1960/1960 [==============================] - 2s 793us/sample - loss: 0.0972 - accuracy: 0.9730 - val_loss: 0.1963 - val_accuracy: 0.9464\n",
      "Epoch 317/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0826 - accuracy: 0.9796 - val_loss: 0.1963 - val_accuracy: 0.9464\n",
      "Epoch 318/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0924 - accuracy: 0.9730 - val_loss: 0.1963 - val_accuracy: 0.9464\n",
      "Epoch 319/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0914 - accuracy: 0.9770 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
      "Epoch 320/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0849 - accuracy: 0.9765 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 321/600\n",
      "1960/1960 [==============================] - 2s 823us/sample - loss: 0.0942 - accuracy: 0.9745 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 322/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0938 - accuracy: 0.9724 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 323/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.1022 - accuracy: 0.9704 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 324/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.1056 - accuracy: 0.9673 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 325/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0986 - accuracy: 0.9730 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 326/600\n",
      "1960/1960 [==============================] - 2s 910us/sample - loss: 0.0845 - accuracy: 0.9740 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 327/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0989 - accuracy: 0.9719 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 328/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.0848 - accuracy: 0.9770 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
      "Epoch 329/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0953 - accuracy: 0.9719 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
      "Epoch 330/600\n",
      "1960/1960 [==============================] - 2s 766us/sample - loss: 0.0967 - accuracy: 0.9724 - val_loss: 0.1962 - val_accuracy: 0.9452\n",
      "Epoch 331/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.1007 - accuracy: 0.9699 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
      "Epoch 332/600\n",
      "1960/1960 [==============================] - 1s 757us/sample - loss: 0.0980 - accuracy: 0.9689 - val_loss: 0.1963 - val_accuracy: 0.9452\n",
      "Epoch 333/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.0927 - accuracy: 0.9740 - val_loss: 0.1963 - val_accuracy: 0.9440\n",
      "Epoch 334/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0904 - accuracy: 0.9796 - val_loss: 0.1963 - val_accuracy: 0.9440\n",
      "Epoch 335/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.0941 - accuracy: 0.9776 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 336/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0885 - accuracy: 0.9765 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 337/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0889 - accuracy: 0.9745 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 338/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0896 - accuracy: 0.9724 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 339/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.0922 - accuracy: 0.9719 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 340/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.0917 - accuracy: 0.9760 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 341/600\n",
      "1960/1960 [==============================] - 2s 803us/sample - loss: 0.0757 - accuracy: 0.9816 - val_loss: 0.1963 - val_accuracy: 0.9440\n",
      "Epoch 342/600\n",
      "1960/1960 [==============================] - 2s 777us/sample - loss: 0.0899 - accuracy: 0.9745 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 343/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.0935 - accuracy: 0.9745 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 344/600\n",
      "1960/1960 [==============================] - 2s 789us/sample - loss: 0.1049 - accuracy: 0.9714 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 345/600\n",
      "1960/1960 [==============================] - 2s 834us/sample - loss: 0.0904 - accuracy: 0.9709 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 346/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.0874 - accuracy: 0.9781 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
      "Epoch 347/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.1015 - accuracy: 0.9709 - val_loss: 0.1965 - val_accuracy: 0.9440\n",
      "Epoch 348/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0932 - accuracy: 0.9755 - val_loss: 0.1965 - val_accuracy: 0.9440\n",
      "Epoch 349/600\n",
      "1960/1960 [==============================] - 2s 803us/sample - loss: 0.0926 - accuracy: 0.9735 - val_loss: 0.1965 - val_accuracy: 0.9452\n",
      "Epoch 350/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0817 - accuracy: 0.9791 - val_loss: 0.1966 - val_accuracy: 0.9452\n",
      "Epoch 351/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0919 - accuracy: 0.9735 - val_loss: 0.1966 - val_accuracy: 0.9452\n",
      "Epoch 352/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.1065 - accuracy: 0.9719 - val_loss: 0.1966 - val_accuracy: 0.9452\n",
      "Epoch 353/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0853 - accuracy: 0.9745 - val_loss: 0.1966 - val_accuracy: 0.9452\n",
      "Epoch 354/600\n",
      "1960/1960 [==============================] - 2s 819us/sample - loss: 0.0956 - accuracy: 0.9745 - val_loss: 0.1966 - val_accuracy: 0.9452\n",
      "Epoch 355/600\n",
      "1960/1960 [==============================] - 2s 881us/sample - loss: 0.0927 - accuracy: 0.9719 - val_loss: 0.1967 - val_accuracy: 0.9452\n",
      "Epoch 356/600\n",
      "1960/1960 [==============================] - 2s 874us/sample - loss: 0.0814 - accuracy: 0.9735 - val_loss: 0.1968 - val_accuracy: 0.9452\n",
      "Epoch 357/600\n",
      "1960/1960 [==============================] - 2s 842us/sample - loss: 0.0971 - accuracy: 0.9719 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
      "Epoch 358/600\n",
      "1960/1960 [==============================] - 2s 879us/sample - loss: 0.0854 - accuracy: 0.9791 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
      "Epoch 359/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.0867 - accuracy: 0.9755 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
      "Epoch 360/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0986 - accuracy: 0.9745 - val_loss: 0.1969 - val_accuracy: 0.9464\n",
      "Epoch 361/600\n",
      "1960/1960 [==============================] - 2s 810us/sample - loss: 0.0987 - accuracy: 0.9760 - val_loss: 0.1969 - val_accuracy: 0.9464\n",
      "Epoch 362/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0927 - accuracy: 0.9719 - val_loss: 0.1970 - val_accuracy: 0.9464\n",
      "Epoch 363/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0938 - accuracy: 0.9765 - val_loss: 0.1971 - val_accuracy: 0.9464\n",
      "Epoch 364/600\n",
      "1960/1960 [==============================] - 2s 864us/sample - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.1971 - val_accuracy: 0.9464\n",
      "Epoch 365/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.1972 - val_accuracy: 0.9464\n",
      "Epoch 366/600\n",
      "1960/1960 [==============================] - 2s 831us/sample - loss: 0.0925 - accuracy: 0.9770 - val_loss: 0.1972 - val_accuracy: 0.9464\n",
      "Epoch 367/600\n",
      "1960/1960 [==============================] - 2s 842us/sample - loss: 0.0952 - accuracy: 0.9760 - val_loss: 0.1973 - val_accuracy: 0.9464\n",
      "Epoch 368/600\n",
      "1960/1960 [==============================] - 2s 847us/sample - loss: 0.0898 - accuracy: 0.9745 - val_loss: 0.1974 - val_accuracy: 0.9452\n",
      "Epoch 369/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0917 - accuracy: 0.9694 - val_loss: 0.1974 - val_accuracy: 0.9452\n",
      "Epoch 370/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0943 - accuracy: 0.9750 - val_loss: 0.1975 - val_accuracy: 0.9452\n",
      "Epoch 371/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0993 - accuracy: 0.9735 - val_loss: 0.1975 - val_accuracy: 0.9440\n",
      "Epoch 372/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0954 - accuracy: 0.9740 - val_loss: 0.1976 - val_accuracy: 0.9440\n",
      "Epoch 373/600\n",
      "1960/1960 [==============================] - 2s 789us/sample - loss: 0.0854 - accuracy: 0.9776 - val_loss: 0.1977 - val_accuracy: 0.9440\n",
      "Epoch 374/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.0845 - accuracy: 0.9740 - val_loss: 0.1978 - val_accuracy: 0.9440\n",
      "Epoch 375/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0907 - accuracy: 0.9760 - val_loss: 0.1978 - val_accuracy: 0.9440\n",
      "Epoch 376/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0894 - accuracy: 0.9730 - val_loss: 0.1979 - val_accuracy: 0.9440\n",
      "Epoch 377/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0865 - accuracy: 0.9786 - val_loss: 0.1979 - val_accuracy: 0.9440\n",
      "Epoch 378/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0853 - accuracy: 0.9827 - val_loss: 0.1979 - val_accuracy: 0.9440\n",
      "Epoch 379/600\n",
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0931 - accuracy: 0.9724 - val_loss: 0.1980 - val_accuracy: 0.9440\n",
      "Epoch 380/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0785 - accuracy: 0.9801 - val_loss: 0.1980 - val_accuracy: 0.9440\n",
      "Epoch 381/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0919 - accuracy: 0.9765 - val_loss: 0.1980 - val_accuracy: 0.9440\n",
      "Epoch 382/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0883 - accuracy: 0.9776 - val_loss: 0.1981 - val_accuracy: 0.9440\n",
      "Epoch 383/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.1001 - accuracy: 0.9673 - val_loss: 0.1981 - val_accuracy: 0.9440\n",
      "Epoch 384/600\n",
      "1960/1960 [==============================] - 2s 847us/sample - loss: 0.1005 - accuracy: 0.9684 - val_loss: 0.1982 - val_accuracy: 0.9440\n",
      "Epoch 385/600\n",
      "1960/1960 [==============================] - 2s 901us/sample - loss: 0.0971 - accuracy: 0.9750 - val_loss: 0.1982 - val_accuracy: 0.9440\n",
      "Epoch 386/600\n",
      "1960/1960 [==============================] - 2s 826us/sample - loss: 0.0885 - accuracy: 0.9735 - val_loss: 0.1983 - val_accuracy: 0.9440\n",
      "Epoch 387/600\n",
      "1960/1960 [==============================] - 2s 858us/sample - loss: 0.0897 - accuracy: 0.9770 - val_loss: 0.1983 - val_accuracy: 0.9440\n",
      "Epoch 388/600\n",
      "1960/1960 [==============================] - 2s 829us/sample - loss: 0.1018 - accuracy: 0.9724 - val_loss: 0.1983 - val_accuracy: 0.9440\n",
      "Epoch 389/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.1003 - accuracy: 0.9750 - val_loss: 0.1983 - val_accuracy: 0.9440\n",
      "Epoch 390/600\n",
      "1960/1960 [==============================] - 2s 836us/sample - loss: 0.0945 - accuracy: 0.9765 - val_loss: 0.1984 - val_accuracy: 0.9440\n",
      "Epoch 391/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0780 - accuracy: 0.9781 - val_loss: 0.1984 - val_accuracy: 0.9440\n",
      "Epoch 392/600\n",
      "1960/1960 [==============================] - 2s 845us/sample - loss: 0.0897 - accuracy: 0.9730 - val_loss: 0.1985 - val_accuracy: 0.9440\n",
      "Epoch 393/600\n",
      "1960/1960 [==============================] - 1s 757us/sample - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.1985 - val_accuracy: 0.9440\n",
      "Epoch 394/600\n",
      "1960/1960 [==============================] - 2s 842us/sample - loss: 0.0864 - accuracy: 0.9776 - val_loss: 0.1986 - val_accuracy: 0.9440\n",
      "Epoch 395/600\n",
      "1960/1960 [==============================] - 2s 854us/sample - loss: 0.0888 - accuracy: 0.9719 - val_loss: 0.1986 - val_accuracy: 0.9440\n",
      "Epoch 396/600\n",
      "1960/1960 [==============================] - 2s 840us/sample - loss: 0.1062 - accuracy: 0.9699 - val_loss: 0.1987 - val_accuracy: 0.9440\n",
      "Epoch 397/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0841 - accuracy: 0.9786 - val_loss: 0.1987 - val_accuracy: 0.9440\n",
      "Epoch 398/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.0921 - accuracy: 0.9745 - val_loss: 0.1988 - val_accuracy: 0.9440\n",
      "Epoch 399/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.0848 - accuracy: 0.9765 - val_loss: 0.1989 - val_accuracy: 0.9440\n",
      "Epoch 400/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.1029 - accuracy: 0.9694 - val_loss: 0.1989 - val_accuracy: 0.9440\n",
      "Epoch 401/600\n",
      "1960/1960 [==============================] - 2s 816us/sample - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.1990 - val_accuracy: 0.9440\n",
      "Epoch 402/600\n",
      "1960/1960 [==============================] - 1s 755us/sample - loss: 0.0850 - accuracy: 0.9776 - val_loss: 0.1991 - val_accuracy: 0.9440\n",
      "Epoch 403/600\n",
      "1960/1960 [==============================] - 2s 819us/sample - loss: 0.0847 - accuracy: 0.9776 - val_loss: 0.1992 - val_accuracy: 0.9440\n",
      "Epoch 404/600\n",
      "1960/1960 [==============================] - 2s 942us/sample - loss: 0.0750 - accuracy: 0.9801 - val_loss: 0.1993 - val_accuracy: 0.9440\n",
      "Epoch 405/600\n",
      "1960/1960 [==============================] - 2s 843us/sample - loss: 0.0885 - accuracy: 0.9740 - val_loss: 0.1993 - val_accuracy: 0.9440\n",
      "Epoch 406/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0920 - accuracy: 0.9730 - val_loss: 0.1994 - val_accuracy: 0.9440\n",
      "Epoch 407/600\n",
      "1960/1960 [==============================] - 2s 883us/sample - loss: 0.0820 - accuracy: 0.9796 - val_loss: 0.1995 - val_accuracy: 0.9440\n",
      "Epoch 408/600\n",
      "1960/1960 [==============================] - 2s 793us/sample - loss: 0.0936 - accuracy: 0.9770 - val_loss: 0.1996 - val_accuracy: 0.9440\n",
      "Epoch 409/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0950 - accuracy: 0.9730 - val_loss: 0.1997 - val_accuracy: 0.9440\n",
      "Epoch 410/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0925 - accuracy: 0.9760 - val_loss: 0.1998 - val_accuracy: 0.9440\n",
      "Epoch 411/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0824 - accuracy: 0.9786 - val_loss: 0.1999 - val_accuracy: 0.9440\n",
      "Epoch 412/600\n",
      "1960/1960 [==============================] - 2s 824us/sample - loss: 0.0939 - accuracy: 0.9750 - val_loss: 0.1999 - val_accuracy: 0.9440\n",
      "Epoch 413/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0891 - accuracy: 0.9755 - val_loss: 0.2000 - val_accuracy: 0.9440\n",
      "Epoch 414/600\n",
      "1960/1960 [==============================] - 2s 840us/sample - loss: 0.0847 - accuracy: 0.9724 - val_loss: 0.2000 - val_accuracy: 0.9452\n",
      "Epoch 415/600\n",
      "1960/1960 [==============================] - 2s 855us/sample - loss: 0.0876 - accuracy: 0.9755 - val_loss: 0.2001 - val_accuracy: 0.9452\n",
      "Epoch 416/600\n",
      "1960/1960 [==============================] - 2s 858us/sample - loss: 0.0858 - accuracy: 0.9735 - val_loss: 0.2001 - val_accuracy: 0.9452\n",
      "Epoch 417/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0895 - accuracy: 0.9760 - val_loss: 0.2001 - val_accuracy: 0.9452\n",
      "Epoch 418/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0934 - accuracy: 0.9730 - val_loss: 0.2002 - val_accuracy: 0.9452\n",
      "Epoch 419/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0800 - accuracy: 0.9801 - val_loss: 0.2002 - val_accuracy: 0.9452\n",
      "Epoch 420/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0882 - accuracy: 0.9770 - val_loss: 0.2002 - val_accuracy: 0.9452\n",
      "Epoch 421/600\n",
      "1960/1960 [==============================] - 2s 843us/sample - loss: 0.0878 - accuracy: 0.9755 - val_loss: 0.2002 - val_accuracy: 0.9452\n",
      "Epoch 422/600\n",
      "1960/1960 [==============================] - 2s 887us/sample - loss: 0.0982 - accuracy: 0.9704 - val_loss: 0.2003 - val_accuracy: 0.9452\n",
      "Epoch 423/600\n",
      "1960/1960 [==============================] - 2s 846us/sample - loss: 0.0786 - accuracy: 0.9796 - val_loss: 0.2003 - val_accuracy: 0.9452\n",
      "Epoch 424/600\n",
      "1960/1960 [==============================] - 2s 864us/sample - loss: 0.0894 - accuracy: 0.9760 - val_loss: 0.2003 - val_accuracy: 0.9452\n",
      "Epoch 425/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.0875 - accuracy: 0.9781 - val_loss: 0.2003 - val_accuracy: 0.9452\n",
      "Epoch 426/600\n",
      "1960/1960 [==============================] - 2s 867us/sample - loss: 0.0952 - accuracy: 0.9745 - val_loss: 0.2004 - val_accuracy: 0.9452\n",
      "Epoch 427/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0968 - accuracy: 0.9760 - val_loss: 0.2004 - val_accuracy: 0.9452\n",
      "Epoch 428/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0873 - accuracy: 0.9740 - val_loss: 0.2004 - val_accuracy: 0.9452\n",
      "Epoch 429/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.0941 - accuracy: 0.9724 - val_loss: 0.2005 - val_accuracy: 0.9452\n",
      "Epoch 430/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0929 - accuracy: 0.9765 - val_loss: 0.2006 - val_accuracy: 0.9452\n",
      "Epoch 431/600\n",
      "1960/1960 [==============================] - 2s 817us/sample - loss: 0.0970 - accuracy: 0.9750 - val_loss: 0.2006 - val_accuracy: 0.9452\n",
      "Epoch 432/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0961 - accuracy: 0.9704 - val_loss: 0.2006 - val_accuracy: 0.9452\n",
      "Epoch 433/600\n",
      "1960/1960 [==============================] - 2s 852us/sample - loss: 0.0871 - accuracy: 0.9786 - val_loss: 0.2007 - val_accuracy: 0.9452\n",
      "Epoch 434/600\n",
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.0841 - accuracy: 0.9791 - val_loss: 0.2007 - val_accuracy: 0.9452\n",
      "Epoch 435/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.2007 - val_accuracy: 0.9452\n",
      "Epoch 436/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 866us/sample - loss: 0.0882 - accuracy: 0.9765 - val_loss: 0.2008 - val_accuracy: 0.9452\n",
      "Epoch 437/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.0814 - accuracy: 0.9801 - val_loss: 0.2008 - val_accuracy: 0.9452\n",
      "Epoch 438/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0762 - accuracy: 0.9765 - val_loss: 0.2008 - val_accuracy: 0.9452\n",
      "Epoch 439/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0797 - accuracy: 0.9786 - val_loss: 0.2009 - val_accuracy: 0.9452\n",
      "Epoch 440/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0957 - accuracy: 0.9704 - val_loss: 0.2009 - val_accuracy: 0.9452\n",
      "Epoch 441/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0916 - accuracy: 0.9765 - val_loss: 0.2009 - val_accuracy: 0.9452\n",
      "Epoch 442/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0952 - accuracy: 0.9724 - val_loss: 0.2010 - val_accuracy: 0.9452\n",
      "Epoch 443/600\n",
      "1960/1960 [==============================] - 2s 861us/sample - loss: 0.0787 - accuracy: 0.9811 - val_loss: 0.2010 - val_accuracy: 0.9452\n",
      "Epoch 444/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0918 - accuracy: 0.9730 - val_loss: 0.2010 - val_accuracy: 0.9452\n",
      "Epoch 445/600\n",
      "1960/1960 [==============================] - 2s 840us/sample - loss: 0.0804 - accuracy: 0.9796 - val_loss: 0.2010 - val_accuracy: 0.9452\n",
      "Epoch 446/600\n",
      "1960/1960 [==============================] - 2s 840us/sample - loss: 0.0946 - accuracy: 0.9770 - val_loss: 0.2010 - val_accuracy: 0.9452\n",
      "Epoch 447/600\n",
      "1960/1960 [==============================] - 2s 783us/sample - loss: 0.0797 - accuracy: 0.9776 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 448/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0924 - accuracy: 0.9714 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 449/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0930 - accuracy: 0.9740 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 450/600\n",
      "1960/1960 [==============================] - 2s 797us/sample - loss: 0.0997 - accuracy: 0.9704 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 451/600\n",
      "1960/1960 [==============================] - 2s 776us/sample - loss: 0.0803 - accuracy: 0.9811 - val_loss: 0.2011 - val_accuracy: 0.9452\n",
      "Epoch 452/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.1041 - accuracy: 0.9735 - val_loss: 0.2012 - val_accuracy: 0.9452\n",
      "Epoch 453/600\n",
      "1960/1960 [==============================] - 2s 903us/sample - loss: 0.0937 - accuracy: 0.9735 - val_loss: 0.2012 - val_accuracy: 0.9452\n",
      "Epoch 454/600\n",
      "1960/1960 [==============================] - 2s 853us/sample - loss: 0.0959 - accuracy: 0.9735 - val_loss: 0.2012 - val_accuracy: 0.9452\n",
      "Epoch 455/600\n",
      "1960/1960 [==============================] - 2s 858us/sample - loss: 0.0837 - accuracy: 0.9770 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 456/600\n",
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.0854 - accuracy: 0.9786 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 457/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0884 - accuracy: 0.9770 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 458/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.0922 - accuracy: 0.9735 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 459/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.0895 - accuracy: 0.9760 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 460/600\n",
      "1960/1960 [==============================] - 2s 789us/sample - loss: 0.0871 - accuracy: 0.9786 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 461/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0966 - accuracy: 0.9719 - val_loss: 0.2013 - val_accuracy: 0.9452\n",
      "Epoch 462/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0887 - accuracy: 0.9745 - val_loss: 0.2014 - val_accuracy: 0.9452\n",
      "Epoch 463/600\n",
      "1960/1960 [==============================] - 2s 846us/sample - loss: 0.0842 - accuracy: 0.9760 - val_loss: 0.2014 - val_accuracy: 0.9452\n",
      "Epoch 464/600\n",
      "1960/1960 [==============================] - 2s 861us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.2015 - val_accuracy: 0.9452\n",
      "Epoch 465/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0882 - accuracy: 0.9770 - val_loss: 0.2015 - val_accuracy: 0.9452\n",
      "Epoch 466/600\n",
      "1960/1960 [==============================] - 2s 830us/sample - loss: 0.1009 - accuracy: 0.9658 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 467/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.0924 - accuracy: 0.9724 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 468/600\n",
      "1960/1960 [==============================] - 2s 819us/sample - loss: 0.1028 - accuracy: 0.9694 - val_loss: 0.2016 - val_accuracy: 0.9452\n",
      "Epoch 469/600\n",
      "1960/1960 [==============================] - 2s 802us/sample - loss: 0.1021 - accuracy: 0.9689 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 470/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0968 - accuracy: 0.9735 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 471/600\n",
      "1960/1960 [==============================] - 2s 775us/sample - loss: 0.0883 - accuracy: 0.9781 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 472/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0938 - accuracy: 0.9740 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 473/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0829 - accuracy: 0.9786 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 474/600\n",
      "1960/1960 [==============================] - 2s 848us/sample - loss: 0.0998 - accuracy: 0.9699 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 475/600\n",
      "1960/1960 [==============================] - 2s 852us/sample - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 476/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.1016 - accuracy: 0.9673 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
      "Epoch 477/600\n",
      "1960/1960 [==============================] - 2s 793us/sample - loss: 0.0939 - accuracy: 0.9745 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 478/600\n",
      "1960/1960 [==============================] - 2s 771us/sample - loss: 0.0872 - accuracy: 0.9765 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 479/600\n",
      "1960/1960 [==============================] - 2s 791us/sample - loss: 0.0837 - accuracy: 0.9760 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 480/600\n",
      "1960/1960 [==============================] - 2s 812us/sample - loss: 0.0827 - accuracy: 0.9740 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 481/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0833 - accuracy: 0.9791 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 482/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0999 - accuracy: 0.9740 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 483/600\n",
      "1960/1960 [==============================] - 2s 838us/sample - loss: 0.0854 - accuracy: 0.9755 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 484/600\n",
      "1960/1960 [==============================] - 2s 822us/sample - loss: 0.0879 - accuracy: 0.9735 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 485/600\n",
      "1960/1960 [==============================] - 2s 846us/sample - loss: 0.0938 - accuracy: 0.9730 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 486/600\n",
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.1006 - accuracy: 0.9704 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 487/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0876 - accuracy: 0.9801 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 488/600\n",
      "1960/1960 [==============================] - 2s 801us/sample - loss: 0.0967 - accuracy: 0.9755 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 489/600\n",
      "1960/1960 [==============================] - 1s 760us/sample - loss: 0.0940 - accuracy: 0.9745 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 490/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0912 - accuracy: 0.9730 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 491/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0790 - accuracy: 0.9781 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 492/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0888 - accuracy: 0.9740 - val_loss: 0.2018 - val_accuracy: 0.9452\n",
      "Epoch 493/600\n",
      "1960/1960 [==============================] - 2s 863us/sample - loss: 0.0951 - accuracy: 0.9730 - val_loss: 0.2018 - val_accuracy: 0.9440\n",
      "Epoch 494/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0905 - accuracy: 0.9735 - val_loss: 0.2018 - val_accuracy: 0.9440\n",
      "Epoch 495/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0902 - accuracy: 0.9735 - val_loss: 0.2019 - val_accuracy: 0.9440\n",
      "Epoch 496/600\n",
      "1960/1960 [==============================] - 2s 901us/sample - loss: 0.0712 - accuracy: 0.9832 - val_loss: 0.2019 - val_accuracy: 0.9440\n",
      "Epoch 497/600\n",
      "1960/1960 [==============================] - 2s 787us/sample - loss: 0.1061 - accuracy: 0.9694 - val_loss: 0.2019 - val_accuracy: 0.9452\n",
      "Epoch 498/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0918 - accuracy: 0.9724 - val_loss: 0.2020 - val_accuracy: 0.9452\n",
      "Epoch 499/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0931 - accuracy: 0.9730 - val_loss: 0.2020 - val_accuracy: 0.9452\n",
      "Epoch 500/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0892 - accuracy: 0.9730 - val_loss: 0.2021 - val_accuracy: 0.9452\n",
      "Epoch 501/600\n",
      "1960/1960 [==============================] - 2s 769us/sample - loss: 0.0755 - accuracy: 0.9776 - val_loss: 0.2021 - val_accuracy: 0.9452\n",
      "Epoch 502/600\n",
      "1960/1960 [==============================] - 2s 826us/sample - loss: 0.0835 - accuracy: 0.9755 - val_loss: 0.2021 - val_accuracy: 0.9452\n",
      "Epoch 503/600\n",
      "1960/1960 [==============================] - 2s 805us/sample - loss: 0.0750 - accuracy: 0.9837 - val_loss: 0.2022 - val_accuracy: 0.9452\n",
      "Epoch 504/600\n",
      "1960/1960 [==============================] - 2s 824us/sample - loss: 0.0989 - accuracy: 0.9745 - val_loss: 0.2022 - val_accuracy: 0.9452\n",
      "Epoch 505/600\n",
      "1960/1960 [==============================] - 2s 857us/sample - loss: 0.0992 - accuracy: 0.9740 - val_loss: 0.2023 - val_accuracy: 0.9452\n",
      "Epoch 506/600\n",
      "1960/1960 [==============================] - 2s 891us/sample - loss: 0.0845 - accuracy: 0.9770 - val_loss: 0.2023 - val_accuracy: 0.9452\n",
      "Epoch 507/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0962 - accuracy: 0.9724 - val_loss: 0.2023 - val_accuracy: 0.9452\n",
      "Epoch 508/600\n",
      "1960/1960 [==============================] - 2s 816us/sample - loss: 0.0881 - accuracy: 0.9776 - val_loss: 0.2023 - val_accuracy: 0.9452\n",
      "Epoch 509/600\n",
      "1960/1960 [==============================] - 2s 786us/sample - loss: 0.0908 - accuracy: 0.9760 - val_loss: 0.2024 - val_accuracy: 0.9452\n",
      "Epoch 510/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0914 - accuracy: 0.9714 - val_loss: 0.2024 - val_accuracy: 0.9452\n",
      "Epoch 511/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0933 - accuracy: 0.9735 - val_loss: 0.2024 - val_accuracy: 0.9452\n",
      "Epoch 512/600\n",
      "1960/1960 [==============================] - 2s 773us/sample - loss: 0.0979 - accuracy: 0.9755 - val_loss: 0.2025 - val_accuracy: 0.9452\n",
      "Epoch 513/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.1037 - accuracy: 0.9689 - val_loss: 0.2025 - val_accuracy: 0.9452\n",
      "Epoch 514/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0903 - accuracy: 0.9745 - val_loss: 0.2026 - val_accuracy: 0.9452\n",
      "Epoch 515/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0777 - accuracy: 0.9821 - val_loss: 0.2027 - val_accuracy: 0.9452\n",
      "Epoch 516/600\n",
      "1960/1960 [==============================] - 2s 889us/sample - loss: 0.1010 - accuracy: 0.9719 - val_loss: 0.2027 - val_accuracy: 0.9452\n",
      "Epoch 517/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0902 - accuracy: 0.9730 - val_loss: 0.2028 - val_accuracy: 0.9452\n",
      "Epoch 518/600\n",
      "1960/1960 [==============================] - 1s 761us/sample - loss: 0.0906 - accuracy: 0.9735 - val_loss: 0.2028 - val_accuracy: 0.9452\n",
      "Epoch 519/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0982 - accuracy: 0.9704 - val_loss: 0.2029 - val_accuracy: 0.9452\n",
      "Epoch 520/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0898 - accuracy: 0.9735 - val_loss: 0.2029 - val_accuracy: 0.9452\n",
      "Epoch 521/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0769 - accuracy: 0.9796 - val_loss: 0.2029 - val_accuracy: 0.9452\n",
      "Epoch 522/600\n",
      "1960/1960 [==============================] - 2s 806us/sample - loss: 0.0994 - accuracy: 0.9719 - val_loss: 0.2029 - val_accuracy: 0.9452\n",
      "Epoch 523/600\n",
      "1960/1960 [==============================] - 2s 821us/sample - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.2030 - val_accuracy: 0.9452\n",
      "Epoch 524/600\n",
      "1960/1960 [==============================] - 2s 841us/sample - loss: 0.0916 - accuracy: 0.9755 - val_loss: 0.2030 - val_accuracy: 0.9440\n",
      "Epoch 525/600\n",
      "1960/1960 [==============================] - 2s 832us/sample - loss: 0.0833 - accuracy: 0.9776 - val_loss: 0.2030 - val_accuracy: 0.9440\n",
      "Epoch 526/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.0871 - accuracy: 0.9776 - val_loss: 0.2031 - val_accuracy: 0.9440\n",
      "Epoch 527/600\n",
      "1960/1960 [==============================] - 2s 803us/sample - loss: 0.0895 - accuracy: 0.9770 - val_loss: 0.2032 - val_accuracy: 0.9429\n",
      "Epoch 528/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0979 - accuracy: 0.9745 - val_loss: 0.2032 - val_accuracy: 0.9429\n",
      "Epoch 529/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.0771 - accuracy: 0.9832 - val_loss: 0.2033 - val_accuracy: 0.9429\n",
      "Epoch 530/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0892 - accuracy: 0.9735 - val_loss: 0.2033 - val_accuracy: 0.9429\n",
      "Epoch 531/600\n",
      "1960/1960 [==============================] - 2s 828us/sample - loss: 0.0761 - accuracy: 0.9796 - val_loss: 0.2034 - val_accuracy: 0.9429\n",
      "Epoch 532/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.0816 - accuracy: 0.9745 - val_loss: 0.2035 - val_accuracy: 0.9429\n",
      "Epoch 533/600\n",
      "1960/1960 [==============================] - 2s 870us/sample - loss: 0.0780 - accuracy: 0.9781 - val_loss: 0.2035 - val_accuracy: 0.9429\n",
      "Epoch 534/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.0895 - accuracy: 0.9765 - val_loss: 0.2035 - val_accuracy: 0.9429\n",
      "Epoch 535/600\n",
      "1960/1960 [==============================] - 2s 838us/sample - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.2035 - val_accuracy: 0.9429\n",
      "Epoch 536/600\n",
      "1960/1960 [==============================] - 2s 871us/sample - loss: 0.0919 - accuracy: 0.9740 - val_loss: 0.2035 - val_accuracy: 0.9429\n",
      "Epoch 537/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0848 - accuracy: 0.9776 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 538/600\n",
      "1960/1960 [==============================] - 2s 813us/sample - loss: 0.0915 - accuracy: 0.9760 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 539/600\n",
      "1960/1960 [==============================] - 2s 789us/sample - loss: 0.0952 - accuracy: 0.9745 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 540/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.0902 - accuracy: 0.9750 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 541/600\n",
      "1960/1960 [==============================] - 2s 795us/sample - loss: 0.0842 - accuracy: 0.9791 - val_loss: 0.2036 - val_accuracy: 0.9429\n",
      "Epoch 542/600\n",
      "1960/1960 [==============================] - 2s 837us/sample - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.2037 - val_accuracy: 0.9429\n",
      "Epoch 543/600\n",
      "1960/1960 [==============================] - 2s 871us/sample - loss: 0.0962 - accuracy: 0.9750 - val_loss: 0.2037 - val_accuracy: 0.9429\n",
      "Epoch 544/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 2s 882us/sample - loss: 0.0987 - accuracy: 0.9709 - val_loss: 0.2037 - val_accuracy: 0.9429\n",
      "Epoch 545/600\n",
      "1960/1960 [==============================] - 2s 812us/sample - loss: 0.0840 - accuracy: 0.9786 - val_loss: 0.2037 - val_accuracy: 0.9429\n",
      "Epoch 546/600\n",
      "1960/1960 [==============================] - 2s 856us/sample - loss: 0.0790 - accuracy: 0.9776 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 547/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.0827 - accuracy: 0.9765 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 548/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.0909 - accuracy: 0.9755 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 549/600\n",
      "1960/1960 [==============================] - 2s 778us/sample - loss: 0.0931 - accuracy: 0.9765 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 550/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0881 - accuracy: 0.9735 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 551/600\n",
      "1960/1960 [==============================] - 2s 779us/sample - loss: 0.0694 - accuracy: 0.9832 - val_loss: 0.2038 - val_accuracy: 0.9429\n",
      "Epoch 552/600\n",
      "1960/1960 [==============================] - 2s 851us/sample - loss: 0.0870 - accuracy: 0.9755 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 553/600\n",
      "1960/1960 [==============================] - 2s 879us/sample - loss: 0.0946 - accuracy: 0.9740 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 554/600\n",
      "1960/1960 [==============================] - 2s 850us/sample - loss: 0.0810 - accuracy: 0.9806 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 555/600\n",
      "1960/1960 [==============================] - 2s 869us/sample - loss: 0.0870 - accuracy: 0.9776 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 556/600\n",
      "1960/1960 [==============================] - 2s 869us/sample - loss: 0.0912 - accuracy: 0.9770 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 557/600\n",
      "1960/1960 [==============================] - 2s 780us/sample - loss: 0.0809 - accuracy: 0.9786 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 558/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0802 - accuracy: 0.9786 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 559/600\n",
      "1960/1960 [==============================] - 2s 781us/sample - loss: 0.0847 - accuracy: 0.9796 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 560/600\n",
      "1960/1960 [==============================] - 2s 770us/sample - loss: 0.0901 - accuracy: 0.9765 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 561/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0819 - accuracy: 0.9781 - val_loss: 0.2039 - val_accuracy: 0.9440\n",
      "Epoch 562/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0941 - accuracy: 0.9724 - val_loss: 0.2039 - val_accuracy: 0.9440\n",
      "Epoch 563/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0956 - accuracy: 0.9760 - val_loss: 0.2039 - val_accuracy: 0.9440\n",
      "Epoch 564/600\n",
      "1960/1960 [==============================] - 2s 839us/sample - loss: 0.0791 - accuracy: 0.9770 - val_loss: 0.2038 - val_accuracy: 0.9440\n",
      "Epoch 565/600\n",
      "1960/1960 [==============================] - 2s 821us/sample - loss: 0.0955 - accuracy: 0.9760 - val_loss: 0.2039 - val_accuracy: 0.9440\n",
      "Epoch 566/600\n",
      "1960/1960 [==============================] - 2s 868us/sample - loss: 0.0768 - accuracy: 0.9745 - val_loss: 0.2039 - val_accuracy: 0.9452\n",
      "Epoch 567/600\n",
      "1960/1960 [==============================] - 2s 823us/sample - loss: 0.0790 - accuracy: 0.9827 - val_loss: 0.2040 - val_accuracy: 0.9452\n",
      "Epoch 568/600\n",
      "1960/1960 [==============================] - 2s 807us/sample - loss: 0.0893 - accuracy: 0.9740 - val_loss: 0.2040 - val_accuracy: 0.9452\n",
      "Epoch 569/600\n",
      "1960/1960 [==============================] - 2s 774us/sample - loss: 0.0843 - accuracy: 0.9770 - val_loss: 0.2041 - val_accuracy: 0.9452\n",
      "Epoch 570/600\n",
      "1960/1960 [==============================] - 2s 814us/sample - loss: 0.0886 - accuracy: 0.9770 - val_loss: 0.2041 - val_accuracy: 0.9452\n",
      "Epoch 571/600\n",
      "1960/1960 [==============================] - 2s 784us/sample - loss: 0.0865 - accuracy: 0.9776 - val_loss: 0.2041 - val_accuracy: 0.9452\n",
      "Epoch 572/600\n",
      "1960/1960 [==============================] - 2s 796us/sample - loss: 0.0826 - accuracy: 0.9806 - val_loss: 0.2042 - val_accuracy: 0.9452\n",
      "Epoch 573/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0936 - accuracy: 0.9760 - val_loss: 0.2042 - val_accuracy: 0.9452\n",
      "Epoch 574/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0789 - accuracy: 0.9786 - val_loss: 0.2042 - val_accuracy: 0.9452\n",
      "Epoch 575/600\n",
      "1960/1960 [==============================] - 2s 845us/sample - loss: 0.1005 - accuracy: 0.9745 - val_loss: 0.2042 - val_accuracy: 0.9452\n",
      "Epoch 576/600\n",
      "1960/1960 [==============================] - 2s 842us/sample - loss: 0.0807 - accuracy: 0.9776 - val_loss: 0.2043 - val_accuracy: 0.9452\n",
      "Epoch 577/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.0855 - accuracy: 0.9760 - val_loss: 0.2043 - val_accuracy: 0.9452\n",
      "Epoch 578/600\n",
      "1960/1960 [==============================] - 2s 782us/sample - loss: 0.0820 - accuracy: 0.9791 - val_loss: 0.2043 - val_accuracy: 0.9452\n",
      "Epoch 579/600\n",
      "1960/1960 [==============================] - 2s 800us/sample - loss: 0.0962 - accuracy: 0.9730 - val_loss: 0.2044 - val_accuracy: 0.9452\n",
      "Epoch 580/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.2044 - val_accuracy: 0.9452\n",
      "Epoch 581/600\n",
      "1960/1960 [==============================] - 2s 825us/sample - loss: 0.0843 - accuracy: 0.9765 - val_loss: 0.2044 - val_accuracy: 0.9452\n",
      "Epoch 582/600\n",
      "1960/1960 [==============================] - 2s 827us/sample - loss: 0.0797 - accuracy: 0.9796 - val_loss: 0.2044 - val_accuracy: 0.9452\n",
      "Epoch 583/600\n",
      "1960/1960 [==============================] - 2s 844us/sample - loss: 0.0849 - accuracy: 0.9821 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 584/600\n",
      "1960/1960 [==============================] - 2s 818us/sample - loss: 0.0859 - accuracy: 0.9740 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 585/600\n",
      "1960/1960 [==============================] - 2s 862us/sample - loss: 0.0823 - accuracy: 0.9776 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 586/600\n",
      "1960/1960 [==============================] - 2s 785us/sample - loss: 0.0933 - accuracy: 0.9699 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 587/600\n",
      "1960/1960 [==============================] - 2s 794us/sample - loss: 0.0932 - accuracy: 0.9740 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 588/600\n",
      "1960/1960 [==============================] - 2s 772us/sample - loss: 0.0856 - accuracy: 0.9781 - val_loss: 0.2045 - val_accuracy: 0.9452\n",
      "Epoch 589/600\n",
      "1960/1960 [==============================] - 2s 775us/sample - loss: 0.0834 - accuracy: 0.9745 - val_loss: 0.2046 - val_accuracy: 0.9452\n",
      "Epoch 590/600\n",
      "1960/1960 [==============================] - 2s 790us/sample - loss: 0.1010 - accuracy: 0.9735 - val_loss: 0.2046 - val_accuracy: 0.9452\n",
      "Epoch 591/600\n",
      "1960/1960 [==============================] - 2s 792us/sample - loss: 0.0874 - accuracy: 0.9791 - val_loss: 0.2046 - val_accuracy: 0.9452\n",
      "Epoch 592/600\n",
      "1960/1960 [==============================] - 2s 799us/sample - loss: 0.0939 - accuracy: 0.9770 - val_loss: 0.2047 - val_accuracy: 0.9452\n",
      "Epoch 593/600\n",
      "1960/1960 [==============================] - 2s 845us/sample - loss: 0.0961 - accuracy: 0.9750 - val_loss: 0.2047 - val_accuracy: 0.9452\n",
      "Epoch 594/600\n",
      "1960/1960 [==============================] - 2s 865us/sample - loss: 0.0920 - accuracy: 0.9770 - val_loss: 0.2048 - val_accuracy: 0.9452\n",
      "Epoch 595/600\n",
      "1960/1960 [==============================] - 2s 835us/sample - loss: 0.0975 - accuracy: 0.9740 - val_loss: 0.2048 - val_accuracy: 0.9452\n",
      "Epoch 596/600\n",
      "1960/1960 [==============================] - 2s 856us/sample - loss: 0.0872 - accuracy: 0.9704 - val_loss: 0.2048 - val_accuracy: 0.9452\n",
      "Epoch 597/600\n",
      "1960/1960 [==============================] - 2s 809us/sample - loss: 0.0917 - accuracy: 0.9730 - val_loss: 0.2048 - val_accuracy: 0.9452\n",
      "Epoch 598/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 1s 763us/sample - loss: 0.0874 - accuracy: 0.9740 - val_loss: 0.2049 - val_accuracy: 0.9452\n",
      "Epoch 599/600\n",
      "1960/1960 [==============================] - 2s 788us/sample - loss: 0.1001 - accuracy: 0.9699 - val_loss: 0.2049 - val_accuracy: 0.9452\n",
      "Epoch 600/600\n",
      "1960/1960 [==============================] - 1s 765us/sample - loss: 0.0915 - accuracy: 0.9760 - val_loss: 0.2050 - val_accuracy: 0.9452\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_Net.save_weights('weights/coarse_lite.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With frame_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    print('epoch{}'.format(e))\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in tqdm(range(len(Train['pose']))): \n",
    "\n",
    "        label = np.zeros(C.clc_coarse)\n",
    "        label[Train['coarse_label'][i]-1] = 1 \n",
    "        \n",
    "        p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "        p = sampling_frame(p,C)\n",
    "        \n",
    "        M = get_CG(p,C)\n",
    "        \n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "   \n",
    "\n",
    "    DD_Net.fit([X_0,X_1],Y,\n",
    "            batch_size=len(Y),\n",
    "            epochs=1,\n",
    "            verbose=True,\n",
    "            shuffle=True,\n",
    "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate time (excute it twice, the first time initialize takes extra times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "y = DD_Net.predict([X_0,X_1])\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAI/CAYAAACf7mYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n24bnetkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = DD_Net.predict([X_test_0,X_test_1])\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(Y_pred,axis=1))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
