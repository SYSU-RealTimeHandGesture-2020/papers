{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import gc\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "# from tensorflow.keras.layers.core import *\n",
    "# from tensorflow.keras.layers.convolutional import *\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.frame_l = 32 # the length of frames\n",
    "        self.joint_n = 21 # the number of joints\n",
    "        self.joint_d = 2 # the dimension of joints\n",
    "        self.coarse = 27 # the number of coarse class\n",
    "        self.feat_d = 210 # n(n-1)/2\n",
    "        self.filters = 16\n",
    "        self.data_dir = '..\\\\data\\\\JESTER\\\\'\n",
    "C = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poses_diff(x):\n",
    "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
    "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
    "    x = tf.image.resize_nearest_neighbor(x,size=[H,W],align_corners=False) # should not alignment here\n",
    "    return x\n",
    "\n",
    "def pose_motion(P,frame_l,joint_n,joint_d):\n",
    "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
    "    P_diff_slow = Reshape((frame_l,joint_n*joint_d))(P_diff_slow)\n",
    "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
    "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
    "    P_diff_fast = Reshape((int(frame_l/2),joint_n*joint_d))(P_diff_fast)\n",
    "    return P_diff_slow,P_diff_fast\n",
    "    \n",
    "def c1D(x,filters,kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def block(x,filters):\n",
    "    x = c1D(x,filters,3)\n",
    "    x = c1D(x,filters,3)\n",
    "    return x\n",
    "    \n",
    "def d1D(x,filters):\n",
    "    x = Dense(filters,use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):   \n",
    "    M = Input(shape=(frame_l,feat_d))\n",
    "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
    "    \n",
    "    diff_slow,diff_fast = pose_motion(P,frame_l,joint_n,joint_d)\n",
    "\n",
    "    print(\"slow\", diff_slow)\n",
    "    print(\"fast\", diff_fast)\n",
    "    print(\"JCD\", M)\n",
    "\n",
    "    x = c1D(M,filters*2,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = c1D(x,filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,3)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "    x_d_slow = c1D(x_d_slow,filters,1)\n",
    "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
    "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
    "\n",
    "    # 测试删去x_d_fast\n",
    "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,3) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "    x_d_fast = c1D(x_d_fast,filters,1) \n",
    "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
    "   \n",
    "    x = concatenate([x,x_d_slow,x_d_fast]) # x = concatenate([x,x_d_slow,x_d_fast])\n",
    "    print('concat', x.shape)\n",
    "    x = block(x,filters*2)\n",
    "    print('conv1', x.shape)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    print('pool1', x.shape)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    x = block(x,filters*4)\n",
    "    print('conv2', x.shape)\n",
    "    x = MaxPool1D(2)(x)\n",
    "    print('pool2', x.shape)    \n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = block(x,filters*8)\n",
    "    print('conv3', x.shape)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    return Model(inputs=[M,P],outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
    "    M = Input(name='M', shape=(frame_l,feat_d))  \n",
    "    P = Input(name='P', shape=(frame_l,joint_n,joint_d)) \n",
    "    \n",
    "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
    "    \n",
    "    x = FM([M,P])\n",
    "\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    print('pool', x.shape)    \n",
    "\n",
    "    x = d1D(x,128)\n",
    "    print('dense1', x.shape)    \n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = d1D(x,128)\n",
    "    print('dense2', x.shape)    \n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(clc_num, activation='softmax')(x)\n",
    "    print('dense3', x.shape)    \n",
    "\n",
    "    ######################Self-supervised part\n",
    "    model = Model(inputs=[M,P],outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow Tensor(\"reshape/Identity:0\", shape=(None, 32, 42), dtype=float32)\n",
      "fast Tensor(\"reshape_1/Identity:0\", shape=(None, 16, 42), dtype=float32)\n",
      "JCD Tensor(\"input_1:0\", shape=(None, 32, 210), dtype=float32)\n",
      "concat (None, 16, 48)\n",
      "conv1 (None, 16, 32)\n",
      "pool1 (None, 8, 32)\n",
      "conv2 (None, 8, 64)\n",
      "pool2 (None, 4, 64)\n",
      "conv3 (None, 4, 128)\n",
      "pool (None, 128)\n",
      "dense1 (None, 128)\n",
      "dense2 (None, 128)\n",
      "dense3 (None, 27)\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.coarse,C.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "M (InputLayer)                  [(None, 32, 210)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "P (InputLayer)                  [(None, 32, 21, 2)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 4, 128)       117184      M[0][0]                          \n",
      "                                                                 P[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          16384       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16384       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 128)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 27)           3483        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 154,459\n",
      "Trainable params: 152,667\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换成无空帧数据\n",
    "Train = pickle.load(open(C.data_dir+\"train_noempty.pkl\", \"rb\"))\n",
    "Test = pickle.load(open(C.data_dir+\"valid_noempty.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without frame_sampling train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 680/680 [00:05<00:00, 121.50it/s]\n"
     ]
    }
   ],
   "source": [
    "X_0 = []\n",
    "X_1 = []\n",
    "Y = []\n",
    "for i in tqdm(range(len(Train['pose']))): \n",
    "    p = np.copy(Train['pose'][i]).reshape([-1,C.joint_n,C.joint_d])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range_2d(p)\n",
    "    \n",
    "    label = np.zeros(C.coarse)\n",
    "    label[Train['label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_0.append(M)\n",
    "    X_1.append(p)\n",
    "    Y.append(label)\n",
    "\n",
    "X_0 = np.stack(X_0)  \n",
    "X_1 = np.stack(X_1) \n",
    "Y = np.stack(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 32, 210) (680, 32, 21, 2) (680, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_0.shape, X_1.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 142.90it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_0 = []\n",
    "X_test_1 = []\n",
    "Y_test = []\n",
    "for i in tqdm(range(len(Test['pose']))): \n",
    "    p = np.copy(Test['pose'][i]).reshape([-1,C.joint_n,C.joint_d])\n",
    "    p = zoom(p,target_l=C.frame_l,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
    "    p = normlize_range_2d(p)\n",
    "    \n",
    "    label = np.zeros(C.coarse)\n",
    "    label[Test['label'][i]-1] = 1   \n",
    "\n",
    "    M = get_CG(p,C)\n",
    "\n",
    "    X_test_0.append(M)\n",
    "    X_test_1.append(p)\n",
    "    Y_test.append(label)\n",
    "\n",
    "X_test_0 = np.stack(X_test_0) \n",
    "X_test_1 = np.stack(X_test_1)  \n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 32, 210) (139, 32, 21, 2) (139, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_0.shape, X_test_1.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 680 samples, validate on 139 samples\n",
      "Epoch 1/600\n",
      "680/680 [==============================] - 9s 14ms/sample - loss: 2.5433 - accuracy: 0.2809 - val_loss: 2.8349 - val_accuracy: 0.1942\n",
      "Epoch 2/600\n",
      "680/680 [==============================] - 0s 687us/sample - loss: 2.5063 - accuracy: 0.2794 - val_loss: 2.8489 - val_accuracy: 0.1727\n",
      "Epoch 3/600\n",
      "680/680 [==============================] - 1s 754us/sample - loss: 2.4948 - accuracy: 0.2853 - val_loss: 2.8657 - val_accuracy: 0.1655\n",
      "Epoch 4/600\n",
      "680/680 [==============================] - 0s 662us/sample - loss: 2.4997 - accuracy: 0.2794 - val_loss: 2.8918 - val_accuracy: 0.1871\n",
      "Epoch 5/600\n",
      "680/680 [==============================] - 0s 714us/sample - loss: 2.4763 - accuracy: 0.2809 - val_loss: 2.9031 - val_accuracy: 0.1799\n",
      "Epoch 6/600\n",
      "680/680 [==============================] - 0s 703us/sample - loss: 2.4807 - accuracy: 0.2882 - val_loss: 2.9019 - val_accuracy: 0.1942\n",
      "Epoch 7/600\n",
      "680/680 [==============================] - 0s 632us/sample - loss: 2.4655 - accuracy: 0.2706 - val_loss: 2.8986 - val_accuracy: 0.2014\n",
      "Epoch 8/600\n",
      "680/680 [==============================] - 1s 824us/sample - loss: 2.4541 - accuracy: 0.2897 - val_loss: 2.8958 - val_accuracy: 0.1871\n",
      "Epoch 9/600\n",
      "680/680 [==============================] - 0s 708us/sample - loss: 2.4798 - accuracy: 0.2676 - val_loss: 2.8833 - val_accuracy: 0.1871\n",
      "Epoch 10/600\n",
      "680/680 [==============================] - 0s 678us/sample - loss: 2.4473 - accuracy: 0.2882 - val_loss: 2.8790 - val_accuracy: 0.1799\n",
      "Epoch 11/600\n",
      "680/680 [==============================] - 0s 627us/sample - loss: 2.4606 - accuracy: 0.2779 - val_loss: 2.8833 - val_accuracy: 0.1799\n",
      "Epoch 12/600\n",
      "680/680 [==============================] - 0s 594us/sample - loss: 2.3870 - accuracy: 0.2735 - val_loss: 2.9064 - val_accuracy: 0.1871\n",
      "Epoch 13/600\n",
      "680/680 [==============================] - 0s 699us/sample - loss: 2.3958 - accuracy: 0.3015 - val_loss: 2.9561 - val_accuracy: 0.2014\n",
      "Epoch 14/600\n",
      "680/680 [==============================] - 0s 638us/sample - loss: 2.4019 - accuracy: 0.3088 - val_loss: 2.9981 - val_accuracy: 0.1942\n",
      "Epoch 15/600\n",
      "680/680 [==============================] - 0s 677us/sample - loss: 2.3338 - accuracy: 0.3103 - val_loss: 3.0432 - val_accuracy: 0.1727\n",
      "Epoch 16/600\n",
      "680/680 [==============================] - 0s 610us/sample - loss: 2.3551 - accuracy: 0.3206 - val_loss: 3.0804 - val_accuracy: 0.1799\n",
      "Epoch 17/600\n",
      "680/680 [==============================] - 0s 632us/sample - loss: 2.3084 - accuracy: 0.3397 - val_loss: 3.0987 - val_accuracy: 0.1727\n",
      "Epoch 18/600\n",
      "680/680 [==============================] - 0s 679us/sample - loss: 2.3588 - accuracy: 0.3000 - val_loss: 3.0812 - val_accuracy: 0.1727\n",
      "Epoch 19/600\n",
      "680/680 [==============================] - 0s 734us/sample - loss: 2.2785 - accuracy: 0.3294 - val_loss: 3.0562 - val_accuracy: 0.2014\n",
      "Epoch 20/600\n",
      "680/680 [==============================] - 0s 649us/sample - loss: 2.2921 - accuracy: 0.3353 - val_loss: 3.0137 - val_accuracy: 0.1942\n",
      "Epoch 21/600\n",
      "680/680 [==============================] - 0s 629us/sample - loss: 2.2831 - accuracy: 0.3088 - val_loss: 2.9731 - val_accuracy: 0.2086\n",
      "Epoch 22/600\n",
      "680/680 [==============================] - 0s 619us/sample - loss: 2.2997 - accuracy: 0.3279 - val_loss: 2.9707 - val_accuracy: 0.2014\n",
      "Epoch 23/600\n",
      "680/680 [==============================] - 0s 681us/sample - loss: 2.2662 - accuracy: 0.3574 - val_loss: 2.9828 - val_accuracy: 0.2014\n",
      "Epoch 24/600\n",
      "680/680 [==============================] - 0s 632us/sample - loss: 2.2732 - accuracy: 0.3191 - val_loss: 2.9993 - val_accuracy: 0.2158\n",
      "Epoch 25/600\n",
      "680/680 [==============================] - 0s 663us/sample - loss: 2.2201 - accuracy: 0.3485 - val_loss: 3.0063 - val_accuracy: 0.2086\n",
      "Epoch 26/600\n",
      "680/680 [==============================] - 1s 762us/sample - loss: 2.2267 - accuracy: 0.3515 - val_loss: 3.0265 - val_accuracy: 0.2086\n",
      "Epoch 27/600\n",
      "680/680 [==============================] - 0s 680us/sample - loss: 2.2585 - accuracy: 0.3324 - val_loss: 3.0427 - val_accuracy: 0.2086\n",
      "Epoch 28/600\n",
      "680/680 [==============================] - 1s 760us/sample - loss: 2.1966 - accuracy: 0.3412 - val_loss: 3.0546 - val_accuracy: 0.2014\n",
      "Epoch 29/600\n",
      "680/680 [==============================] - 1s 767us/sample - loss: 2.1421 - accuracy: 0.3794 - val_loss: 3.0489 - val_accuracy: 0.1871\n",
      "Epoch 30/600\n",
      "680/680 [==============================] - 1s 769us/sample - loss: 2.1916 - accuracy: 0.3676 - val_loss: 3.0808 - val_accuracy: 0.1942\n",
      "Epoch 31/600\n",
      "680/680 [==============================] - 0s 719us/sample - loss: 2.2193 - accuracy: 0.3426 - val_loss: 3.0980 - val_accuracy: 0.1799\n",
      "Epoch 32/600\n",
      "680/680 [==============================] - 0s 617us/sample - loss: 2.1463 - accuracy: 0.3912 - val_loss: 3.1022 - val_accuracy: 0.1799\n",
      "Epoch 33/600\n",
      "680/680 [==============================] - 1s 783us/sample - loss: 2.1598 - accuracy: 0.3515 - val_loss: 3.1052 - val_accuracy: 0.1727\n",
      "Epoch 34/600\n",
      "680/680 [==============================] - 1s 761us/sample - loss: 2.0883 - accuracy: 0.3691 - val_loss: 3.1064 - val_accuracy: 0.1655\n",
      "Epoch 35/600\n",
      "680/680 [==============================] - 1s 802us/sample - loss: 2.0956 - accuracy: 0.3721 - val_loss: 3.1152 - val_accuracy: 0.1727\n",
      "Epoch 36/600\n",
      "680/680 [==============================] - 1s 821us/sample - loss: 2.1533 - accuracy: 0.3706 - val_loss: 3.1203 - val_accuracy: 0.1727\n",
      "Epoch 37/600\n",
      "680/680 [==============================] - 1s 747us/sample - loss: 2.1062 - accuracy: 0.3588 - val_loss: 3.1436 - val_accuracy: 0.1583\n",
      "Epoch 38/600\n",
      "680/680 [==============================] - 1s 786us/sample - loss: 2.0247 - accuracy: 0.4044 - val_loss: 3.1360 - val_accuracy: 0.1583\n",
      "Epoch 39/600\n",
      "680/680 [==============================] - 1s 867us/sample - loss: 2.0317 - accuracy: 0.3809 - val_loss: 3.1530 - val_accuracy: 0.1583\n",
      "Epoch 40/600\n",
      "680/680 [==============================] - 0s 722us/sample - loss: 2.0666 - accuracy: 0.4118 - val_loss: 3.1274 - val_accuracy: 0.1727\n",
      "Epoch 41/600\n",
      "680/680 [==============================] - 1s 769us/sample - loss: 2.0196 - accuracy: 0.3971 - val_loss: 3.1251 - val_accuracy: 0.1799\n",
      "Epoch 42/600\n",
      "680/680 [==============================] - 1s 783us/sample - loss: 1.9932 - accuracy: 0.4118 - val_loss: 3.1112 - val_accuracy: 0.1799\n",
      "Epoch 43/600\n",
      "680/680 [==============================] - 1s 739us/sample - loss: 1.9699 - accuracy: 0.4074 - val_loss: 3.1104 - val_accuracy: 0.1871\n",
      "Epoch 44/600\n",
      "680/680 [==============================] - 0s 734us/sample - loss: 1.9552 - accuracy: 0.4029 - val_loss: 3.1073 - val_accuracy: 0.1727\n",
      "Epoch 45/600\n",
      "680/680 [==============================] - 0s 692us/sample - loss: 1.9756 - accuracy: 0.4206 - val_loss: 3.0994 - val_accuracy: 0.1799\n",
      "Epoch 46/600\n",
      "680/680 [==============================] - 1s 840us/sample - loss: 1.9640 - accuracy: 0.4074 - val_loss: 3.1039 - val_accuracy: 0.1871\n",
      "Epoch 47/600\n",
      "680/680 [==============================] - 1s 830us/sample - loss: 1.9512 - accuracy: 0.4324 - val_loss: 3.1005 - val_accuracy: 0.1799\n",
      "Epoch 48/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 1.9304 - accuracy: 0.4265 - val_loss: 3.1075 - val_accuracy: 0.2014\n",
      "Epoch 49/600\n",
      "680/680 [==============================] - 0s 675us/sample - loss: 1.9813 - accuracy: 0.4191 - val_loss: 3.1242 - val_accuracy: 0.2014\n",
      "Epoch 50/600\n",
      "680/680 [==============================] - 1s 741us/sample - loss: 1.9068 - accuracy: 0.4250 - val_loss: 3.1317 - val_accuracy: 0.2086\n",
      "Epoch 51/600\n",
      "680/680 [==============================] - 0s 686us/sample - loss: 1.9324 - accuracy: 0.4309 - val_loss: 3.1401 - val_accuracy: 0.1942\n",
      "Epoch 52/600\n",
      "680/680 [==============================] - 0s 646us/sample - loss: 1.9167 - accuracy: 0.4221 - val_loss: 3.1510 - val_accuracy: 0.1942\n",
      "Epoch 53/600\n",
      "680/680 [==============================] - 1s 765us/sample - loss: 1.9212 - accuracy: 0.4206 - val_loss: 3.1828 - val_accuracy: 0.2014\n",
      "Epoch 54/600\n",
      "680/680 [==============================] - 0s 657us/sample - loss: 1.8330 - accuracy: 0.4500 - val_loss: 3.2157 - val_accuracy: 0.2014\n",
      "Epoch 55/600\n",
      "680/680 [==============================] - 0s 725us/sample - loss: 1.8991 - accuracy: 0.4382 - val_loss: 3.2155 - val_accuracy: 0.1942\n",
      "Epoch 56/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 740us/sample - loss: 1.8683 - accuracy: 0.4206 - val_loss: 3.2217 - val_accuracy: 0.1871\n",
      "Epoch 57/600\n",
      "680/680 [==============================] - 0s 730us/sample - loss: 1.7886 - accuracy: 0.4647 - val_loss: 3.2438 - val_accuracy: 0.1871\n",
      "Epoch 58/600\n",
      "680/680 [==============================] - 1s 817us/sample - loss: 1.9085 - accuracy: 0.4309 - val_loss: 3.2912 - val_accuracy: 0.1942\n",
      "Epoch 59/600\n",
      "680/680 [==============================] - 0s 707us/sample - loss: 1.7768 - accuracy: 0.4632 - val_loss: 3.3126 - val_accuracy: 0.1871\n",
      "Epoch 60/600\n",
      "680/680 [==============================] - 1s 762us/sample - loss: 1.7490 - accuracy: 0.4882 - val_loss: 3.2873 - val_accuracy: 0.1799\n",
      "Epoch 61/600\n",
      "680/680 [==============================] - 0s 682us/sample - loss: 1.8018 - accuracy: 0.4588 - val_loss: 3.2779 - val_accuracy: 0.1799\n",
      "Epoch 62/600\n",
      "680/680 [==============================] - 0s 666us/sample - loss: 1.7562 - accuracy: 0.4853 - val_loss: 3.2648 - val_accuracy: 0.1871\n",
      "Epoch 63/600\n",
      "680/680 [==============================] - 1s 792us/sample - loss: 1.6862 - accuracy: 0.5074 - val_loss: 3.2675 - val_accuracy: 0.1799\n",
      "Epoch 64/600\n",
      "680/680 [==============================] - 0s 704us/sample - loss: 1.7573 - accuracy: 0.4971 - val_loss: 3.2550 - val_accuracy: 0.1583\n",
      "Epoch 65/600\n",
      "680/680 [==============================] - 1s 841us/sample - loss: 1.6938 - accuracy: 0.5103 - val_loss: 3.2315 - val_accuracy: 0.1727\n",
      "Epoch 66/600\n",
      "680/680 [==============================] - 1s 818us/sample - loss: 1.7720 - accuracy: 0.4824 - val_loss: 3.2400 - val_accuracy: 0.1727\n",
      "Epoch 67/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.6625 - accuracy: 0.5191 - val_loss: 3.2653 - val_accuracy: 0.1871\n",
      "Epoch 68/600\n",
      "680/680 [==============================] - 1s 946us/sample - loss: 1.6489 - accuracy: 0.5221 - val_loss: 3.3074 - val_accuracy: 0.1942\n",
      "Epoch 69/600\n",
      "680/680 [==============================] - 1s 965us/sample - loss: 1.6783 - accuracy: 0.5147 - val_loss: 3.3411 - val_accuracy: 0.1871\n",
      "Epoch 70/600\n",
      "680/680 [==============================] - 1s 813us/sample - loss: 1.6247 - accuracy: 0.5250 - val_loss: 3.3646 - val_accuracy: 0.1799\n",
      "Epoch 71/600\n",
      "680/680 [==============================] - 1s 835us/sample - loss: 1.6252 - accuracy: 0.5265 - val_loss: 3.3821 - val_accuracy: 0.1799\n",
      "Epoch 72/600\n",
      "680/680 [==============================] - 1s 874us/sample - loss: 1.6254 - accuracy: 0.5353 - val_loss: 3.3621 - val_accuracy: 0.1871\n",
      "Epoch 73/600\n",
      "680/680 [==============================] - 1s 946us/sample - loss: 1.6796 - accuracy: 0.4824 - val_loss: 3.3348 - val_accuracy: 0.1871\n",
      "Epoch 74/600\n",
      "680/680 [==============================] - 1s 813us/sample - loss: 1.6023 - accuracy: 0.5441 - val_loss: 3.2967 - val_accuracy: 0.2014\n",
      "Epoch 75/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.5984 - accuracy: 0.5162 - val_loss: 3.2986 - val_accuracy: 0.2086\n",
      "Epoch 76/600\n",
      "680/680 [==============================] - 1s 851us/sample - loss: 1.5922 - accuracy: 0.5191 - val_loss: 3.2832 - val_accuracy: 0.2086\n",
      "Epoch 77/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.5334 - accuracy: 0.5632 - val_loss: 3.2631 - val_accuracy: 0.2158\n",
      "Epoch 78/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.5285 - accuracy: 0.5485 - val_loss: 3.2420 - val_accuracy: 0.2158\n",
      "Epoch 79/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.5417 - accuracy: 0.5588 - val_loss: 3.2386 - val_accuracy: 0.2230\n",
      "Epoch 80/600\n",
      "680/680 [==============================] - 1s 884us/sample - loss: 1.5087 - accuracy: 0.5618 - val_loss: 3.2353 - val_accuracy: 0.2158\n",
      "Epoch 81/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 1.4891 - accuracy: 0.5456 - val_loss: 3.2499 - val_accuracy: 0.2014\n",
      "Epoch 82/600\n",
      "680/680 [==============================] - 1s 931us/sample - loss: 1.5500 - accuracy: 0.5088 - val_loss: 3.2514 - val_accuracy: 0.1871\n",
      "Epoch 83/600\n",
      "680/680 [==============================] - 1s 771us/sample - loss: 1.4824 - accuracy: 0.5706 - val_loss: 3.2280 - val_accuracy: 0.2086\n",
      "Epoch 84/600\n",
      "680/680 [==============================] - 1s 776us/sample - loss: 1.4866 - accuracy: 0.5809 - val_loss: 3.2010 - val_accuracy: 0.2086\n",
      "Epoch 85/600\n",
      "680/680 [==============================] - 1s 788us/sample - loss: 1.4271 - accuracy: 0.5853 - val_loss: 3.2010 - val_accuracy: 0.1942\n",
      "Epoch 86/600\n",
      "680/680 [==============================] - 1s 753us/sample - loss: 1.4895 - accuracy: 0.5662 - val_loss: 3.2374 - val_accuracy: 0.1942\n",
      "Epoch 87/600\n",
      "680/680 [==============================] - 1s 783us/sample - loss: 1.4179 - accuracy: 0.5574 - val_loss: 3.2549 - val_accuracy: 0.1942\n",
      "Epoch 88/600\n",
      "680/680 [==============================] - 1s 801us/sample - loss: 1.4754 - accuracy: 0.5456 - val_loss: 3.2409 - val_accuracy: 0.1871\n",
      "Epoch 89/600\n",
      "680/680 [==============================] - 1s 903us/sample - loss: 1.3939 - accuracy: 0.5956 - val_loss: 3.1855 - val_accuracy: 0.2014\n",
      "Epoch 90/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.3606 - accuracy: 0.6118 - val_loss: 3.1542 - val_accuracy: 0.1942\n",
      "Epoch 91/600\n",
      "680/680 [==============================] - 1s 861us/sample - loss: 1.4092 - accuracy: 0.5691 - val_loss: 3.1295 - val_accuracy: 0.1942\n",
      "Epoch 92/600\n",
      "680/680 [==============================] - 1s 831us/sample - loss: 1.4036 - accuracy: 0.5853 - val_loss: 3.1160 - val_accuracy: 0.2086\n",
      "Epoch 93/600\n",
      "680/680 [==============================] - 1s 851us/sample - loss: 1.3701 - accuracy: 0.5956 - val_loss: 3.1322 - val_accuracy: 0.2158\n",
      "Epoch 94/600\n",
      "680/680 [==============================] - 1s 846us/sample - loss: 1.3165 - accuracy: 0.6324 - val_loss: 3.1629 - val_accuracy: 0.2302\n",
      "Epoch 95/600\n",
      "680/680 [==============================] - 1s 928us/sample - loss: 1.3652 - accuracy: 0.6103 - val_loss: 3.2027 - val_accuracy: 0.2230\n",
      "Epoch 96/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.3135 - accuracy: 0.6221 - val_loss: 3.2623 - val_accuracy: 0.2014\n",
      "Epoch 97/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.3540 - accuracy: 0.5912 - val_loss: 3.3087 - val_accuracy: 0.1799\n",
      "Epoch 98/600\n",
      "680/680 [==============================] - 1s 994us/sample - loss: 1.2915 - accuracy: 0.6368 - val_loss: 3.3234 - val_accuracy: 0.1799\n",
      "Epoch 99/600\n",
      "680/680 [==============================] - 1s 950us/sample - loss: 1.3314 - accuracy: 0.6000 - val_loss: 3.3320 - val_accuracy: 0.1871\n",
      "Epoch 100/600\n",
      "680/680 [==============================] - 1s 909us/sample - loss: 1.2993 - accuracy: 0.6044 - val_loss: 3.3331 - val_accuracy: 0.1727\n",
      "Epoch 101/600\n",
      "680/680 [==============================] - 1s 920us/sample - loss: 1.3076 - accuracy: 0.6000 - val_loss: 3.3132 - val_accuracy: 0.1655\n",
      "Epoch 102/600\n",
      "680/680 [==============================] - 1s 906us/sample - loss: 1.2919 - accuracy: 0.6221 - val_loss: 3.3026 - val_accuracy: 0.1583\n",
      "Epoch 103/600\n",
      "680/680 [==============================] - 1s 954us/sample - loss: 1.2370 - accuracy: 0.6279 - val_loss: 3.3101 - val_accuracy: 0.1799\n",
      "Epoch 104/600\n",
      "680/680 [==============================] - 1s 861us/sample - loss: 1.2331 - accuracy: 0.6250 - val_loss: 3.3382 - val_accuracy: 0.1871\n",
      "Epoch 105/600\n",
      "680/680 [==============================] - 1s 945us/sample - loss: 1.2459 - accuracy: 0.6191 - val_loss: 3.3701 - val_accuracy: 0.1655\n",
      "Epoch 106/600\n",
      "680/680 [==============================] - 1s 898us/sample - loss: 1.1940 - accuracy: 0.6515 - val_loss: 3.3925 - val_accuracy: 0.1727\n",
      "Epoch 107/600\n",
      "680/680 [==============================] - 1s 864us/sample - loss: 1.2368 - accuracy: 0.6279 - val_loss: 3.4292 - val_accuracy: 0.1511\n",
      "Epoch 108/600\n",
      "680/680 [==============================] - 0s 726us/sample - loss: 1.1497 - accuracy: 0.6647 - val_loss: 3.4993 - val_accuracy: 0.1439\n",
      "Epoch 109/600\n",
      "680/680 [==============================] - 1s 883us/sample - loss: 1.1873 - accuracy: 0.6544 - val_loss: 3.5557 - val_accuracy: 0.1439\n",
      "Epoch 110/600\n",
      "680/680 [==============================] - 0s 733us/sample - loss: 1.1887 - accuracy: 0.6647 - val_loss: 3.5891 - val_accuracy: 0.1655\n",
      "Epoch 111/600\n",
      "680/680 [==============================] - 1s 830us/sample - loss: 1.1413 - accuracy: 0.6735 - val_loss: 3.5666 - val_accuracy: 0.1727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/600\n",
      "680/680 [==============================] - 1s 745us/sample - loss: 1.1491 - accuracy: 0.6691 - val_loss: 3.5318 - val_accuracy: 0.1727\n",
      "Epoch 113/600\n",
      "680/680 [==============================] - 1s 865us/sample - loss: 1.1296 - accuracy: 0.6735 - val_loss: 3.5073 - val_accuracy: 0.1727\n",
      "Epoch 114/600\n",
      "680/680 [==============================] - 1s 877us/sample - loss: 1.1965 - accuracy: 0.6397 - val_loss: 3.4707 - val_accuracy: 0.1942\n",
      "Epoch 115/600\n",
      "680/680 [==============================] - 1s 842us/sample - loss: 1.1248 - accuracy: 0.6426 - val_loss: 3.4504 - val_accuracy: 0.1871\n",
      "Epoch 116/600\n",
      "680/680 [==============================] - 1s 817us/sample - loss: 1.0578 - accuracy: 0.6691 - val_loss: 3.4344 - val_accuracy: 0.2014\n",
      "Epoch 117/600\n",
      "680/680 [==============================] - 1s 800us/sample - loss: 1.1291 - accuracy: 0.6647 - val_loss: 3.4344 - val_accuracy: 0.1942\n",
      "Epoch 118/600\n",
      "680/680 [==============================] - 1s 810us/sample - loss: 1.1218 - accuracy: 0.6588 - val_loss: 3.4263 - val_accuracy: 0.2014\n",
      "Epoch 119/600\n",
      "680/680 [==============================] - 1s 889us/sample - loss: 1.0075 - accuracy: 0.7162 - val_loss: 3.4290 - val_accuracy: 0.1727\n",
      "Epoch 120/600\n",
      "680/680 [==============================] - 1s 737us/sample - loss: 1.0951 - accuracy: 0.6750 - val_loss: 3.4541 - val_accuracy: 0.1727\n",
      "Epoch 121/600\n",
      "680/680 [==============================] - 1s 823us/sample - loss: 1.0743 - accuracy: 0.6691 - val_loss: 3.4595 - val_accuracy: 0.1655\n",
      "Epoch 122/600\n",
      "680/680 [==============================] - 1s 814us/sample - loss: 1.0410 - accuracy: 0.6971 - val_loss: 3.4655 - val_accuracy: 0.1727\n",
      "Epoch 123/600\n",
      "680/680 [==============================] - 1s 917us/sample - loss: 1.0009 - accuracy: 0.7206 - val_loss: 3.4465 - val_accuracy: 0.1871\n",
      "Epoch 124/600\n",
      "680/680 [==============================] - 1s 836us/sample - loss: 0.9922 - accuracy: 0.6971 - val_loss: 3.4277 - val_accuracy: 0.1799\n",
      "Epoch 125/600\n",
      "680/680 [==============================] - 1s 783us/sample - loss: 1.0182 - accuracy: 0.7029 - val_loss: 3.4082 - val_accuracy: 0.1942\n",
      "Epoch 126/600\n",
      "680/680 [==============================] - 1s 868us/sample - loss: 1.0144 - accuracy: 0.7029 - val_loss: 3.4106 - val_accuracy: 0.1942\n",
      "Epoch 127/600\n",
      "680/680 [==============================] - 1s 919us/sample - loss: 1.0174 - accuracy: 0.7191 - val_loss: 3.4221 - val_accuracy: 0.1871\n",
      "Epoch 128/600\n",
      "680/680 [==============================] - 1s 2ms/sample - loss: 1.0135 - accuracy: 0.6912 - val_loss: 3.4331 - val_accuracy: 0.1871\n",
      "Epoch 129/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9196 - accuracy: 0.7353 - val_loss: 3.4741 - val_accuracy: 0.1871\n",
      "Epoch 130/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.0051 - accuracy: 0.7074 - val_loss: 3.5088 - val_accuracy: 0.1871\n",
      "Epoch 131/600\n",
      "680/680 [==============================] - 1s 996us/sample - loss: 0.9837 - accuracy: 0.6926 - val_loss: 3.5447 - val_accuracy: 0.1942\n",
      "Epoch 132/600\n",
      "680/680 [==============================] - 1s 964us/sample - loss: 1.0266 - accuracy: 0.7118 - val_loss: 3.5562 - val_accuracy: 0.1799\n",
      "Epoch 133/600\n",
      "680/680 [==============================] - 1s 971us/sample - loss: 0.9231 - accuracy: 0.7397 - val_loss: 3.5727 - val_accuracy: 0.1655\n",
      "Epoch 134/600\n",
      "680/680 [==============================] - 1s 948us/sample - loss: 0.9600 - accuracy: 0.7250 - val_loss: 3.5571 - val_accuracy: 0.1655\n",
      "Epoch 135/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9260 - accuracy: 0.7368 - val_loss: 3.5491 - val_accuracy: 0.1655\n",
      "Epoch 136/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 1.0360 - accuracy: 0.6691 - val_loss: 3.5451 - val_accuracy: 0.1655\n",
      "Epoch 137/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8995 - accuracy: 0.7265 - val_loss: 3.5431 - val_accuracy: 0.1727\n",
      "Epoch 138/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8976 - accuracy: 0.7529 - val_loss: 3.5443 - val_accuracy: 0.1727\n",
      "Epoch 139/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9342 - accuracy: 0.7294 - val_loss: 3.5142 - val_accuracy: 0.1655\n",
      "Epoch 140/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8462 - accuracy: 0.7397 - val_loss: 3.4939 - val_accuracy: 0.1655\n",
      "Epoch 141/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9473 - accuracy: 0.7221 - val_loss: 3.4771 - val_accuracy: 0.1583\n",
      "Epoch 142/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9579 - accuracy: 0.7147 - val_loss: 3.4727 - val_accuracy: 0.1511\n",
      "Epoch 143/600\n",
      "680/680 [==============================] - 1s 918us/sample - loss: 0.9354 - accuracy: 0.7324 - val_loss: 3.4690 - val_accuracy: 0.1511\n",
      "Epoch 144/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8717 - accuracy: 0.7544 - val_loss: 3.4686 - val_accuracy: 0.1439\n",
      "Epoch 145/600\n",
      "680/680 [==============================] - 1s 960us/sample - loss: 0.8743 - accuracy: 0.7706 - val_loss: 3.4764 - val_accuracy: 0.1439\n",
      "Epoch 146/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9056 - accuracy: 0.7206 - val_loss: 3.4786 - val_accuracy: 0.1439\n",
      "Epoch 147/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8561 - accuracy: 0.7441 - val_loss: 3.4791 - val_accuracy: 0.1511\n",
      "Epoch 148/600\n",
      "680/680 [==============================] - 1s 970us/sample - loss: 0.8864 - accuracy: 0.7515 - val_loss: 3.4825 - val_accuracy: 0.1511\n",
      "Epoch 149/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8394 - accuracy: 0.7706 - val_loss: 3.4863 - val_accuracy: 0.1511\n",
      "Epoch 150/600\n",
      "680/680 [==============================] - 1s 950us/sample - loss: 0.9127 - accuracy: 0.7235 - val_loss: 3.4889 - val_accuracy: 0.1439\n",
      "Epoch 151/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8849 - accuracy: 0.7353 - val_loss: 3.4913 - val_accuracy: 0.1511\n",
      "Epoch 152/600\n",
      "680/680 [==============================] - 1s 871us/sample - loss: 0.8511 - accuracy: 0.7559 - val_loss: 3.4965 - val_accuracy: 0.1511\n",
      "Epoch 153/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8845 - accuracy: 0.7559 - val_loss: 3.5040 - val_accuracy: 0.1511\n",
      "Epoch 154/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8543 - accuracy: 0.7471 - val_loss: 3.5114 - val_accuracy: 0.1655\n",
      "Epoch 155/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8510 - accuracy: 0.7485 - val_loss: 3.5147 - val_accuracy: 0.1655\n",
      "Epoch 156/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8456 - accuracy: 0.7632 - val_loss: 3.5149 - val_accuracy: 0.1655\n",
      "Epoch 157/600\n",
      "680/680 [==============================] - 1s 813us/sample - loss: 0.8291 - accuracy: 0.7647 - val_loss: 3.5125 - val_accuracy: 0.1727\n",
      "Epoch 158/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8924 - accuracy: 0.7529 - val_loss: 3.5117 - val_accuracy: 0.1727\n",
      "Epoch 159/600\n",
      "680/680 [==============================] - 1s 925us/sample - loss: 0.8429 - accuracy: 0.7485 - val_loss: 3.5128 - val_accuracy: 0.1727\n",
      "Epoch 160/600\n",
      "680/680 [==============================] - 1s 868us/sample - loss: 0.7945 - accuracy: 0.7574 - val_loss: 3.5141 - val_accuracy: 0.1655\n",
      "Epoch 161/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8137 - accuracy: 0.7721 - val_loss: 3.5134 - val_accuracy: 0.1727\n",
      "Epoch 162/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8483 - accuracy: 0.7559 - val_loss: 3.5117 - val_accuracy: 0.1727\n",
      "Epoch 163/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8374 - accuracy: 0.7603 - val_loss: 3.5087 - val_accuracy: 0.1799\n",
      "Epoch 164/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8699 - accuracy: 0.7294 - val_loss: 3.5081 - val_accuracy: 0.1799\n",
      "Epoch 165/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.9292 - accuracy: 0.7235 - val_loss: 3.5077 - val_accuracy: 0.1727\n",
      "Epoch 166/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7878 - accuracy: 0.7691 - val_loss: 3.5061 - val_accuracy: 0.1727\n",
      "Epoch 167/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8391 - accuracy: 0.7647 - val_loss: 3.5047 - val_accuracy: 0.1799\n",
      "Epoch 168/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8569 - accuracy: 0.7456 - val_loss: 3.5026 - val_accuracy: 0.1799\n",
      "Epoch 169/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8029 - accuracy: 0.7721 - val_loss: 3.4997 - val_accuracy: 0.1799\n",
      "Epoch 170/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8239 - accuracy: 0.7544 - val_loss: 3.4964 - val_accuracy: 0.1799\n",
      "Epoch 171/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8467 - accuracy: 0.7500 - val_loss: 3.4938 - val_accuracy: 0.1871\n",
      "Epoch 172/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8029 - accuracy: 0.7676 - val_loss: 3.4906 - val_accuracy: 0.1799\n",
      "Epoch 173/600\n",
      "680/680 [==============================] - 1s 965us/sample - loss: 0.7710 - accuracy: 0.7691 - val_loss: 3.4872 - val_accuracy: 0.1799\n",
      "Epoch 174/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8120 - accuracy: 0.7574 - val_loss: 3.4830 - val_accuracy: 0.1799\n",
      "Epoch 175/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7602 - accuracy: 0.8029 - val_loss: 3.4787 - val_accuracy: 0.1799\n",
      "Epoch 176/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8018 - accuracy: 0.7618 - val_loss: 3.4741 - val_accuracy: 0.1799\n",
      "Epoch 177/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8157 - accuracy: 0.7632 - val_loss: 3.4704 - val_accuracy: 0.1799\n",
      "Epoch 178/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8560 - accuracy: 0.7456 - val_loss: 3.4667 - val_accuracy: 0.1799\n",
      "Epoch 179/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8497 - accuracy: 0.7559 - val_loss: 3.4633 - val_accuracy: 0.1799\n",
      "Epoch 180/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7672 - accuracy: 0.7809 - val_loss: 3.4607 - val_accuracy: 0.1799\n",
      "Epoch 181/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8483 - accuracy: 0.7662 - val_loss: 3.4588 - val_accuracy: 0.1799\n",
      "Epoch 182/600\n",
      "680/680 [==============================] - 1s 913us/sample - loss: 0.8301 - accuracy: 0.7426 - val_loss: 3.4570 - val_accuracy: 0.1799\n",
      "Epoch 183/600\n",
      "680/680 [==============================] - 1s 804us/sample - loss: 0.8469 - accuracy: 0.7500 - val_loss: 3.4552 - val_accuracy: 0.1871\n",
      "Epoch 184/600\n",
      "680/680 [==============================] - 1s 820us/sample - loss: 0.7662 - accuracy: 0.7735 - val_loss: 3.4532 - val_accuracy: 0.1871\n",
      "Epoch 185/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7767 - accuracy: 0.7882 - val_loss: 3.4511 - val_accuracy: 0.1871\n",
      "Epoch 186/600\n",
      "680/680 [==============================] - 1s 863us/sample - loss: 0.8547 - accuracy: 0.7676 - val_loss: 3.4493 - val_accuracy: 0.1871\n",
      "Epoch 187/600\n",
      "680/680 [==============================] - 1s 917us/sample - loss: 0.8289 - accuracy: 0.7676 - val_loss: 3.4480 - val_accuracy: 0.1871\n",
      "Epoch 188/600\n",
      "680/680 [==============================] - 1s 991us/sample - loss: 0.7889 - accuracy: 0.7735 - val_loss: 3.4466 - val_accuracy: 0.1871\n",
      "Epoch 189/600\n",
      "680/680 [==============================] - 1s 841us/sample - loss: 0.8294 - accuracy: 0.7441 - val_loss: 3.4456 - val_accuracy: 0.1871\n",
      "Epoch 190/600\n",
      "680/680 [==============================] - 1s 859us/sample - loss: 0.8428 - accuracy: 0.7809 - val_loss: 3.4440 - val_accuracy: 0.1871\n",
      "Epoch 191/600\n",
      "680/680 [==============================] - 1s 826us/sample - loss: 0.8208 - accuracy: 0.7588 - val_loss: 3.4430 - val_accuracy: 0.1942\n",
      "Epoch 192/600\n",
      "680/680 [==============================] - 1s 843us/sample - loss: 0.8551 - accuracy: 0.7397 - val_loss: 3.4412 - val_accuracy: 0.1871\n",
      "Epoch 193/600\n",
      "680/680 [==============================] - 1s 837us/sample - loss: 0.8410 - accuracy: 0.7515 - val_loss: 3.4397 - val_accuracy: 0.1871\n",
      "Epoch 194/600\n",
      "680/680 [==============================] - 1s 763us/sample - loss: 0.8156 - accuracy: 0.7456 - val_loss: 3.4382 - val_accuracy: 0.1871\n",
      "Epoch 195/600\n",
      "680/680 [==============================] - 1s 754us/sample - loss: 0.8261 - accuracy: 0.7618 - val_loss: 3.4370 - val_accuracy: 0.1871\n",
      "Epoch 196/600\n",
      "680/680 [==============================] - 1s 856us/sample - loss: 0.7964 - accuracy: 0.7735 - val_loss: 3.4362 - val_accuracy: 0.1942\n",
      "Epoch 197/600\n",
      "680/680 [==============================] - 1s 819us/sample - loss: 0.8247 - accuracy: 0.7574 - val_loss: 3.4356 - val_accuracy: 0.1942\n",
      "Epoch 198/600\n",
      "680/680 [==============================] - 0s 704us/sample - loss: 0.7698 - accuracy: 0.7809 - val_loss: 3.4351 - val_accuracy: 0.1871\n",
      "Epoch 199/600\n",
      "680/680 [==============================] - 0s 683us/sample - loss: 0.7882 - accuracy: 0.7706 - val_loss: 3.4342 - val_accuracy: 0.1942\n",
      "Epoch 200/600\n",
      "680/680 [==============================] - 1s 804us/sample - loss: 0.7367 - accuracy: 0.7882 - val_loss: 3.4332 - val_accuracy: 0.1942\n",
      "Epoch 201/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8064 - accuracy: 0.7662 - val_loss: 3.4322 - val_accuracy: 0.2014\n",
      "Epoch 202/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8526 - accuracy: 0.7426 - val_loss: 3.4313 - val_accuracy: 0.2014\n",
      "Epoch 203/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8349 - accuracy: 0.7676 - val_loss: 3.4306 - val_accuracy: 0.2014\n",
      "Epoch 204/600\n",
      "680/680 [==============================] - 1s 915us/sample - loss: 0.7859 - accuracy: 0.7676 - val_loss: 3.4299 - val_accuracy: 0.2014\n",
      "Epoch 205/600\n",
      "680/680 [==============================] - 1s 920us/sample - loss: 0.7974 - accuracy: 0.7706 - val_loss: 3.4293 - val_accuracy: 0.2014\n",
      "Epoch 206/600\n",
      "680/680 [==============================] - 1s 934us/sample - loss: 0.8307 - accuracy: 0.7632 - val_loss: 3.4286 - val_accuracy: 0.2014\n",
      "Epoch 207/600\n",
      "680/680 [==============================] - 1s 993us/sample - loss: 0.8217 - accuracy: 0.7515 - val_loss: 3.4281 - val_accuracy: 0.2014\n",
      "Epoch 208/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8940 - accuracy: 0.7426 - val_loss: 3.4272 - val_accuracy: 0.2014\n",
      "Epoch 209/600\n",
      "680/680 [==============================] - 1s 951us/sample - loss: 0.7942 - accuracy: 0.7676 - val_loss: 3.4266 - val_accuracy: 0.2086\n",
      "Epoch 210/600\n",
      "680/680 [==============================] - 1s 899us/sample - loss: 0.7863 - accuracy: 0.7662 - val_loss: 3.4256 - val_accuracy: 0.2086\n",
      "Epoch 211/600\n",
      "680/680 [==============================] - 1s 926us/sample - loss: 0.8498 - accuracy: 0.7618 - val_loss: 3.4248 - val_accuracy: 0.2014\n",
      "Epoch 212/600\n",
      "680/680 [==============================] - 1s 942us/sample - loss: 0.7936 - accuracy: 0.7706 - val_loss: 3.4241 - val_accuracy: 0.2014\n",
      "Epoch 213/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8045 - accuracy: 0.7632 - val_loss: 3.4232 - val_accuracy: 0.2014\n",
      "Epoch 214/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8110 - accuracy: 0.7721 - val_loss: 3.4225 - val_accuracy: 0.2014\n",
      "Epoch 215/600\n",
      "680/680 [==============================] - 1s 973us/sample - loss: 0.8558 - accuracy: 0.7632 - val_loss: 3.4219 - val_accuracy: 0.2086\n",
      "Epoch 216/600\n",
      "680/680 [==============================] - 1s 991us/sample - loss: 0.8427 - accuracy: 0.7676 - val_loss: 3.4211 - val_accuracy: 0.2086\n",
      "Epoch 217/600\n",
      "680/680 [==============================] - 1s 915us/sample - loss: 0.8232 - accuracy: 0.7544 - val_loss: 3.4201 - val_accuracy: 0.2086\n",
      "Epoch 218/600\n",
      "680/680 [==============================] - 1s 970us/sample - loss: 0.8120 - accuracy: 0.7588 - val_loss: 3.4196 - val_accuracy: 0.2086\n",
      "Epoch 219/600\n",
      "680/680 [==============================] - 1s 928us/sample - loss: 0.8097 - accuracy: 0.7544 - val_loss: 3.4193 - val_accuracy: 0.2086\n",
      "Epoch 220/600\n",
      "680/680 [==============================] - 1s 984us/sample - loss: 0.7768 - accuracy: 0.7750 - val_loss: 3.4186 - val_accuracy: 0.2086\n",
      "Epoch 221/600\n",
      "680/680 [==============================] - 1s 884us/sample - loss: 0.8239 - accuracy: 0.7632 - val_loss: 3.4180 - val_accuracy: 0.2086\n",
      "Epoch 222/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 977us/sample - loss: 0.8760 - accuracy: 0.7574 - val_loss: 3.4176 - val_accuracy: 0.2086\n",
      "Epoch 223/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8145 - accuracy: 0.7662 - val_loss: 3.4170 - val_accuracy: 0.2086\n",
      "Epoch 224/600\n",
      "680/680 [==============================] - 1s 967us/sample - loss: 0.7689 - accuracy: 0.7676 - val_loss: 3.4162 - val_accuracy: 0.2086\n",
      "Epoch 225/600\n",
      "680/680 [==============================] - 1s 859us/sample - loss: 0.8424 - accuracy: 0.7647 - val_loss: 3.4156 - val_accuracy: 0.2086\n",
      "Epoch 226/600\n",
      "680/680 [==============================] - 1s 911us/sample - loss: 0.7556 - accuracy: 0.7735 - val_loss: 3.4147 - val_accuracy: 0.2086\n",
      "Epoch 227/600\n",
      "680/680 [==============================] - 1s 937us/sample - loss: 0.8326 - accuracy: 0.7441 - val_loss: 3.4141 - val_accuracy: 0.2086\n",
      "Epoch 228/600\n",
      "680/680 [==============================] - 1s 830us/sample - loss: 0.7869 - accuracy: 0.7897 - val_loss: 3.4132 - val_accuracy: 0.2158\n",
      "Epoch 229/600\n",
      "680/680 [==============================] - 1s 857us/sample - loss: 0.8254 - accuracy: 0.7779 - val_loss: 3.4127 - val_accuracy: 0.2158\n",
      "Epoch 230/600\n",
      "680/680 [==============================] - 1s 896us/sample - loss: 0.8408 - accuracy: 0.7544 - val_loss: 3.4117 - val_accuracy: 0.2158\n",
      "Epoch 231/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8121 - accuracy: 0.7485 - val_loss: 3.4111 - val_accuracy: 0.2158\n",
      "Epoch 232/600\n",
      "680/680 [==============================] - 1s 870us/sample - loss: 0.8612 - accuracy: 0.7412 - val_loss: 3.4105 - val_accuracy: 0.2158\n",
      "Epoch 233/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 0.7399 - accuracy: 0.8029 - val_loss: 3.4098 - val_accuracy: 0.2158\n",
      "Epoch 234/600\n",
      "680/680 [==============================] - 1s 906us/sample - loss: 0.7817 - accuracy: 0.7912 - val_loss: 3.4095 - val_accuracy: 0.2158\n",
      "Epoch 235/600\n",
      "680/680 [==============================] - 1s 923us/sample - loss: 0.8388 - accuracy: 0.7618 - val_loss: 3.4089 - val_accuracy: 0.2158\n",
      "Epoch 236/600\n",
      "680/680 [==============================] - 1s 881us/sample - loss: 0.8268 - accuracy: 0.7779 - val_loss: 3.4081 - val_accuracy: 0.2158\n",
      "Epoch 237/600\n",
      "680/680 [==============================] - 1s 919us/sample - loss: 0.8676 - accuracy: 0.7353 - val_loss: 3.4074 - val_accuracy: 0.2158\n",
      "Epoch 238/600\n",
      "680/680 [==============================] - 1s 875us/sample - loss: 0.7665 - accuracy: 0.7941 - val_loss: 3.4065 - val_accuracy: 0.2158\n",
      "Epoch 239/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8257 - accuracy: 0.7603 - val_loss: 3.4059 - val_accuracy: 0.2158\n",
      "Epoch 240/600\n",
      "680/680 [==============================] - 1s 856us/sample - loss: 0.7511 - accuracy: 0.7985 - val_loss: 3.4055 - val_accuracy: 0.2158\n",
      "Epoch 241/600\n",
      "680/680 [==============================] - 1s 971us/sample - loss: 0.8428 - accuracy: 0.7647 - val_loss: 3.4049 - val_accuracy: 0.2158\n",
      "Epoch 242/600\n",
      "680/680 [==============================] - 1s 863us/sample - loss: 0.8310 - accuracy: 0.7794 - val_loss: 3.4043 - val_accuracy: 0.2158\n",
      "Epoch 243/600\n",
      "680/680 [==============================] - 1s 898us/sample - loss: 0.7844 - accuracy: 0.7897 - val_loss: 3.4037 - val_accuracy: 0.2158\n",
      "Epoch 244/600\n",
      "680/680 [==============================] - 1s 900us/sample - loss: 0.8318 - accuracy: 0.7544 - val_loss: 3.4029 - val_accuracy: 0.2158\n",
      "Epoch 245/600\n",
      "680/680 [==============================] - 1s 981us/sample - loss: 0.8217 - accuracy: 0.7809 - val_loss: 3.4023 - val_accuracy: 0.2158\n",
      "Epoch 246/600\n",
      "680/680 [==============================] - 1s 986us/sample - loss: 0.8474 - accuracy: 0.7397 - val_loss: 3.4012 - val_accuracy: 0.2158\n",
      "Epoch 247/600\n",
      "680/680 [==============================] - 1s 943us/sample - loss: 0.8038 - accuracy: 0.7735 - val_loss: 3.4004 - val_accuracy: 0.2158\n",
      "Epoch 248/600\n",
      "680/680 [==============================] - 1s 929us/sample - loss: 0.8046 - accuracy: 0.7691 - val_loss: 3.3994 - val_accuracy: 0.2158\n",
      "Epoch 249/600\n",
      "680/680 [==============================] - 1s 844us/sample - loss: 0.8038 - accuracy: 0.7706 - val_loss: 3.3986 - val_accuracy: 0.2158\n",
      "Epoch 250/600\n",
      "680/680 [==============================] - 1s 873us/sample - loss: 0.8310 - accuracy: 0.7706 - val_loss: 3.3974 - val_accuracy: 0.2158\n",
      "Epoch 251/600\n",
      "680/680 [==============================] - 1s 850us/sample - loss: 0.8446 - accuracy: 0.7515 - val_loss: 3.3966 - val_accuracy: 0.2158\n",
      "Epoch 252/600\n",
      "680/680 [==============================] - 1s 890us/sample - loss: 0.8057 - accuracy: 0.7529 - val_loss: 3.3959 - val_accuracy: 0.2158\n",
      "Epoch 253/600\n",
      "680/680 [==============================] - 1s 845us/sample - loss: 0.8231 - accuracy: 0.7382 - val_loss: 3.3953 - val_accuracy: 0.2158\n",
      "Epoch 254/600\n",
      "680/680 [==============================] - 1s 993us/sample - loss: 0.8024 - accuracy: 0.7706 - val_loss: 3.3950 - val_accuracy: 0.2158\n",
      "Epoch 255/600\n",
      "680/680 [==============================] - 1s 905us/sample - loss: 0.8491 - accuracy: 0.7471 - val_loss: 3.3939 - val_accuracy: 0.2158\n",
      "Epoch 256/600\n",
      "680/680 [==============================] - 1s 937us/sample - loss: 0.8091 - accuracy: 0.7809 - val_loss: 3.3930 - val_accuracy: 0.2158\n",
      "Epoch 257/600\n",
      "680/680 [==============================] - 1s 888us/sample - loss: 0.7975 - accuracy: 0.7676 - val_loss: 3.3923 - val_accuracy: 0.2158\n",
      "Epoch 258/600\n",
      "680/680 [==============================] - 1s 952us/sample - loss: 0.8051 - accuracy: 0.7632 - val_loss: 3.3914 - val_accuracy: 0.2158\n",
      "Epoch 259/600\n",
      "680/680 [==============================] - 1s 876us/sample - loss: 0.8047 - accuracy: 0.7647 - val_loss: 3.3909 - val_accuracy: 0.2230\n",
      "Epoch 260/600\n",
      "680/680 [==============================] - 1s 979us/sample - loss: 0.8129 - accuracy: 0.7838 - val_loss: 3.3901 - val_accuracy: 0.2230\n",
      "Epoch 261/600\n",
      "680/680 [==============================] - 1s 888us/sample - loss: 0.8291 - accuracy: 0.7662 - val_loss: 3.3896 - val_accuracy: 0.2230\n",
      "Epoch 262/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7959 - accuracy: 0.7559 - val_loss: 3.3889 - val_accuracy: 0.2302\n",
      "Epoch 263/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 0.7986 - accuracy: 0.7647 - val_loss: 3.3882 - val_accuracy: 0.2302\n",
      "Epoch 264/600\n",
      "680/680 [==============================] - 1s 956us/sample - loss: 0.7959 - accuracy: 0.7618 - val_loss: 3.3876 - val_accuracy: 0.2302\n",
      "Epoch 265/600\n",
      "680/680 [==============================] - 1s 872us/sample - loss: 0.8103 - accuracy: 0.7662 - val_loss: 3.3870 - val_accuracy: 0.2302\n",
      "Epoch 266/600\n",
      "680/680 [==============================] - 1s 934us/sample - loss: 0.7622 - accuracy: 0.7882 - val_loss: 3.3866 - val_accuracy: 0.2302\n",
      "Epoch 267/600\n",
      "680/680 [==============================] - 1s 889us/sample - loss: 0.8411 - accuracy: 0.7574 - val_loss: 3.3859 - val_accuracy: 0.2302\n",
      "Epoch 268/600\n",
      "680/680 [==============================] - 1s 916us/sample - loss: 0.8040 - accuracy: 0.7603 - val_loss: 3.3854 - val_accuracy: 0.2302\n",
      "Epoch 269/600\n",
      "680/680 [==============================] - 1s 896us/sample - loss: 0.7520 - accuracy: 0.7721 - val_loss: 3.3852 - val_accuracy: 0.2302\n",
      "Epoch 270/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8345 - accuracy: 0.7544 - val_loss: 3.3846 - val_accuracy: 0.2302\n",
      "Epoch 271/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7876 - accuracy: 0.7750 - val_loss: 3.3843 - val_accuracy: 0.2230\n",
      "Epoch 272/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8265 - accuracy: 0.7691 - val_loss: 3.3838 - val_accuracy: 0.2230\n",
      "Epoch 273/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8230 - accuracy: 0.7456 - val_loss: 3.3835 - val_accuracy: 0.2230\n",
      "Epoch 274/600\n",
      "680/680 [==============================] - 1s 886us/sample - loss: 0.8147 - accuracy: 0.7632 - val_loss: 3.3830 - val_accuracy: 0.2230\n",
      "Epoch 275/600\n",
      "680/680 [==============================] - 1s 946us/sample - loss: 0.8380 - accuracy: 0.7588 - val_loss: 3.3827 - val_accuracy: 0.2230\n",
      "Epoch 276/600\n",
      "680/680 [==============================] - 1s 864us/sample - loss: 0.7900 - accuracy: 0.7809 - val_loss: 3.3822 - val_accuracy: 0.2230\n",
      "Epoch 277/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 886us/sample - loss: 0.8020 - accuracy: 0.7721 - val_loss: 3.3820 - val_accuracy: 0.2230\n",
      "Epoch 278/600\n",
      "680/680 [==============================] - 1s 796us/sample - loss: 0.8265 - accuracy: 0.7632 - val_loss: 3.3817 - val_accuracy: 0.2230\n",
      "Epoch 279/600\n",
      "680/680 [==============================] - 1s 831us/sample - loss: 0.8033 - accuracy: 0.7794 - val_loss: 3.3812 - val_accuracy: 0.2230\n",
      "Epoch 280/600\n",
      "680/680 [==============================] - 1s 737us/sample - loss: 0.8184 - accuracy: 0.7750 - val_loss: 3.3810 - val_accuracy: 0.2230\n",
      "Epoch 281/600\n",
      "680/680 [==============================] - 1s 818us/sample - loss: 0.8178 - accuracy: 0.7603 - val_loss: 3.3807 - val_accuracy: 0.2230\n",
      "Epoch 282/600\n",
      "680/680 [==============================] - 1s 806us/sample - loss: 0.7854 - accuracy: 0.7588 - val_loss: 3.3803 - val_accuracy: 0.2230\n",
      "Epoch 283/600\n",
      "680/680 [==============================] - 1s 804us/sample - loss: 0.7410 - accuracy: 0.7956 - val_loss: 3.3798 - val_accuracy: 0.2302\n",
      "Epoch 284/600\n",
      "680/680 [==============================] - 1s 776us/sample - loss: 0.8301 - accuracy: 0.7485 - val_loss: 3.3793 - val_accuracy: 0.2302\n",
      "Epoch 285/600\n",
      "680/680 [==============================] - 1s 743us/sample - loss: 0.7898 - accuracy: 0.7735 - val_loss: 3.3789 - val_accuracy: 0.2302\n",
      "Epoch 286/600\n",
      "680/680 [==============================] - 1s 925us/sample - loss: 0.8397 - accuracy: 0.7676 - val_loss: 3.3785 - val_accuracy: 0.2302\n",
      "Epoch 287/600\n",
      "680/680 [==============================] - 1s 744us/sample - loss: 0.8406 - accuracy: 0.7544 - val_loss: 3.3781 - val_accuracy: 0.2302\n",
      "Epoch 288/600\n",
      "680/680 [==============================] - 1s 800us/sample - loss: 0.8318 - accuracy: 0.7618 - val_loss: 3.3775 - val_accuracy: 0.2302\n",
      "Epoch 289/600\n",
      "680/680 [==============================] - 0s 685us/sample - loss: 0.8154 - accuracy: 0.7588 - val_loss: 3.3769 - val_accuracy: 0.2302\n",
      "Epoch 290/600\n",
      "680/680 [==============================] - 1s 805us/sample - loss: 0.7963 - accuracy: 0.7676 - val_loss: 3.3766 - val_accuracy: 0.2302\n",
      "Epoch 291/600\n",
      "680/680 [==============================] - 0s 705us/sample - loss: 0.8235 - accuracy: 0.7603 - val_loss: 3.3762 - val_accuracy: 0.2302\n",
      "Epoch 292/600\n",
      "680/680 [==============================] - 1s 852us/sample - loss: 0.8133 - accuracy: 0.7603 - val_loss: 3.3762 - val_accuracy: 0.2302\n",
      "Epoch 293/600\n",
      "680/680 [==============================] - 1s 785us/sample - loss: 0.7928 - accuracy: 0.7559 - val_loss: 3.3761 - val_accuracy: 0.2302\n",
      "Epoch 294/600\n",
      "680/680 [==============================] - 0s 688us/sample - loss: 0.8126 - accuracy: 0.7559 - val_loss: 3.3758 - val_accuracy: 0.2302\n",
      "Epoch 295/600\n",
      "680/680 [==============================] - 1s 848us/sample - loss: 0.7775 - accuracy: 0.7603 - val_loss: 3.3755 - val_accuracy: 0.2302\n",
      "Epoch 296/600\n",
      "680/680 [==============================] - 0s 627us/sample - loss: 0.8260 - accuracy: 0.7632 - val_loss: 3.3756 - val_accuracy: 0.2302\n",
      "Epoch 297/600\n",
      "680/680 [==============================] - 1s 765us/sample - loss: 0.8571 - accuracy: 0.7515 - val_loss: 3.3753 - val_accuracy: 0.2302\n",
      "Epoch 298/600\n",
      "680/680 [==============================] - 0s 727us/sample - loss: 0.8569 - accuracy: 0.7353 - val_loss: 3.3753 - val_accuracy: 0.2302\n",
      "Epoch 299/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8197 - accuracy: 0.7676 - val_loss: 3.3750 - val_accuracy: 0.2302\n",
      "Epoch 300/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8047 - accuracy: 0.7824 - val_loss: 3.3750 - val_accuracy: 0.2230\n",
      "Epoch 301/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8231 - accuracy: 0.7618 - val_loss: 3.3750 - val_accuracy: 0.2230\n",
      "Epoch 302/600\n",
      "680/680 [==============================] - 1s 987us/sample - loss: 0.7893 - accuracy: 0.7794 - val_loss: 3.3748 - val_accuracy: 0.2230\n",
      "Epoch 303/600\n",
      "680/680 [==============================] - 1s 971us/sample - loss: 0.7594 - accuracy: 0.7853 - val_loss: 3.3748 - val_accuracy: 0.2302\n",
      "Epoch 304/600\n",
      "680/680 [==============================] - 1s 912us/sample - loss: 0.7650 - accuracy: 0.7912 - val_loss: 3.3748 - val_accuracy: 0.2302\n",
      "Epoch 305/600\n",
      "680/680 [==============================] - 1s 923us/sample - loss: 0.8391 - accuracy: 0.7382 - val_loss: 3.3748 - val_accuracy: 0.2302\n",
      "Epoch 306/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7843 - accuracy: 0.7603 - val_loss: 3.3747 - val_accuracy: 0.2302\n",
      "Epoch 307/600\n",
      "680/680 [==============================] - 1s 941us/sample - loss: 0.8208 - accuracy: 0.7647 - val_loss: 3.3746 - val_accuracy: 0.2302\n",
      "Epoch 308/600\n",
      "680/680 [==============================] - 1s 886us/sample - loss: 0.8252 - accuracy: 0.7500 - val_loss: 3.3746 - val_accuracy: 0.2302\n",
      "Epoch 309/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8146 - accuracy: 0.7574 - val_loss: 3.3748 - val_accuracy: 0.2302\n",
      "Epoch 310/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7393 - accuracy: 0.7912 - val_loss: 3.3747 - val_accuracy: 0.2302\n",
      "Epoch 311/600\n",
      "680/680 [==============================] - 1s 931us/sample - loss: 0.7985 - accuracy: 0.7794 - val_loss: 3.3744 - val_accuracy: 0.2302\n",
      "Epoch 312/600\n",
      "680/680 [==============================] - 1s 885us/sample - loss: 0.8248 - accuracy: 0.7412 - val_loss: 3.3741 - val_accuracy: 0.2302\n",
      "Epoch 313/600\n",
      "680/680 [==============================] - 1s 918us/sample - loss: 0.8451 - accuracy: 0.7456 - val_loss: 3.3739 - val_accuracy: 0.2302\n",
      "Epoch 314/600\n",
      "680/680 [==============================] - 1s 865us/sample - loss: 0.8107 - accuracy: 0.7588 - val_loss: 3.3741 - val_accuracy: 0.2302\n",
      "Epoch 315/600\n",
      "680/680 [==============================] - 1s 987us/sample - loss: 0.7931 - accuracy: 0.7779 - val_loss: 3.3743 - val_accuracy: 0.2302\n",
      "Epoch 316/600\n",
      "680/680 [==============================] - 1s 962us/sample - loss: 0.8085 - accuracy: 0.7603 - val_loss: 3.3742 - val_accuracy: 0.2302\n",
      "Epoch 317/600\n",
      "680/680 [==============================] - 1s 966us/sample - loss: 0.7868 - accuracy: 0.7676 - val_loss: 3.3740 - val_accuracy: 0.2230\n",
      "Epoch 318/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8763 - accuracy: 0.7529 - val_loss: 3.3742 - val_accuracy: 0.2230\n",
      "Epoch 319/600\n",
      "680/680 [==============================] - 1s 957us/sample - loss: 0.8000 - accuracy: 0.7721 - val_loss: 3.3743 - val_accuracy: 0.2230\n",
      "Epoch 320/600\n",
      "680/680 [==============================] - 1s 913us/sample - loss: 0.8118 - accuracy: 0.7691 - val_loss: 3.3743 - val_accuracy: 0.2230\n",
      "Epoch 321/600\n",
      "680/680 [==============================] - 1s 876us/sample - loss: 0.8370 - accuracy: 0.7456 - val_loss: 3.3745 - val_accuracy: 0.2230\n",
      "Epoch 322/600\n",
      "680/680 [==============================] - 1s 969us/sample - loss: 0.8328 - accuracy: 0.7544 - val_loss: 3.3745 - val_accuracy: 0.2230\n",
      "Epoch 323/600\n",
      "680/680 [==============================] - 1s 831us/sample - loss: 0.7699 - accuracy: 0.7750 - val_loss: 3.3744 - val_accuracy: 0.2230\n",
      "Epoch 324/600\n",
      "680/680 [==============================] - 1s 878us/sample - loss: 0.8479 - accuracy: 0.7559 - val_loss: 3.3745 - val_accuracy: 0.2230\n",
      "Epoch 325/600\n",
      "680/680 [==============================] - 1s 941us/sample - loss: 0.8032 - accuracy: 0.7691 - val_loss: 3.3746 - val_accuracy: 0.2230\n",
      "Epoch 326/600\n",
      "680/680 [==============================] - 1s 889us/sample - loss: 0.7424 - accuracy: 0.7794 - val_loss: 3.3745 - val_accuracy: 0.2230\n",
      "Epoch 327/600\n",
      "680/680 [==============================] - 1s 887us/sample - loss: 0.7728 - accuracy: 0.7838 - val_loss: 3.3746 - val_accuracy: 0.2230\n",
      "Epoch 328/600\n",
      "680/680 [==============================] - 1s 861us/sample - loss: 0.8219 - accuracy: 0.7588 - val_loss: 3.3746 - val_accuracy: 0.2230\n",
      "Epoch 329/600\n",
      "680/680 [==============================] - 1s 814us/sample - loss: 0.7865 - accuracy: 0.7706 - val_loss: 3.3747 - val_accuracy: 0.2230\n",
      "Epoch 330/600\n",
      "680/680 [==============================] - 1s 866us/sample - loss: 0.8097 - accuracy: 0.7765 - val_loss: 3.3747 - val_accuracy: 0.2230\n",
      "Epoch 331/600\n",
      "680/680 [==============================] - 1s 872us/sample - loss: 0.8118 - accuracy: 0.7750 - val_loss: 3.3748 - val_accuracy: 0.2230\n",
      "Epoch 332/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 968us/sample - loss: 0.8706 - accuracy: 0.7706 - val_loss: 3.3750 - val_accuracy: 0.2230\n",
      "Epoch 333/600\n",
      "680/680 [==============================] - 1s 947us/sample - loss: 0.8334 - accuracy: 0.7412 - val_loss: 3.3750 - val_accuracy: 0.2230\n",
      "Epoch 334/600\n",
      "680/680 [==============================] - 1s 961us/sample - loss: 0.8494 - accuracy: 0.7485 - val_loss: 3.3748 - val_accuracy: 0.2230\n",
      "Epoch 335/600\n",
      "680/680 [==============================] - 1s 903us/sample - loss: 0.8133 - accuracy: 0.7515 - val_loss: 3.3749 - val_accuracy: 0.2230\n",
      "Epoch 336/600\n",
      "680/680 [==============================] - 1s 928us/sample - loss: 0.8079 - accuracy: 0.7809 - val_loss: 3.3750 - val_accuracy: 0.2230\n",
      "Epoch 337/600\n",
      "680/680 [==============================] - 1s 839us/sample - loss: 0.8497 - accuracy: 0.7574 - val_loss: 3.3751 - val_accuracy: 0.2230\n",
      "Epoch 338/600\n",
      "680/680 [==============================] - 1s 894us/sample - loss: 0.8165 - accuracy: 0.7706 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 339/600\n",
      "680/680 [==============================] - 1s 834us/sample - loss: 0.7940 - accuracy: 0.7691 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 340/600\n",
      "680/680 [==============================] - 1s 905us/sample - loss: 0.8272 - accuracy: 0.7441 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 341/600\n",
      "680/680 [==============================] - 1s 875us/sample - loss: 0.8241 - accuracy: 0.7515 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 342/600\n",
      "680/680 [==============================] - 1s 895us/sample - loss: 0.7966 - accuracy: 0.7574 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 343/600\n",
      "680/680 [==============================] - 1s 766us/sample - loss: 0.8376 - accuracy: 0.7588 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 344/600\n",
      "680/680 [==============================] - 1s 877us/sample - loss: 0.8496 - accuracy: 0.7471 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 345/600\n",
      "680/680 [==============================] - 1s 891us/sample - loss: 0.8147 - accuracy: 0.7662 - val_loss: 3.3752 - val_accuracy: 0.2230\n",
      "Epoch 346/600\n",
      "680/680 [==============================] - 1s 912us/sample - loss: 0.8022 - accuracy: 0.7794 - val_loss: 3.3752 - val_accuracy: 0.2230\n",
      "Epoch 347/600\n",
      "680/680 [==============================] - 1s 883us/sample - loss: 0.8655 - accuracy: 0.7397 - val_loss: 3.3753 - val_accuracy: 0.2230\n",
      "Epoch 348/600\n",
      "680/680 [==============================] - 1s 917us/sample - loss: 0.7970 - accuracy: 0.7750 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 349/600\n",
      "680/680 [==============================] - 1s 900us/sample - loss: 0.8051 - accuracy: 0.7691 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 350/600\n",
      "680/680 [==============================] - 1s 925us/sample - loss: 0.8530 - accuracy: 0.7574 - val_loss: 3.3753 - val_accuracy: 0.2230\n",
      "Epoch 351/600\n",
      "680/680 [==============================] - 1s 798us/sample - loss: 0.7767 - accuracy: 0.7926 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 352/600\n",
      "680/680 [==============================] - 1s 868us/sample - loss: 0.7620 - accuracy: 0.7676 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 353/600\n",
      "680/680 [==============================] - 1s 851us/sample - loss: 0.8540 - accuracy: 0.7441 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 354/600\n",
      "680/680 [==============================] - 1s 842us/sample - loss: 0.8148 - accuracy: 0.7647 - val_loss: 3.3757 - val_accuracy: 0.2230\n",
      "Epoch 355/600\n",
      "680/680 [==============================] - 1s 916us/sample - loss: 0.8262 - accuracy: 0.7765 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 356/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 0.7977 - accuracy: 0.7721 - val_loss: 3.3753 - val_accuracy: 0.2230\n",
      "Epoch 357/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8085 - accuracy: 0.7721 - val_loss: 3.3752 - val_accuracy: 0.2230\n",
      "Epoch 358/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7568 - accuracy: 0.7838 - val_loss: 3.3749 - val_accuracy: 0.2230\n",
      "Epoch 359/600\n",
      "680/680 [==============================] - 1s 977us/sample - loss: 0.7867 - accuracy: 0.7588 - val_loss: 3.3749 - val_accuracy: 0.2230\n",
      "Epoch 360/600\n",
      "680/680 [==============================] - 1s 971us/sample - loss: 0.7624 - accuracy: 0.7779 - val_loss: 3.3749 - val_accuracy: 0.2230\n",
      "Epoch 361/600\n",
      "680/680 [==============================] - 1s 898us/sample - loss: 0.8150 - accuracy: 0.7750 - val_loss: 3.3753 - val_accuracy: 0.2230\n",
      "Epoch 362/600\n",
      "680/680 [==============================] - 1s 857us/sample - loss: 0.8180 - accuracy: 0.7794 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 363/600\n",
      "680/680 [==============================] - 1s 807us/sample - loss: 0.8015 - accuracy: 0.7809 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 364/600\n",
      "680/680 [==============================] - 0s 717us/sample - loss: 0.8558 - accuracy: 0.7309 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 365/600\n",
      "680/680 [==============================] - 1s 962us/sample - loss: 0.7909 - accuracy: 0.7662 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 366/600\n",
      "680/680 [==============================] - 0s 728us/sample - loss: 0.8496 - accuracy: 0.7632 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 367/600\n",
      "680/680 [==============================] - 1s 839us/sample - loss: 0.8746 - accuracy: 0.7294 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 368/600\n",
      "680/680 [==============================] - 1s 746us/sample - loss: 0.7820 - accuracy: 0.7706 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 369/600\n",
      "680/680 [==============================] - 1s 754us/sample - loss: 0.7992 - accuracy: 0.7706 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 370/600\n",
      "680/680 [==============================] - 0s 721us/sample - loss: 0.8255 - accuracy: 0.7529 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 371/600\n",
      "680/680 [==============================] - 1s 778us/sample - loss: 0.7637 - accuracy: 0.7765 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 372/600\n",
      "680/680 [==============================] - 1s 844us/sample - loss: 0.7688 - accuracy: 0.7750 - val_loss: 3.3760 - val_accuracy: 0.2230\n",
      "Epoch 373/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8352 - accuracy: 0.7706 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 374/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7730 - accuracy: 0.7971 - val_loss: 3.3759 - val_accuracy: 0.2230\n",
      "Epoch 375/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7899 - accuracy: 0.7588 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 376/600\n",
      "680/680 [==============================] - 1s 953us/sample - loss: 0.8237 - accuracy: 0.7574 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 377/600\n",
      "680/680 [==============================] - 1s 961us/sample - loss: 0.8261 - accuracy: 0.7691 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 378/600\n",
      "680/680 [==============================] - 1s 847us/sample - loss: 0.7773 - accuracy: 0.7603 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 379/600\n",
      "680/680 [==============================] - 1s 862us/sample - loss: 0.7902 - accuracy: 0.7676 - val_loss: 3.3759 - val_accuracy: 0.2230\n",
      "Epoch 380/600\n",
      "680/680 [==============================] - 1s 830us/sample - loss: 0.7898 - accuracy: 0.7647 - val_loss: 3.3760 - val_accuracy: 0.2230\n",
      "Epoch 381/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8767 - accuracy: 0.7206 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 382/600\n",
      "680/680 [==============================] - 1s 956us/sample - loss: 0.8776 - accuracy: 0.7485 - val_loss: 3.3757 - val_accuracy: 0.2230\n",
      "Epoch 383/600\n",
      "680/680 [==============================] - 1s 889us/sample - loss: 0.8180 - accuracy: 0.7647 - val_loss: 3.3752 - val_accuracy: 0.2230\n",
      "Epoch 384/600\n",
      "680/680 [==============================] - 1s 848us/sample - loss: 0.7914 - accuracy: 0.7765 - val_loss: 3.3753 - val_accuracy: 0.2230\n",
      "Epoch 385/600\n",
      "680/680 [==============================] - 1s 921us/sample - loss: 0.8263 - accuracy: 0.7485 - val_loss: 3.3755 - val_accuracy: 0.2230\n",
      "Epoch 386/600\n",
      "680/680 [==============================] - 1s 866us/sample - loss: 0.7950 - accuracy: 0.7691 - val_loss: 3.3754 - val_accuracy: 0.2230\n",
      "Epoch 387/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 888us/sample - loss: 0.7792 - accuracy: 0.7794 - val_loss: 3.3756 - val_accuracy: 0.2230\n",
      "Epoch 388/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7648 - accuracy: 0.7706 - val_loss: 3.3757 - val_accuracy: 0.2230\n",
      "Epoch 389/600\n",
      "680/680 [==============================] - 1s 967us/sample - loss: 0.8145 - accuracy: 0.7706 - val_loss: 3.3758 - val_accuracy: 0.2230\n",
      "Epoch 390/600\n",
      "680/680 [==============================] - 1s 929us/sample - loss: 0.7538 - accuracy: 0.7838 - val_loss: 3.3761 - val_accuracy: 0.2230\n",
      "Epoch 391/600\n",
      "680/680 [==============================] - 1s 923us/sample - loss: 0.8186 - accuracy: 0.7500 - val_loss: 3.3762 - val_accuracy: 0.2230\n",
      "Epoch 392/600\n",
      "680/680 [==============================] - 1s 969us/sample - loss: 0.8134 - accuracy: 0.7735 - val_loss: 3.3761 - val_accuracy: 0.2230\n",
      "Epoch 393/600\n",
      "680/680 [==============================] - 1s 925us/sample - loss: 0.7954 - accuracy: 0.7750 - val_loss: 3.3763 - val_accuracy: 0.2230\n",
      "Epoch 394/600\n",
      "680/680 [==============================] - 1s 993us/sample - loss: 0.7789 - accuracy: 0.7838 - val_loss: 3.3766 - val_accuracy: 0.2230\n",
      "Epoch 395/600\n",
      "680/680 [==============================] - 1s 982us/sample - loss: 0.8109 - accuracy: 0.7632 - val_loss: 3.3769 - val_accuracy: 0.2230\n",
      "Epoch 396/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8521 - accuracy: 0.7574 - val_loss: 3.3775 - val_accuracy: 0.2230\n",
      "Epoch 397/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8317 - accuracy: 0.7471 - val_loss: 3.3777 - val_accuracy: 0.2230\n",
      "Epoch 398/600\n",
      "680/680 [==============================] - 1s 944us/sample - loss: 0.8670 - accuracy: 0.7412 - val_loss: 3.3782 - val_accuracy: 0.2230\n",
      "Epoch 399/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8060 - accuracy: 0.7706 - val_loss: 3.3784 - val_accuracy: 0.2230\n",
      "Epoch 400/600\n",
      "680/680 [==============================] - 1s 941us/sample - loss: 0.7896 - accuracy: 0.7750 - val_loss: 3.3788 - val_accuracy: 0.2230\n",
      "Epoch 401/600\n",
      "680/680 [==============================] - 1s 919us/sample - loss: 0.7559 - accuracy: 0.7632 - val_loss: 3.3789 - val_accuracy: 0.2230\n",
      "Epoch 402/600\n",
      "680/680 [==============================] - 1s 816us/sample - loss: 0.8415 - accuracy: 0.7441 - val_loss: 3.3791 - val_accuracy: 0.2230\n",
      "Epoch 403/600\n",
      "680/680 [==============================] - 1s 935us/sample - loss: 0.7675 - accuracy: 0.7765 - val_loss: 3.3789 - val_accuracy: 0.2230\n",
      "Epoch 404/600\n",
      "680/680 [==============================] - 1s 833us/sample - loss: 0.8033 - accuracy: 0.7632 - val_loss: 3.3792 - val_accuracy: 0.2230\n",
      "Epoch 405/600\n",
      "680/680 [==============================] - 1s 922us/sample - loss: 0.8597 - accuracy: 0.7397 - val_loss: 3.3794 - val_accuracy: 0.2230\n",
      "Epoch 406/600\n",
      "680/680 [==============================] - 1s 869us/sample - loss: 0.7785 - accuracy: 0.7809 - val_loss: 3.3801 - val_accuracy: 0.2230\n",
      "Epoch 407/600\n",
      "680/680 [==============================] - 1s 991us/sample - loss: 0.8726 - accuracy: 0.7338 - val_loss: 3.3805 - val_accuracy: 0.2230\n",
      "Epoch 408/600\n",
      "680/680 [==============================] - 1s 839us/sample - loss: 0.7818 - accuracy: 0.7838 - val_loss: 3.3807 - val_accuracy: 0.2230\n",
      "Epoch 409/600\n",
      "680/680 [==============================] - 1s 941us/sample - loss: 0.8334 - accuracy: 0.7647 - val_loss: 3.3810 - val_accuracy: 0.2230\n",
      "Epoch 410/600\n",
      "680/680 [==============================] - 1s 870us/sample - loss: 0.8240 - accuracy: 0.7382 - val_loss: 3.3813 - val_accuracy: 0.2230\n",
      "Epoch 411/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8072 - accuracy: 0.7544 - val_loss: 3.3816 - val_accuracy: 0.2230\n",
      "Epoch 412/600\n",
      "680/680 [==============================] - 1s 849us/sample - loss: 0.7684 - accuracy: 0.7853 - val_loss: 3.3819 - val_accuracy: 0.2230\n",
      "Epoch 413/600\n",
      "680/680 [==============================] - 1s 862us/sample - loss: 0.8572 - accuracy: 0.7765 - val_loss: 3.3821 - val_accuracy: 0.2230\n",
      "Epoch 414/600\n",
      "680/680 [==============================] - 1s 809us/sample - loss: 0.8256 - accuracy: 0.7691 - val_loss: 3.3821 - val_accuracy: 0.2230\n",
      "Epoch 415/600\n",
      "680/680 [==============================] - 1s 934us/sample - loss: 0.7925 - accuracy: 0.7662 - val_loss: 3.3823 - val_accuracy: 0.2230\n",
      "Epoch 416/600\n",
      "680/680 [==============================] - 1s 815us/sample - loss: 0.7942 - accuracy: 0.7765 - val_loss: 3.3821 - val_accuracy: 0.2230\n",
      "Epoch 417/600\n",
      "680/680 [==============================] - 1s 889us/sample - loss: 0.8731 - accuracy: 0.7441 - val_loss: 3.3819 - val_accuracy: 0.2230\n",
      "Epoch 418/600\n",
      "680/680 [==============================] - 1s 831us/sample - loss: 0.8009 - accuracy: 0.7750 - val_loss: 3.3817 - val_accuracy: 0.2230\n",
      "Epoch 419/600\n",
      "680/680 [==============================] - 1s 958us/sample - loss: 0.7380 - accuracy: 0.7750 - val_loss: 3.3814 - val_accuracy: 0.2230\n",
      "Epoch 420/600\n",
      "680/680 [==============================] - 1s 967us/sample - loss: 0.8061 - accuracy: 0.7471 - val_loss: 3.3814 - val_accuracy: 0.2230\n",
      "Epoch 421/600\n",
      "680/680 [==============================] - 1s 935us/sample - loss: 0.7267 - accuracy: 0.7956 - val_loss: 3.3815 - val_accuracy: 0.2230\n",
      "Epoch 422/600\n",
      "680/680 [==============================] - 1s 835us/sample - loss: 0.8314 - accuracy: 0.7706 - val_loss: 3.3815 - val_accuracy: 0.2230\n",
      "Epoch 423/600\n",
      "680/680 [==============================] - 1s 881us/sample - loss: 0.8329 - accuracy: 0.7559 - val_loss: 3.3817 - val_accuracy: 0.2230\n",
      "Epoch 424/600\n",
      "680/680 [==============================] - 1s 758us/sample - loss: 0.8012 - accuracy: 0.7662 - val_loss: 3.3819 - val_accuracy: 0.2230\n",
      "Epoch 425/600\n",
      "680/680 [==============================] - 1s 828us/sample - loss: 0.8046 - accuracy: 0.7735 - val_loss: 3.3820 - val_accuracy: 0.2230\n",
      "Epoch 426/600\n",
      "680/680 [==============================] - 1s 792us/sample - loss: 0.7814 - accuracy: 0.7794 - val_loss: 3.3821 - val_accuracy: 0.2230\n",
      "Epoch 427/600\n",
      "680/680 [==============================] - 1s 840us/sample - loss: 0.8261 - accuracy: 0.7750 - val_loss: 3.3823 - val_accuracy: 0.2230\n",
      "Epoch 428/600\n",
      "680/680 [==============================] - 1s 890us/sample - loss: 0.7939 - accuracy: 0.7676 - val_loss: 3.3826 - val_accuracy: 0.2230\n",
      "Epoch 429/600\n",
      "680/680 [==============================] - 1s 896us/sample - loss: 0.7961 - accuracy: 0.7691 - val_loss: 3.3828 - val_accuracy: 0.2230\n",
      "Epoch 430/600\n",
      "680/680 [==============================] - 1s 811us/sample - loss: 0.7970 - accuracy: 0.7706 - val_loss: 3.3832 - val_accuracy: 0.2230\n",
      "Epoch 431/600\n",
      "680/680 [==============================] - 1s 953us/sample - loss: 0.8522 - accuracy: 0.7529 - val_loss: 3.3832 - val_accuracy: 0.2230\n",
      "Epoch 432/600\n",
      "680/680 [==============================] - 1s 867us/sample - loss: 0.8114 - accuracy: 0.7750 - val_loss: 3.3832 - val_accuracy: 0.2230\n",
      "Epoch 433/600\n",
      "680/680 [==============================] - 1s 906us/sample - loss: 0.7583 - accuracy: 0.7838 - val_loss: 3.3834 - val_accuracy: 0.2230\n",
      "Epoch 434/600\n",
      "680/680 [==============================] - 1s 838us/sample - loss: 0.8315 - accuracy: 0.7471 - val_loss: 3.3834 - val_accuracy: 0.2230\n",
      "Epoch 435/600\n",
      "680/680 [==============================] - 1s 958us/sample - loss: 0.8045 - accuracy: 0.7632 - val_loss: 3.3833 - val_accuracy: 0.2230\n",
      "Epoch 436/600\n",
      "680/680 [==============================] - 1s 925us/sample - loss: 0.8377 - accuracy: 0.7765 - val_loss: 3.3835 - val_accuracy: 0.2230\n",
      "Epoch 437/600\n",
      "680/680 [==============================] - 1s 911us/sample - loss: 0.8775 - accuracy: 0.7574 - val_loss: 3.3838 - val_accuracy: 0.2230\n",
      "Epoch 438/600\n",
      "680/680 [==============================] - 1s 813us/sample - loss: 0.8053 - accuracy: 0.7574 - val_loss: 3.3840 - val_accuracy: 0.2230\n",
      "Epoch 439/600\n",
      "680/680 [==============================] - 1s 885us/sample - loss: 0.8054 - accuracy: 0.7618 - val_loss: 3.3841 - val_accuracy: 0.2230\n",
      "Epoch 440/600\n",
      "680/680 [==============================] - 1s 851us/sample - loss: 0.7697 - accuracy: 0.7779 - val_loss: 3.3839 - val_accuracy: 0.2230\n",
      "Epoch 441/600\n",
      "680/680 [==============================] - 1s 932us/sample - loss: 0.7845 - accuracy: 0.7750 - val_loss: 3.3840 - val_accuracy: 0.2302\n",
      "Epoch 442/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 832us/sample - loss: 0.8127 - accuracy: 0.7588 - val_loss: 3.3841 - val_accuracy: 0.2230\n",
      "Epoch 443/600\n",
      "680/680 [==============================] - 1s 901us/sample - loss: 0.7812 - accuracy: 0.7706 - val_loss: 3.3843 - val_accuracy: 0.2230\n",
      "Epoch 444/600\n",
      "680/680 [==============================] - 1s 880us/sample - loss: 0.8339 - accuracy: 0.7588 - val_loss: 3.3846 - val_accuracy: 0.2230\n",
      "Epoch 445/600\n",
      "680/680 [==============================] - 1s 940us/sample - loss: 0.8846 - accuracy: 0.7529 - val_loss: 3.3847 - val_accuracy: 0.2230\n",
      "Epoch 446/600\n",
      "680/680 [==============================] - 1s 940us/sample - loss: 0.8275 - accuracy: 0.7412 - val_loss: 3.3851 - val_accuracy: 0.2230\n",
      "Epoch 447/600\n",
      "680/680 [==============================] - 1s 955us/sample - loss: 0.7599 - accuracy: 0.7853 - val_loss: 3.3852 - val_accuracy: 0.2230\n",
      "Epoch 448/600\n",
      "680/680 [==============================] - 1s 818us/sample - loss: 0.7943 - accuracy: 0.7662 - val_loss: 3.3854 - val_accuracy: 0.2230\n",
      "Epoch 449/600\n",
      "680/680 [==============================] - 1s 942us/sample - loss: 0.7846 - accuracy: 0.7750 - val_loss: 3.3857 - val_accuracy: 0.2230\n",
      "Epoch 450/600\n",
      "680/680 [==============================] - 1s 819us/sample - loss: 0.8213 - accuracy: 0.7765 - val_loss: 3.3859 - val_accuracy: 0.2230\n",
      "Epoch 451/600\n",
      "680/680 [==============================] - 1s 884us/sample - loss: 0.8107 - accuracy: 0.7632 - val_loss: 3.3863 - val_accuracy: 0.2230\n",
      "Epoch 452/600\n",
      "680/680 [==============================] - 1s 904us/sample - loss: 0.7657 - accuracy: 0.7882 - val_loss: 3.3866 - val_accuracy: 0.2230\n",
      "Epoch 453/600\n",
      "680/680 [==============================] - 1s 940us/sample - loss: 0.8096 - accuracy: 0.7647 - val_loss: 3.3869 - val_accuracy: 0.2230\n",
      "Epoch 454/600\n",
      "680/680 [==============================] - 1s 797us/sample - loss: 0.8129 - accuracy: 0.7500 - val_loss: 3.3869 - val_accuracy: 0.2230\n",
      "Epoch 455/600\n",
      "680/680 [==============================] - 1s 912us/sample - loss: 0.7945 - accuracy: 0.7721 - val_loss: 3.3870 - val_accuracy: 0.2230\n",
      "Epoch 456/600\n",
      "680/680 [==============================] - 1s 796us/sample - loss: 0.8296 - accuracy: 0.7441 - val_loss: 3.3870 - val_accuracy: 0.2230\n",
      "Epoch 457/600\n",
      "680/680 [==============================] - 1s 989us/sample - loss: 0.7680 - accuracy: 0.7824 - val_loss: 3.3871 - val_accuracy: 0.2230\n",
      "Epoch 458/600\n",
      "680/680 [==============================] - 1s 877us/sample - loss: 0.7898 - accuracy: 0.7691 - val_loss: 3.3872 - val_accuracy: 0.2230\n",
      "Epoch 459/600\n",
      "680/680 [==============================] - 1s 918us/sample - loss: 0.8542 - accuracy: 0.7338 - val_loss: 3.3875 - val_accuracy: 0.2230\n",
      "Epoch 460/600\n",
      "680/680 [==============================] - 1s 882us/sample - loss: 0.7758 - accuracy: 0.7721 - val_loss: 3.3877 - val_accuracy: 0.2230\n",
      "Epoch 461/600\n",
      "680/680 [==============================] - 1s 953us/sample - loss: 0.7800 - accuracy: 0.7588 - val_loss: 3.3877 - val_accuracy: 0.2230\n",
      "Epoch 462/600\n",
      "680/680 [==============================] - 1s 858us/sample - loss: 0.7873 - accuracy: 0.7632 - val_loss: 3.3880 - val_accuracy: 0.2230\n",
      "Epoch 463/600\n",
      "680/680 [==============================] - 1s 886us/sample - loss: 0.7518 - accuracy: 0.8044 - val_loss: 3.3877 - val_accuracy: 0.2230\n",
      "Epoch 464/600\n",
      "680/680 [==============================] - 1s 883us/sample - loss: 0.8249 - accuracy: 0.7676 - val_loss: 3.3879 - val_accuracy: 0.2230\n",
      "Epoch 465/600\n",
      "680/680 [==============================] - 1s 907us/sample - loss: 0.7286 - accuracy: 0.7912 - val_loss: 3.3878 - val_accuracy: 0.2230\n",
      "Epoch 466/600\n",
      "680/680 [==============================] - 1s 835us/sample - loss: 0.8196 - accuracy: 0.7515 - val_loss: 3.3880 - val_accuracy: 0.2230\n",
      "Epoch 467/600\n",
      "680/680 [==============================] - 1s 871us/sample - loss: 0.8288 - accuracy: 0.7603 - val_loss: 3.3883 - val_accuracy: 0.2230\n",
      "Epoch 468/600\n",
      "680/680 [==============================] - 1s 843us/sample - loss: 0.7869 - accuracy: 0.7706 - val_loss: 3.3885 - val_accuracy: 0.2230\n",
      "Epoch 469/600\n",
      "680/680 [==============================] - 1s 965us/sample - loss: 0.7638 - accuracy: 0.7838 - val_loss: 3.3887 - val_accuracy: 0.2230\n",
      "Epoch 470/600\n",
      "680/680 [==============================] - 1s 846us/sample - loss: 0.8664 - accuracy: 0.7662 - val_loss: 3.3888 - val_accuracy: 0.2230\n",
      "Epoch 471/600\n",
      "680/680 [==============================] - 1s 887us/sample - loss: 0.7668 - accuracy: 0.7706 - val_loss: 3.3889 - val_accuracy: 0.2230\n",
      "Epoch 472/600\n",
      "680/680 [==============================] - 1s 860us/sample - loss: 0.7878 - accuracy: 0.7779 - val_loss: 3.3891 - val_accuracy: 0.2230\n",
      "Epoch 473/600\n",
      "680/680 [==============================] - 1s 852us/sample - loss: 0.7803 - accuracy: 0.7912 - val_loss: 3.3895 - val_accuracy: 0.2230\n",
      "Epoch 474/600\n",
      "680/680 [==============================] - 1s 774us/sample - loss: 0.7902 - accuracy: 0.7691 - val_loss: 3.3899 - val_accuracy: 0.2230\n",
      "Epoch 475/600\n",
      "680/680 [==============================] - 1s 807us/sample - loss: 0.7985 - accuracy: 0.7706 - val_loss: 3.3899 - val_accuracy: 0.2230\n",
      "Epoch 476/600\n",
      "680/680 [==============================] - 1s 807us/sample - loss: 0.8106 - accuracy: 0.7603 - val_loss: 3.3901 - val_accuracy: 0.2230\n",
      "Epoch 477/600\n",
      "680/680 [==============================] - 1s 964us/sample - loss: 0.7457 - accuracy: 0.7882 - val_loss: 3.3903 - val_accuracy: 0.2230\n",
      "Epoch 478/600\n",
      "680/680 [==============================] - 1s 815us/sample - loss: 0.7461 - accuracy: 0.7941 - val_loss: 3.3903 - val_accuracy: 0.2230\n",
      "Epoch 479/600\n",
      "680/680 [==============================] - 1s 862us/sample - loss: 0.7602 - accuracy: 0.7809 - val_loss: 3.3903 - val_accuracy: 0.2230\n",
      "Epoch 480/600\n",
      "680/680 [==============================] - 1s 854us/sample - loss: 0.7849 - accuracy: 0.7809 - val_loss: 3.3907 - val_accuracy: 0.2230\n",
      "Epoch 481/600\n",
      "680/680 [==============================] - 1s 838us/sample - loss: 0.7451 - accuracy: 0.7926 - val_loss: 3.3906 - val_accuracy: 0.2230\n",
      "Epoch 482/600\n",
      "680/680 [==============================] - 1s 788us/sample - loss: 0.7424 - accuracy: 0.7897 - val_loss: 3.3906 - val_accuracy: 0.2230\n",
      "Epoch 483/600\n",
      "680/680 [==============================] - 1s 894us/sample - loss: 0.8094 - accuracy: 0.7882 - val_loss: 3.3905 - val_accuracy: 0.2230\n",
      "Epoch 484/600\n",
      "680/680 [==============================] - 1s 890us/sample - loss: 0.8169 - accuracy: 0.7544 - val_loss: 3.3906 - val_accuracy: 0.2230\n",
      "Epoch 485/600\n",
      "680/680 [==============================] - 1s 983us/sample - loss: 0.8380 - accuracy: 0.7485 - val_loss: 3.3907 - val_accuracy: 0.2230\n",
      "Epoch 486/600\n",
      "680/680 [==============================] - 1s 952us/sample - loss: 0.8144 - accuracy: 0.7721 - val_loss: 3.3909 - val_accuracy: 0.2230\n",
      "Epoch 487/600\n",
      "680/680 [==============================] - 1s 936us/sample - loss: 0.7915 - accuracy: 0.7618 - val_loss: 3.3911 - val_accuracy: 0.2230\n",
      "Epoch 488/600\n",
      "680/680 [==============================] - 1s 785us/sample - loss: 0.8190 - accuracy: 0.7632 - val_loss: 3.3912 - val_accuracy: 0.2230\n",
      "Epoch 489/600\n",
      "680/680 [==============================] - 1s 942us/sample - loss: 0.7577 - accuracy: 0.7853 - val_loss: 3.3913 - val_accuracy: 0.2230\n",
      "Epoch 490/600\n",
      "680/680 [==============================] - 1s 844us/sample - loss: 0.8476 - accuracy: 0.7721 - val_loss: 3.3918 - val_accuracy: 0.2230\n",
      "Epoch 491/600\n",
      "680/680 [==============================] - 1s 932us/sample - loss: 0.8156 - accuracy: 0.7632 - val_loss: 3.3919 - val_accuracy: 0.2230\n",
      "Epoch 492/600\n",
      "680/680 [==============================] - 1s 825us/sample - loss: 0.8158 - accuracy: 0.7691 - val_loss: 3.3919 - val_accuracy: 0.2230\n",
      "Epoch 493/600\n",
      "680/680 [==============================] - 1s 969us/sample - loss: 0.8006 - accuracy: 0.7706 - val_loss: 3.3918 - val_accuracy: 0.2230\n",
      "Epoch 494/600\n",
      "680/680 [==============================] - 1s 900us/sample - loss: 0.7926 - accuracy: 0.7779 - val_loss: 3.3920 - val_accuracy: 0.2230\n",
      "Epoch 495/600\n",
      "680/680 [==============================] - 1s 886us/sample - loss: 0.7904 - accuracy: 0.7868 - val_loss: 3.3923 - val_accuracy: 0.2230\n",
      "Epoch 496/600\n",
      "680/680 [==============================] - 1s 843us/sample - loss: 0.8074 - accuracy: 0.7544 - val_loss: 3.3924 - val_accuracy: 0.2230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/600\n",
      "680/680 [==============================] - 1s 911us/sample - loss: 0.8073 - accuracy: 0.7706 - val_loss: 3.3923 - val_accuracy: 0.2230\n",
      "Epoch 498/600\n",
      "680/680 [==============================] - 1s 883us/sample - loss: 0.8521 - accuracy: 0.7706 - val_loss: 3.3921 - val_accuracy: 0.2230\n",
      "Epoch 499/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7788 - accuracy: 0.7706 - val_loss: 3.3921 - val_accuracy: 0.2230\n",
      "Epoch 500/600\n",
      "680/680 [==============================] - 1s 853us/sample - loss: 0.8356 - accuracy: 0.7544 - val_loss: 3.3921 - val_accuracy: 0.2230\n",
      "Epoch 501/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8292 - accuracy: 0.7603 - val_loss: 3.3920 - val_accuracy: 0.2230\n",
      "Epoch 502/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8006 - accuracy: 0.7706 - val_loss: 3.3919 - val_accuracy: 0.2230\n",
      "Epoch 503/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8493 - accuracy: 0.7382 - val_loss: 3.3920 - val_accuracy: 0.2230\n",
      "Epoch 504/600\n",
      "680/680 [==============================] - 1s 850us/sample - loss: 0.8101 - accuracy: 0.7691 - val_loss: 3.3924 - val_accuracy: 0.2230\n",
      "Epoch 505/600\n",
      "680/680 [==============================] - 1s 900us/sample - loss: 0.8235 - accuracy: 0.7676 - val_loss: 3.3923 - val_accuracy: 0.2230\n",
      "Epoch 506/600\n",
      "680/680 [==============================] - 1s 834us/sample - loss: 0.8429 - accuracy: 0.7588 - val_loss: 3.3921 - val_accuracy: 0.2230\n",
      "Epoch 507/600\n",
      "680/680 [==============================] - 1s 764us/sample - loss: 0.8121 - accuracy: 0.7529 - val_loss: 3.3923 - val_accuracy: 0.2230\n",
      "Epoch 508/600\n",
      "680/680 [==============================] - 1s 740us/sample - loss: 0.8213 - accuracy: 0.7544 - val_loss: 3.3924 - val_accuracy: 0.2230\n",
      "Epoch 509/600\n",
      "680/680 [==============================] - 1s 873us/sample - loss: 0.8302 - accuracy: 0.7779 - val_loss: 3.3922 - val_accuracy: 0.2230\n",
      "Epoch 510/600\n",
      "680/680 [==============================] - 1s 857us/sample - loss: 0.7947 - accuracy: 0.7676 - val_loss: 3.3919 - val_accuracy: 0.2230\n",
      "Epoch 511/600\n",
      "680/680 [==============================] - 1s 774us/sample - loss: 0.8361 - accuracy: 0.7500 - val_loss: 3.3918 - val_accuracy: 0.2230\n",
      "Epoch 512/600\n",
      "680/680 [==============================] - 1s 884us/sample - loss: 0.8543 - accuracy: 0.7559 - val_loss: 3.3919 - val_accuracy: 0.2230\n",
      "Epoch 513/600\n",
      "680/680 [==============================] - 1s 780us/sample - loss: 0.7983 - accuracy: 0.7676 - val_loss: 3.3917 - val_accuracy: 0.2230\n",
      "Epoch 514/600\n",
      "680/680 [==============================] - 1s 846us/sample - loss: 0.8542 - accuracy: 0.7603 - val_loss: 3.3916 - val_accuracy: 0.2230\n",
      "Epoch 515/600\n",
      "680/680 [==============================] - 0s 704us/sample - loss: 0.7583 - accuracy: 0.7824 - val_loss: 3.3918 - val_accuracy: 0.2230\n",
      "Epoch 516/600\n",
      "680/680 [==============================] - 0s 719us/sample - loss: 0.7983 - accuracy: 0.7765 - val_loss: 3.3921 - val_accuracy: 0.2230\n",
      "Epoch 517/600\n",
      "680/680 [==============================] - 1s 835us/sample - loss: 0.8694 - accuracy: 0.7353 - val_loss: 3.3924 - val_accuracy: 0.2230\n",
      "Epoch 518/600\n",
      "680/680 [==============================] - 1s 858us/sample - loss: 0.7913 - accuracy: 0.7662 - val_loss: 3.3925 - val_accuracy: 0.2230\n",
      "Epoch 519/600\n",
      "680/680 [==============================] - 1s 880us/sample - loss: 0.7912 - accuracy: 0.7574 - val_loss: 3.3924 - val_accuracy: 0.2230\n",
      "Epoch 520/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8057 - accuracy: 0.7691 - val_loss: 3.3925 - val_accuracy: 0.2230\n",
      "Epoch 521/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8186 - accuracy: 0.7662 - val_loss: 3.3927 - val_accuracy: 0.2230\n",
      "Epoch 522/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8317 - accuracy: 0.7559 - val_loss: 3.3930 - val_accuracy: 0.2230\n",
      "Epoch 523/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8249 - accuracy: 0.7529 - val_loss: 3.3927 - val_accuracy: 0.2230\n",
      "Epoch 524/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8350 - accuracy: 0.7529 - val_loss: 3.3928 - val_accuracy: 0.2230\n",
      "Epoch 525/600\n",
      "680/680 [==============================] - 1s 934us/sample - loss: 0.8040 - accuracy: 0.7647 - val_loss: 3.3930 - val_accuracy: 0.2230\n",
      "Epoch 526/600\n",
      "680/680 [==============================] - 1s 940us/sample - loss: 0.7514 - accuracy: 0.7897 - val_loss: 3.3933 - val_accuracy: 0.2230\n",
      "Epoch 527/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 0.8116 - accuracy: 0.7618 - val_loss: 3.3932 - val_accuracy: 0.2230\n",
      "Epoch 528/600\n",
      "680/680 [==============================] - 1s 961us/sample - loss: 0.7686 - accuracy: 0.7721 - val_loss: 3.3931 - val_accuracy: 0.2230\n",
      "Epoch 529/600\n",
      "680/680 [==============================] - 1s 859us/sample - loss: 0.7921 - accuracy: 0.7676 - val_loss: 3.3933 - val_accuracy: 0.2230\n",
      "Epoch 530/600\n",
      "680/680 [==============================] - 1s 868us/sample - loss: 0.7877 - accuracy: 0.7882 - val_loss: 3.3932 - val_accuracy: 0.2230\n",
      "Epoch 531/600\n",
      "680/680 [==============================] - 1s 803us/sample - loss: 0.7901 - accuracy: 0.7794 - val_loss: 3.3936 - val_accuracy: 0.2230\n",
      "Epoch 532/600\n",
      "680/680 [==============================] - 1s 951us/sample - loss: 0.8244 - accuracy: 0.7368 - val_loss: 3.3939 - val_accuracy: 0.2230\n",
      "Epoch 533/600\n",
      "680/680 [==============================] - 1s 931us/sample - loss: 0.7674 - accuracy: 0.7941 - val_loss: 3.3942 - val_accuracy: 0.2230\n",
      "Epoch 534/600\n",
      "680/680 [==============================] - 1s 952us/sample - loss: 0.7785 - accuracy: 0.7779 - val_loss: 3.3942 - val_accuracy: 0.2230\n",
      "Epoch 535/600\n",
      "680/680 [==============================] - 1s 863us/sample - loss: 0.8162 - accuracy: 0.7485 - val_loss: 3.3944 - val_accuracy: 0.2230\n",
      "Epoch 536/600\n",
      "680/680 [==============================] - 1s 854us/sample - loss: 0.8308 - accuracy: 0.7471 - val_loss: 3.3945 - val_accuracy: 0.2230\n",
      "Epoch 537/600\n",
      "680/680 [==============================] - 1s 868us/sample - loss: 0.7438 - accuracy: 0.7926 - val_loss: 3.3947 - val_accuracy: 0.2158\n",
      "Epoch 538/600\n",
      "680/680 [==============================] - 1s 900us/sample - loss: 0.8172 - accuracy: 0.7691 - val_loss: 3.3951 - val_accuracy: 0.2158\n",
      "Epoch 539/600\n",
      "680/680 [==============================] - 1s 843us/sample - loss: 0.7577 - accuracy: 0.7971 - val_loss: 3.3952 - val_accuracy: 0.2158\n",
      "Epoch 540/600\n",
      "680/680 [==============================] - 1s 967us/sample - loss: 0.7818 - accuracy: 0.7882 - val_loss: 3.3954 - val_accuracy: 0.2158\n",
      "Epoch 541/600\n",
      "680/680 [==============================] - 1s 912us/sample - loss: 0.8403 - accuracy: 0.7574 - val_loss: 3.3953 - val_accuracy: 0.2158\n",
      "Epoch 542/600\n",
      "680/680 [==============================] - 1s 881us/sample - loss: 0.8071 - accuracy: 0.7632 - val_loss: 3.3956 - val_accuracy: 0.2158\n",
      "Epoch 543/600\n",
      "680/680 [==============================] - 1s 853us/sample - loss: 0.7705 - accuracy: 0.7765 - val_loss: 3.3958 - val_accuracy: 0.2158\n",
      "Epoch 544/600\n",
      "680/680 [==============================] - 1s 897us/sample - loss: 0.8073 - accuracy: 0.7706 - val_loss: 3.3959 - val_accuracy: 0.2158\n",
      "Epoch 545/600\n",
      "680/680 [==============================] - 1s 933us/sample - loss: 0.7724 - accuracy: 0.7676 - val_loss: 3.3960 - val_accuracy: 0.2158\n",
      "Epoch 546/600\n",
      "680/680 [==============================] - 1s 952us/sample - loss: 0.7962 - accuracy: 0.7794 - val_loss: 3.3959 - val_accuracy: 0.2158\n",
      "Epoch 547/600\n",
      "680/680 [==============================] - 1s 941us/sample - loss: 0.7631 - accuracy: 0.7721 - val_loss: 3.3963 - val_accuracy: 0.2158\n",
      "Epoch 548/600\n",
      "680/680 [==============================] - 1s 991us/sample - loss: 0.8243 - accuracy: 0.7574 - val_loss: 3.3967 - val_accuracy: 0.2158\n",
      "Epoch 549/600\n",
      "680/680 [==============================] - 1s 968us/sample - loss: 0.8166 - accuracy: 0.7647 - val_loss: 3.3970 - val_accuracy: 0.2158\n",
      "Epoch 550/600\n",
      "680/680 [==============================] - 1s 927us/sample - loss: 0.7852 - accuracy: 0.7618 - val_loss: 3.3973 - val_accuracy: 0.2158\n",
      "Epoch 551/600\n",
      "680/680 [==============================] - 1s 869us/sample - loss: 0.7645 - accuracy: 0.7779 - val_loss: 3.3974 - val_accuracy: 0.2158\n",
      "Epoch 552/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/680 [==============================] - 1s 807us/sample - loss: 0.8058 - accuracy: 0.7500 - val_loss: 3.3978 - val_accuracy: 0.2158\n",
      "Epoch 553/600\n",
      "680/680 [==============================] - 1s 892us/sample - loss: 0.7318 - accuracy: 0.7941 - val_loss: 3.3979 - val_accuracy: 0.2158\n",
      "Epoch 554/600\n",
      "680/680 [==============================] - 1s 781us/sample - loss: 0.8559 - accuracy: 0.7544 - val_loss: 3.3984 - val_accuracy: 0.2158\n",
      "Epoch 555/600\n",
      "680/680 [==============================] - 1s 832us/sample - loss: 0.7892 - accuracy: 0.7824 - val_loss: 3.3984 - val_accuracy: 0.2158\n",
      "Epoch 556/600\n",
      "680/680 [==============================] - 1s 869us/sample - loss: 0.7809 - accuracy: 0.7691 - val_loss: 3.3988 - val_accuracy: 0.2158\n",
      "Epoch 557/600\n",
      "680/680 [==============================] - 1s 928us/sample - loss: 0.7669 - accuracy: 0.7824 - val_loss: 3.3986 - val_accuracy: 0.2158\n",
      "Epoch 558/600\n",
      "680/680 [==============================] - 1s 808us/sample - loss: 0.7452 - accuracy: 0.8044 - val_loss: 3.3989 - val_accuracy: 0.2230\n",
      "Epoch 559/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7110 - accuracy: 0.8088 - val_loss: 3.3991 - val_accuracy: 0.2230\n",
      "Epoch 560/600\n",
      "680/680 [==============================] - 1s 833us/sample - loss: 0.8231 - accuracy: 0.7529 - val_loss: 3.3991 - val_accuracy: 0.2230\n",
      "Epoch 561/600\n",
      "680/680 [==============================] - 1s 943us/sample - loss: 0.8036 - accuracy: 0.7706 - val_loss: 3.3994 - val_accuracy: 0.2230\n",
      "Epoch 562/600\n",
      "680/680 [==============================] - 1s 923us/sample - loss: 0.7398 - accuracy: 0.7853 - val_loss: 3.3996 - val_accuracy: 0.2230\n",
      "Epoch 563/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8118 - accuracy: 0.7794 - val_loss: 3.4000 - val_accuracy: 0.2230\n",
      "Epoch 564/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.8007 - accuracy: 0.7838 - val_loss: 3.4005 - val_accuracy: 0.2230\n",
      "Epoch 565/600\n",
      "680/680 [==============================] - 1s 1ms/sample - loss: 0.7358 - accuracy: 0.7956 - val_loss: 3.4005 - val_accuracy: 0.2230\n",
      "Epoch 566/600\n",
      "680/680 [==============================] - 1s 854us/sample - loss: 0.8200 - accuracy: 0.7485 - val_loss: 3.4006 - val_accuracy: 0.2230\n",
      "Epoch 567/600\n",
      "680/680 [==============================] - 1s 890us/sample - loss: 0.8396 - accuracy: 0.7471 - val_loss: 3.4007 - val_accuracy: 0.2230\n",
      "Epoch 568/600\n",
      "680/680 [==============================] - 1s 992us/sample - loss: 0.8363 - accuracy: 0.7647 - val_loss: 3.4009 - val_accuracy: 0.2230\n",
      "Epoch 569/600\n",
      "680/680 [==============================] - 1s 791us/sample - loss: 0.7552 - accuracy: 0.7868 - val_loss: 3.4011 - val_accuracy: 0.2230\n",
      "Epoch 570/600\n",
      "680/680 [==============================] - 1s 742us/sample - loss: 0.8104 - accuracy: 0.7721 - val_loss: 3.4014 - val_accuracy: 0.2230\n",
      "Epoch 571/600\n",
      "680/680 [==============================] - 1s 863us/sample - loss: 0.7960 - accuracy: 0.7515 - val_loss: 3.4015 - val_accuracy: 0.2230\n",
      "Epoch 572/600\n",
      "680/680 [==============================] - 1s 820us/sample - loss: 0.7913 - accuracy: 0.7515 - val_loss: 3.4016 - val_accuracy: 0.2230\n",
      "Epoch 573/600\n",
      "680/680 [==============================] - 1s 992us/sample - loss: 0.7289 - accuracy: 0.7868 - val_loss: 3.4014 - val_accuracy: 0.2230\n",
      "Epoch 574/600\n",
      "680/680 [==============================] - 1s 887us/sample - loss: 0.7704 - accuracy: 0.7691 - val_loss: 3.4014 - val_accuracy: 0.2230\n",
      "Epoch 575/600\n",
      "680/680 [==============================] - 1s 832us/sample - loss: 0.7768 - accuracy: 0.7706 - val_loss: 3.4013 - val_accuracy: 0.2230\n",
      "Epoch 576/600\n",
      "680/680 [==============================] - 1s 808us/sample - loss: 0.8152 - accuracy: 0.7559 - val_loss: 3.4013 - val_accuracy: 0.2230\n",
      "Epoch 577/600\n",
      "680/680 [==============================] - 1s 932us/sample - loss: 0.7995 - accuracy: 0.7750 - val_loss: 3.4013 - val_accuracy: 0.2230\n",
      "Epoch 578/600\n",
      "\r"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=Adam(lr),metrics=['accuracy'])\n",
    "lrScheduler = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
    "history = DD_Net.fit([X_0,X_1],Y,\n",
    "                    batch_size=len(Y),\n",
    "                    epochs=600,\n",
    "                    verbose=True,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[lrScheduler],\n",
    "                    validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_Net.save_weights('weights/coarse_lite.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With frame_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=adam(lr),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    print('epoch{}'.format(e))\n",
    "    X_0 = []\n",
    "    X_1 = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in tqdm(range(len(Train['pose']))): \n",
    "\n",
    "        label = np.zeros(C.clc_coarse)\n",
    "        label[Train['coarse_label'][i]-1] = 1 \n",
    "        \n",
    "        p = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
    "        p = sampling_frame(p,C)\n",
    "        \n",
    "        M = get_CG(p,C)\n",
    "        \n",
    "        X_0.append(M)\n",
    "        X_1.append(p)\n",
    "        Y.append(label)\n",
    "\n",
    "    X_0 = np.stack(X_0)  \n",
    "    X_1 = np.stack(X_1) \n",
    "    Y = np.stack(Y)\n",
    "   \n",
    "\n",
    "    DD_Net.fit([X_0,X_1],Y,\n",
    "            batch_size=len(Y),\n",
    "            epochs=1,\n",
    "            verbose=True,\n",
    "            shuffle=True,\n",
    "            validation_data=([X_test_0,X_test_1],Y_test)      \n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate time (excute it twice, the first time initialize takes extra times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "y = DD_Net.predict([X_0,X_1])\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = DD_Net.predict([X_test_0,X_test_1])\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_test,axis=1),np.argmax(Y_pred,axis=1))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
