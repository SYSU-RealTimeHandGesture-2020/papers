# Real-time Hand Gesture Detection and Classfication Using Convolutional Neural Networks

## 一、介绍

本文所提出的实时动态手势检测模型既考虑到准确率所要求的的模型规模，又考虑到实时识别的效率，结合了轻型的3d cnn实时检测器和复杂的离线训练的3d cnn分类器。  
 
细节上：
1. 通过滑动窗口截取视频流的帧序列，传入检测器，只有当检测器检测到手势后，分类器才会被激活。  
2. 为了避免相似的手势在分类时同时出现高分值，因此分配了权值（详见第三部分）  
3. 用Levenshtein距离作为评估指标，区别捕捉的单次激活手势与真实标签

> Levenshtein距离，是指利用字符操作（包括插入、删除和修改一个字符），把字符串A转换成字符串B所需要的最少操作数，两个字符串的编辑距离越小，则它们越相似。  


## 二、相关工作  

相比于将视频信息分轨或分割传入2d cnn进行预训练，3d cnn以视频帧序列作为输入，可以同时捕获时间和空间上的区别特征。  
 
同时，相比于已有的基于视频流的实时手势检测或分类的系统，本文提出的模型同时结合检测器与分类器，并且是第一个在基于深度学习的手势识别系统中执行单次激活的模型。  


## 三、模型架构  
### 1. 滑动窗及输入序列
滑动移速 s=1；  
传入检测器的帧序列 size = n；  
传入分类器的帧序列 size = m（n<<m）  
  
### 2. 检测器  
 当检测器检测到一个手势，分类器才会被激活并传入size=m的帧序列    
  
- 处理较小规模的序列以保证鲁棒性  
- 传入检测器的帧序列是传入分类器的帧序列的起始部分，因此不会遗漏被检测到的手势  
- 为了降低误报的可能性，检测器模型采用加权交叉熵损失进行训练  
- 为了保证实时检测的连续性，使用轻量级的模型  
  
### 3. 分类器  
- 分类器模型看重分类准确率，因此套用了C3D和ResNext-101模型
- 为了避免3d cnn模型过拟合，分类器模型先用Jester数据集进行预训练，再用于EgoGesture和nvGesture数据集
  
### 4. 后处理
本文提出一种后处理决策，基于检测器的前期预测最终决定检测器的判断，提高了可信度，并清除了预测中的大多数错误分类  
  
### 5. 单次激活
 通过两级控制机制实现

- early-detection 
 
  在手势结束之前（检测器激活分类器时）进行检测；  
  由于每个手势在一开始可能有相似的准备部分，因此在一个手势刚被检测到时，对分类得分进行加权平均，并且用加权平均后的分值差异作为可信度；  
 若两个分值最高的类别之间的差异值超过阈值水平，则触发early-detection

- late-detection
 若没有触发early-detection，在手势结束后（检测器停用分类器）将超过阈值的分值最高的类别作为延迟检测结果  

### 四、实验结果
 用Jester数据集预训练后，对EgoGesture和nvGesture数据集的离线分类准确率达到94.04%和83.82%，达到state-of-the-art级  
 而实时检测和分类任务中，准确率分别为91.04%和77.39%，接近离线分类的准确率
